This run was done on: This run was done on: This run was done on: This run was done on: This run was done on: This run was done on: This run was done on: This run was done on: This run was done on: This run was done on: Вс окт 14 16:11:08 MSK 2018
HPL.dat: 
This run was done on: This run was done on: Вс окт 14 16:11:08 MSK 2018
Вс окт 14 16:11:08 MSK 2018
This run was done on: Вс окт 14 16:11:08 MSK 2018
This run was done on: Вс окт 14 16:11:08 MSK 2018
Вс окт 14 16:11:08 MSK 2018
Вс окт 14 16:11:08 MSK 2018
Вс окт 14 16:11:08 MSK 2018
HPL.dat: 
Вс окт 14 16:11:08 MSK 2018
Вс окт 14 16:11:08 MSK 2018
HPL.dat: 
HPL.dat: 
Вс окт 14 16:11:08 MSK 2018
Вс окт 14 16:11:08 MSK 2018
HPL.dat: 
HPL.dat: 
HPL.dat: 
Вс окт 14 16:11:08 MSK 2018
HPL.dat: 
HPL.dat: 
HPL.dat: 
HPL.dat: 
HPL.dat: 
HPL.dat: 
Вс окт 14 16:11:08 MSK 2018
HPL.dat: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Binary name: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Binary name: 
Binary name: 
Binary name: 
Binary name: 
Binary name: 
Binary name: 
Binary name: 
Binary name: 
Binary name: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Binary name: 
Binary name: 
Binary name: 
Binary name: 
This run was done on: This run was done on: This run was done on: -rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
This run was done on: This run was done on: This run was done on: -rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
This run was done on: This run was done on: This run was done on: -rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
This run was done on: This run was done on: This run was done on: -rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
This run was done on: This run was done on: This run was done on: -rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
This run was done on: This run was done on: This run was done on: -rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
This run was done on: This run was done on: This run was done on: -rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
This run was done on: This run was done on: This run was done on: -rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
This run was done on: This run was done on: This run was done on: -rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
This run was done on: This run was done on: This run was done on: -rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
This run was done on: This run was done on: This run was done on: -rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
This run was done on: This run was done on: This run was done on: -rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
This run was done on: This run was done on: This run was done on: -rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
This run was done on: This run was done on: This run was done on: -rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
This script: 
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
This script: 
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
This script: 
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
This script: 
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
This script: 
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
This script: 
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
This script: 
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
This script: 
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
This script: 
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
This script: 
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
This script: 
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
This script: 
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:09 MSK 2018
This script: 
Вс окт 14 16:11:09 MSK 2018
Вс окт 14 16:11:10 MSK 2018
Вс окт 14 16:11:10 MSK 2018
This script: 
HPL.dat: 
HPL.dat: 
HPL.dat: 
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
HPL.dat: 
HPL.dat: 
HPL.dat: 
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
HPL.dat: 
HPL.dat: 
HPL.dat: 
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
HPL.dat: 
HPL.dat: 
HPL.dat: 
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
HPL.dat: 
HPL.dat: 
HPL.dat: 
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
HPL.dat: 
HPL.dat: 
HPL.dat: 
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
HPL.dat: 
HPL.dat: 
HPL.dat: 
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
HPL.dat: 
HPL.dat: 
HPL.dat: 
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
HPL.dat: 
HPL.dat: 
HPL.dat: 
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
HPL.dat: 
HPL.dat: 
HPL.dat: 
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
HPL.dat: 
HPL.dat: 
HPL.dat: 
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
HPL.dat: 
HPL.dat: 
HPL.dat: 
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
HPL.dat: 
HPL.dat: 
HPL.dat: 
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
HPL.dat: 
HPL.dat: 
HPL.dat: 
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Environment variables: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Environment variables: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Environment variables: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Environment variables: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Environment variables: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Environment variables: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Environment variables: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Environment variables: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Environment variables: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Environment variables: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Environment variables: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Environment variables: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Environment variables: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Environment variables: 
Binary name: 
Binary name: 
Binary name: 
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x10,11,38,39
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=5
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p170
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=0
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=0
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=22
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:0 0,1 2,2 4,3 6,4 8,5 10,6 12,7 14,8 16,9 18,10 20,11 22,12 24,13 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Binary name: 
Binary name: 
Binary name: 
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x2,3,30,31
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=1
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p170
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=0
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=0
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=8
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:0 0,1 2,2 4,3 6,4 8,5 10,6 12,7 14,8 16,9 18,10 20,11 22,12 24,13 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Binary name: 
Binary name: 
Binary name: 
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x4,5,32,33
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=2
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p170
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=0
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=0
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=13
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:0 0,1 2,2 4,3 6,4 8,5 10,6 12,7 14,8 16,9 18,10 20,11 22,12 24,13 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Binary name: 
Binary name: 
Binary name: 
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x12,13,40,41
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=6
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p170
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=0
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=0
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=25
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:0 0,1 2,2 4,3 6,4 8,5 10,6 12,7 14,8 16,9 18,10 20,11 22,12 24,13 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Binary name: 
Binary name: 
Binary name: 
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x0,1,28,29
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=0
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p170
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=0
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=0
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=7
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:0 0,1 2,2 4,3 6,4 8,5 10,6 12,7 14,8 16,9 18,10 20,11 22,12 24,13 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Binary name: 
Binary name: 
Binary name: 
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x22,23,50,51
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=11
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p170
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=0
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=0
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=40
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:0 0,1 2,2 4,3 6,4 8,5 10,6 12,7 14,8 16,9 18,10 20,11 22,12 24,13 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Binary name: 
Binary name: 
Binary name: 
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x24,25,52,53
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=12
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p170
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=0
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=0
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=43
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:0 0,1 2,2 4,3 6,4 8,5 10,6 12,7 14,8 16,9 18,10 20,11 22,12 24,13 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Binary name: 
Binary name: 
Binary name: 
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x6,7,34,35
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=3
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p170
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=0
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=0
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=16
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:0 0,1 2,2 4,3 6,4 8,5 10,6 12,7 14,8 16,9 18,10 20,11 22,12 24,13 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Binary name: 
Binary name: 
Binary name: 
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x20,21,48,49
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=10
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p170
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=0
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=0
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=37
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:0 0,1 2,2 4,3 6,4 8,5 10,6 12,7 14,8 16,9 18,10 20,11 22,12 24,13 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Binary name: 
Binary name: 
Binary name: 
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x26,27,54,55
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=13
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p170
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=0
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=0
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=46
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:0 0,1 2,2 4,3 6,4 8,5 10,6 12,7 14,8 16,9 18,10 20,11 22,12 24,13 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Binary name: 
Binary name: 
Binary name: 
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x8,9,36,37
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=4
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p170
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=0
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=0
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=19
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:0 0,1 2,2 4,3 6,4 8,5 10,6 12,7 14,8 16,9 18,10 20,11 22,12 24,13 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Binary name: 
Binary name: 
Binary name: 
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x18,19,46,47
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=9
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p170
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=0
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=0
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=34
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:0 0,1 2,2 4,3 6,4 8,5 10,6 12,7 14,8 16,9 18,10 20,11 22,12 24,13 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Binary name: 
Binary name: 
Binary name: 
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x14,15,42,43
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=7
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p170
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=0
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=0
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=28
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:0 0,1 2,2 4,3 6,4 8,5 10,6 12,7 14,8 16,9 18,10 20,11 22,12 24,13 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Binary name: 
Binary name: 
Binary name: 
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x16,17,44,45
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=8
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p170
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=0
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=0
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=31
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:0 0,1 2,2 4,3 6,4 8,5 10,6 12,7 14,8 16,9 18,10 20,11 22,12 24,13 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
Actual run: 
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
Actual run: 
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
Actual run: 
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
Actual run: 
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
Actual run: 
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
Actual run: 
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
Actual run: 
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
Actual run: 
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
Actual run: 
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
Actual run: 
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
Actual run: 
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
Actual run: 
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
Actual run: 
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
Actual run: 
This script: 
This script: 
This script: 
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script: 
This script: 
This script: 
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script: 
This script: 
This script: 
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script: 
This script: 
This script: 
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script: 
This script: 
This script: 
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script: 
This script: 
This script: 
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script: 
This script: 
This script: 
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script: 
This script: 
This script: 
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script: 
This script: 
This script: 
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script: 
This script: 
This script: 
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script: 
This script: 
This script: 
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script: 
This script: 
This script: 
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script: 
This script: 
This script: 
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script: 
This script: 
This script: 
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Environment variables: 
Environment variables: 
Environment variables: 
Done: Environment variables: 
Environment variables: 
Environment variables: 
Done: Environment variables: 
Environment variables: 
Environment variables: 
Done: Environment variables: 
Environment variables: 
Environment variables: 
Done: Environment variables: 
Environment variables: 
Environment variables: 
Done: Environment variables: 
Environment variables: 
Environment variables: 
Done: Environment variables: 
Environment variables: 
Environment variables: 
Done: Environment variables: 
Environment variables: 
Environment variables: 
Done: Environment variables: 
Environment variables: 
Environment variables: 
Done: Environment variables: 
Environment variables: 
Environment variables: 
Done: Environment variables: 
Environment variables: 
Environment variables: 
Done: Environment variables: 
Environment variables: 
Environment variables: 
Done: Environment variables: 
Environment variables: 
Environment variables: 
Done: Environment variables: 
Environment variables: 
Environment variables: 
Done: I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x2,3,30,31
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=15
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p171
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=1
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=1
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=9
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:14 0,15 2,16 4,17 6,18 8,19 10,20 12,21 14,22 16,23 18,24 20,25 22,26 24,27 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x6,7,34,35
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=45
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p173
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=3
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=3
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=15
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:42 0,43 2,44 4,45 6,46 8,47 10,48 12,49 14,50 16,51 18,52 20,53 22,54 24,55 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x4,5,32,33
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=30
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p172
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=2
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=2
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=12
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:28 0,29 2,30 4,31 6,32 8,33 10,34 12,35 14,36 16,37 18,38 20,39 22,40 24,41 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Вс окт 14 16:11:18 MSK 2018
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x0,1,28,29
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=14
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p171
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=1
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=1
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=7
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:14 0,15 2,16 4,17 6,18 8,19 10,20 12,21 14,22 16,23 18,24 20,25 22,26 24,27 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x26,27,54,55
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=55
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p173
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=3
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=3
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=45
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:42 0,43 2,44 4,45 6,46 8,47 10,48 12,49 14,50 16,51 18,52 20,53 22,54 24,55 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x0,1,28,29
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=28
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p172
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=2
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=2
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=7
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:28 0,29 2,30 4,31 6,32 8,33 10,34 12,35 14,36 16,37 18,38 20,39 22,40 24,41 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Вс окт 14 16:11:18 MSK 2018
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x6,7,34,35
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=17
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p171
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=1
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=1
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=15
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:14 0,15 2,16 4,17 6,18 8,19 10,20 12,21 14,22 16,23 18,24 20,25 22,26 24,27 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x10,11,38,39
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=47
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p173
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=3
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=3
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=21
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:42 0,43 2,44 4,45 6,46 8,47 10,48 12,49 14,50 16,51 18,52 20,53 22,54 24,55 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x20,21,48,49
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=38
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p172
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=2
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=2
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=36
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:28 0,29 2,30 4,31 6,32 8,33 10,34 12,35 14,36 16,37 18,38 20,39 22,40 24,41 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Вс окт 14 16:11:18 MSK 2018
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x24,25,52,53
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=26
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p171
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=1
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=1
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=42
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:14 0,15 2,16 4,17 6,18 8,19 10,20 12,21 14,22 16,23 18,24 20,25 22,26 24,27 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x2,3,30,31
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=43
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p173
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=3
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=3
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=9
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:42 0,43 2,44 4,45 6,46 8,47 10,48 12,49 14,50 16,51 18,52 20,53 22,54 24,55 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x24,25,52,53
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=40
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p172
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=2
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=2
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=42
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:28 0,29 2,30 4,31 6,32 8,33 10,34 12,35 14,36 16,37 18,38 20,39 22,40 24,41 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Вс окт 14 16:11:18 MSK 2018
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x4,5,32,33
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=16
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p171
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=1
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=1
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=12
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:14 0,15 2,16 4,17 6,18 8,19 10,20 12,21 14,22 16,23 18,24 20,25 22,26 24,27 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x12,13,40,41
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=48
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p173
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=3
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=3
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=24
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:42 0,43 2,44 4,45 6,46 8,47 10,48 12,49 14,50 16,51 18,52 20,53 22,54 24,55 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x2,3,30,31
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=29
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p172
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=2
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=2
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=9
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:28 0,29 2,30 4,31 6,32 8,33 10,34 12,35 14,36 16,37 18,38 20,39 22,40 24,41 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Вс окт 14 16:11:18 MSK 2018
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x26,27,54,55
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=27
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p171
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=1
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=1
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=45
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:14 0,15 2,16 4,17 6,18 8,19 10,20 12,21 14,22 16,23 18,24 20,25 22,26 24,27 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x14,15,42,43
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=49
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p173
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=3
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=3
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=27
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:42 0,43 2,44 4,45 6,46 8,47 10,48 12,49 14,50 16,51 18,52 20,53 22,54 24,55 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x10,11,38,39
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=33
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p172
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=2
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=2
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=21
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:28 0,29 2,30 4,31 6,32 8,33 10,34 12,35 14,36 16,37 18,38 20,39 22,40 24,41 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Вс окт 14 16:11:18 MSK 2018
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x16,17,44,45
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=22
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p171
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=1
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=1
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=30
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:14 0,15 2,16 4,17 6,18 8,19 10,20 12,21 14,22 16,23 18,24 20,25 22,26 24,27 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x0,1,28,29
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=42
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p173
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=3
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=3
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=7
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:42 0,43 2,44 4,45 6,46 8,47 10,48 12,49 14,50 16,51 18,52 20,53 22,54 24,55 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x12,13,40,41
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=34
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p172
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=2
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=2
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=24
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:28 0,29 2,30 4,31 6,32 8,33 10,34 12,35 14,36 16,37 18,38 20,39 22,40 24,41 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Вс окт 14 16:11:18 MSK 2018
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x22,23,50,51
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=25
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p171
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=1
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=1
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=39
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:14 0,15 2,16 4,17 6,18 8,19 10,20 12,21 14,22 16,23 18,24 20,25 22,26 24,27 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x16,17,44,45
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=50
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p173
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=3
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=3
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=30
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:42 0,43 2,44 4,45 6,46 8,47 10,48 12,49 14,50 16,51 18,52 20,53 22,54 24,55 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x18,19,46,47
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=37
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p172
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=2
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=2
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=33
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:28 0,29 2,30 4,31 6,32 8,33 10,34 12,35 14,36 16,37 18,38 20,39 22,40 24,41 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Вс окт 14 16:11:18 MSK 2018
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x8,9,36,37
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=18
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p171
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=1
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=1
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=18
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:14 0,15 2,16 4,17 6,18 8,19 10,20 12,21 14,22 16,23 18,24 20,25 22,26 24,27 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x18,19,46,47
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=51
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p173
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=3
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=3
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=33
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:42 0,43 2,44 4,45 6,46 8,47 10,48 12,49 14,50 16,51 18,52 20,53 22,54 24,55 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x6,7,34,35
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=31
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p172
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=2
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=2
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=15
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:28 0,29 2,30 4,31 6,32 8,33 10,34 12,35 14,36 16,37 18,38 20,39 22,40 24,41 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Вс окт 14 16:11:18 MSK 2018
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x10,11,38,39
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=19
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p171
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=1
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=1
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=21
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:14 0,15 2,16 4,17 6,18 8,19 10,20 12,21 14,22 16,23 18,24 20,25 22,26 24,27 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x4,5,32,33
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=44
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p173
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=3
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=3
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=12
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:42 0,43 2,44 4,45 6,46 8,47 10,48 12,49 14,50 16,51 18,52 20,53 22,54 24,55 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x8,9,36,37
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=32
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p172
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=2
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=2
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=18
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:28 0,29 2,30 4,31 6,32 8,33 10,34 12,35 14,36 16,37 18,38 20,39 22,40 24,41 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Вс окт 14 16:11:19 MSK 2018
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x12,13,40,41
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=20
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p171
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=1
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=1
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=24
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:14 0,15 2,16 4,17 6,18 8,19 10,20 12,21 14,22 16,23 18,24 20,25 22,26 24,27 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x8,9,36,37
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=46
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p173
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=3
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=3
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=18
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:42 0,43 2,44 4,45 6,46 8,47 10,48 12,49 14,50 16,51 18,52 20,53 22,54 24,55 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x16,17,44,45
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=36
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p172
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=2
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=2
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=30
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:28 0,29 2,30 4,31 6,32 8,33 10,34 12,35 14,36 16,37 18,38 20,39 22,40 24,41 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Вс окт 14 16:11:19 MSK 2018
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x18,19,46,47
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=23
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p171
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=1
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=1
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=33
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:14 0,15 2,16 4,17 6,18 8,19 10,20 12,21 14,22 16,23 18,24 20,25 22,26 24,27 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x22,23,50,51
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=53
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p173
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=3
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=3
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=39
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:42 0,43 2,44 4,45 6,46 8,47 10,48 12,49 14,50 16,51 18,52 20,53 22,54 24,55 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x14,15,42,43
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=35
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p172
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=2
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=2
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=27
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:28 0,29 2,30 4,31 6,32 8,33 10,34 12,35 14,36 16,37 18,38 20,39 22,40 24,41 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Вс окт 14 16:11:19 MSK 2018
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x20,21,48,49
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=24
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p171
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=1
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=1
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=36
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:14 0,15 2,16 4,17 6,18 8,19 10,20 12,21 14,22 16,23 18,24 20,25 22,26 24,27 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x24,25,52,53
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=54
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p173
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=3
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=3
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=42
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:42 0,43 2,44 4,45 6,46 8,47 10,48 12,49 14,50 16,51 18,52 20,53 22,54 24,55 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x22,23,50,51
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=39
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p172
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=2
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=2
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=39
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:28 0,29 2,30 4,31 6,32 8,33 10,34 12,35 14,36 16,37 18,38 20,39 22,40 24,41 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Вс окт 14 16:11:19 MSK 2018
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x14,15,42,43
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=21
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p171
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=1
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=1
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=27
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:14 0,15 2,16 4,17 6,18 8,19 10,20 12,21 14,22 16,23 18,24 20,25 22,26 24,27 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x20,21,48,49
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=52
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p173
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=3
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=3
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=36
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:42 0,43 2,44 4,45 6,46 8,47 10,48 12,49 14,50 16,51 18,52 20,53 22,54 24,55 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
I_MPI_INFO_LCPU=56
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
SLURM_NODELIST=n01p[170-173]
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
I_MPI_INFO_SIGN=198386
SLURM_JOB_NAME=run.sh
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
PMI_SIZE=56
LC_ADDRESS=ru_RU.UTF-8
SLURMD_NODENAME=n01p170
SLURM_TOPOLOGY_ADDR=n01p170
VT_MPI=impi4
HOSTNAME=n01p170
LC_MONETARY=ru_RU.UTF-8
SLURM_PRIO_PROCESS=0
I_MPI_INFO_PACK=0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1
GFORTRAN_UNBUFFERED_PRECONNECTED=y
SLURM_NODE_ALIASES=(null)
SLURM_SRUN_COMM_PORT=33793
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
SLURM_JOB_QOS=normal
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
I_MPI_PM=hydra
I_MPI_PIN_INFO=x26,27,54,55
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
I_MPI_INFO_CACHE_SHARE=2,2,16
QTDIR=/usr/lib64/qt-3.3
I_MPI_INFO_NUMA_NODE_MAP=mlx5_0:0
QTINC=/usr/lib64/qt-3.3/include
I_MPI_INFO_FLGDEXT=0
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
SLURM_NNODES=4
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
I_MPI_MPIRUN=mpirun
I_MPI_HYDRA_JMI_LIBRARY=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib/libjmi_slurm.so
DAPL_NETWORK_PROCESS_NUM=56
SLURM_STEP_NUM_NODES=4
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
I_MPI_INFO_THREAD=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1
SRUN_DEBUG=3
SLURM_JOBID=473245
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
I_MPI_INFO_CACHES=3
I_MPI_INFO_VEND=1
SLURM_NTASKS=4
NUMMIC=1
I_MPI_INFO_BRAND=Intel(R) Xeon(R) 
I_MPI_INFO_STATE=0
SLURM_LAUNCH_NODE_IPADDR=10.252.192.182
SLURM_STEP_ID=0
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
I_MPI_INFO_DESC=1342177285
SLURM_STEP_LAUNCHER_PORT=33793
SLURM_TASKS_PER_NODE=1(x4)
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
PMI_RANK=41
IPATH_NO_BACKTRACE=1
SLURM_JOB_ID=473245
SLURM_CPUS_PER_TASK=4
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
I_MPI_CMD=mpirun ./runme_intel64_dynamic 
MPIR_CVAR_NEMESIS_ENABLE_CKPOINT=1
SLURM_STEPID=0
SLURM_JOB_USER=snytav
PWD=/home/icmmg/snytav/HPL
MPIR_CVAR_CH3_INTERFACE_HOSTNAME=n01p172
SLURM_SRUN_COMM_HOST=10.252.192.182
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
I_MPI_INFO_CORE=0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14,0,1,2,3,4,5,6,8,9,10,11,12,13,14
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
I_MPI_HYDRA_UUID=902d0000-8386-c90d-3078-0500c0b60afc
SLURM_UMASK=0022
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_JOB_UID=50267
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
I_MPI_INFO_NUMA_NODE_NUM=4
SLURM_NODEID=2
I_MPI_INFO_NP=2
I_MPI_RANK_CMD=./runme_intel64_dynamic 
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_NPROCS=4
SLURM_TASK_PID=11649
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_DISTRIBUTION=cyclic
SLURM_CPUS_ON_NODE=56
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_PROCID=2
ENVIRONMENT=BATCH
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
SLURM_JOB_NODELIST=n01p[170-173]
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=5
HOME=/home/icmmg/snytav
I_MPI_INFO_SERIAL=E5-2697 v3 
SLURM_LOCALID=0
PMI_FD=45
I_MPI_INFO_CACHE_SIZE=32768,262144,18350080
SLURM_JOB_CPUS_PER_NODE=56(x4)
SLURM_CLUSTER_NAME=rsc
I_MPI_INFO_C_NAME=Unknown
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=login1.cluster
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
SLURM_JOB_PARTITION=tornado
I_MPI_PIN_MAPPING=14:28 0,29 2,30 4,31 6,32 8,33 10,34 12,35 14,36 16,37 18,38 20,39 22,40 24,41 26
LOGNAME=snytav
SLURM_STEP_NUM_TASKS=4
QTLIB=/usr/lib64/qt-3.3/lib
I_MPI_INFO_CACHE1=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_ACCOUNT=icmmg
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
I_MPI_INFO_CACHE2=0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30,0,1,2,3,4,5,6,8,9,10,11,12,13,14,16,17,18,19,20,21,22,24,25,26,27,28,29,30
SLURM_JOB_NUM_NODES=4
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_INFO_CACHE3=0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,0,0,0,0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3
LESSOPEN=||/usr/bin/lesspipe.sh %s
SLURM_STEP_TASKS_PER_NODE=1(x4)
INSPECTOR_2017_DIR=/opt/software/intel/inspector
SLURM_STEP_NODELIST=n01p[170-173]
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
I_MPI_INFO_FLGC=2147417087
I_MPI_PERHOST=allcores
CC=icc
I_MPI_INFO_NC=28
I_MPI_INFO_FLGB=14251
I_MPI_INFO_FLGD=-1075053569
I_MPI_INFO_NUMA_NODE_DIST=10,11,21,21,11,10,21,21,21,21,10,11,21,21,11,10
LC_TIME=ru_RU.UTF-8
I_MPI_INFO_FLGCEXT=0
I_MPI_INFO_MODE=775
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Вс окт 14 16:11:19 MSK 2018
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
Actual run: 
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Done: For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Done: Done: For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Done: Done: Done: This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Done: For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Done: Done: Вс окт 14 16:11:21 MSK 2018
Done: Done: This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Done: Вс окт 14 16:11:21 MSK 2018
Вс окт 14 16:11:21 MSK 2018
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Вс окт 14 16:11:21 MSK 2018
Вс окт 14 16:11:21 MSK 2018
Вс окт 14 16:11:21 MSK 2018
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Вс окт 14 16:11:22 MSK 2018
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Done: Done: This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Вс окт 14 16:11:22 MSK 2018
Вс окт 14 16:11:22 MSK 2018
Done: Вс окт 14 16:11:22 MSK 2018
Вс окт 14 16:11:22 MSK 2018
Вс окт 14 16:11:22 MSK 2018
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Done: Done: This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Done: This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Вс окт 14 16:11:22 MSK 2018
Вс окт 14 16:11:22 MSK 2018
Вс окт 14 16:11:22 MSK 2018
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Done: Done: Done: This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Вс окт 14 16:11:22 MSK 2018
Вс окт 14 16:11:22 MSK 2018
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Вс окт 14 16:11:22 MSK 2018
Done: Done: Done: This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Done: Done: Done: This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Вс окт 14 16:11:23 MSK 2018
Вс окт 14 16:11:23 MSK 2018
Вс окт 14 16:11:23 MSK 2018
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Done: Done: Done: Вс окт 14 16:11:23 MSK 2018
Вс окт 14 16:11:23 MSK 2018
Вс окт 14 16:11:23 MSK 2018
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Done: Done: Done: Вс окт 14 16:11:23 MSK 2018
Вс окт 14 16:11:23 MSK 2018
Вс окт 14 16:11:23 MSK 2018
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Done: Done: Done: Вс окт 14 16:11:23 MSK 2018
Вс окт 14 16:11:23 MSK 2018
Вс окт 14 16:11:23 MSK 2018
Done: Done: Done: Вс окт 14 16:11:23 MSK 2018
Вс окт 14 16:11:23 MSK 2018
Вс окт 14 16:11:23 MSK 2018
Done: Done: Done: Вс окт 14 16:11:23 MSK 2018
Вс окт 14 16:11:23 MSK 2018
Вс окт 14 16:11:23 MSK 2018
Вс окт 14 16:11:24 MSK 2018
Вс окт 14 16:11:24 MSK 2018
Вс окт 14 16:11:24 MSK 2018
Вс окт 14 16:11:24 MSK 2018
Вс окт 14 16:11:24 MSK 2018
Вс окт 14 16:11:24 MSK 2018
This run was done on: Вс окт 14 16:15:35 MSK 2018
HPL.dat: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Binary name: 
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
This script: 
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
Environment variables: 
LC_PAPER=ru_RU.UTF-8
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
SLURM_NODELIST=n01p[170-173]
SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MPS_STAT_DIR_POSTFIX=_%D-%T
SLURM_JOB_NAME=run.sh
MPI_PROC_NUM=4
LC_ADDRESS=ru_RU.UTF-8
LC_MONETARY=ru_RU.UTF-8
HOSTNAME=n01p170
VT_MPI=impi4
SLURM_TOPOLOGY_ADDR=n01p170
SLURMD_NODENAME=n01p170
SLURM_PRIO_PROCESS=0
INTEL_LICENSE_FILE=28518@license
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
SLURM_NODE_ALIASES=(null)
SHELL=/bin/bash
TERM=xterm
HISTSIZE=1000
MPS_LD_PRELOAD=libmps.so
SLURM_JOB_QOS=normal
SSH_CLIENT=5.44.169.193 47258 22
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SLURM_TOPOLOGY_ADDR_PATTERN=node
TMPDIR=/tmp
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
QTDIR=/usr/lib64/qt-3.3
QTINC=/usr/lib64/qt-3.3/include
SSH_TTY=/dev/pts/85
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
USER=snytav
SLURM_NNODES=4
LC_TELEPHONE=ru_RU.UTF-8
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib
MPS_STAT_ENABLE_IDLE_VAL=1
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
SLURM_JOBID=473246
MPI_PER_NODE=4
NUMMIC=1
MC_TMPDIR=/tmp/mc-snytav
MPS_STAT_LEVEL=5
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
MAIL=/var/spool/mail/snytav
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
SLURM_TASKS_PER_NODE=14(x4)
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
MPS_KMP_FORKJOIN_FRAMES_MODE=3
SLURM_CPUS_PER_TASK=4
SLURM_JOB_ID=473246
LC_IDENTIFICATION=ru_RU.UTF-8
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
HPL_EXE=xhpl_intel64_dynamic
PWD=/home/icmmg/snytav/HPL
SLURM_JOB_USER=snytav
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
LANG=en_US.UTF-8
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
SLURM_UMASK=0022
LC_MEASUREMENT=ru_RU.UTF-8
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
SLURM_JOB_UID=50267
SLURM_NODEID=0
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
SLURM_SUBMIT_DIR=/home/icmmg/snytav/HPL
VT_ROOT=/opt/software/intel/itac/2017.4.034
SLURM_TASK_PID=13841
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
SLURM_CPUS_ON_NODE=56
HISTCONTROL=ignorespace
CXX=icpc
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
ENVIRONMENT=BATCH
SLURM_PROCID=0
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SLURM_JOB_NODELIST=n01p[170-173]
HOME=/home/icmmg/snytav
SHLVL=4
SLURM_LOCALID=0
SLURM_CLUSTER_NAME=rsc
SLURM_JOB_CPUS_PER_NODE=56(x4)
MC_SID=56657
VT_ARCH=intel64
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
FC=ifort
SLURM_SUBMIT_HOST=login1.cluster
SLURM_GTIDS=0
SLURM_JOB_PARTITION=tornado
LOGNAME=snytav
QTLIB=/usr/lib64/qt-3.3/lib
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SLURM_JOB_ACCOUNT=icmmg
MODULESHOME=/usr/share/Modules
MPS_STAT_MESSAGES=1
SLURM_JOB_NUM_NODES=4
LESSOPEN=||/usr/bin/lesspipe.sh %s
INSPECTOR_2017_DIR=/opt/software/intel/inspector
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
CC=icc
LC_TIME=ru_RU.UTF-8
LC_NAME=ru_RU.UTF-8
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Actual run: 
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Done: Вс окт 14 16:15:35 MSK 2018
This run was done on: Вс окт 14 16:18:12 MSK 2018
HPL.dat: 
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
4000         Ns
1            # of NBs
192          NBs
1            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
1            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
6            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM,6=Psh,7=Psh2)
1            # of lookahead depth
0            DEPTHs (>=0)
0            SWAP (0=bin-exch,1=long,2=mix)
1           swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
1            U  in (0=transposed,1=no-transposed) form
0            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
Binary name: 
-rwxr-xr-x 1 snytav icmmg 1311927 авг  2  2016 xhpl_intel64_dynamic
This script: 
#!/bin/bash
#===============================================================================
# Copyright 2001-2016 Intel Corporation All Rights Reserved.
#
# The source code,  information  and material  ("Material") contained  herein is
# owned by Intel Corporation or its  suppliers or licensors,  and  title to such
# Material remains with Intel  Corporation or its  suppliers or  licensors.  The
# Material  contains  proprietary  information  of  Intel or  its suppliers  and
# licensors.  The Material is protected by  worldwide copyright  laws and treaty
# provisions.  No part  of  the  Material   may  be  used,  copied,  reproduced,
# modified, published,  uploaded, posted, transmitted,  distributed or disclosed
# in any way without Intel's prior express written permission.  No license under
# any patent,  copyright or other  intellectual property rights  in the Material
# is granted to  or  conferred  upon  you,  either   expressly,  by implication,
# inducement,  estoppel  or  otherwise.  Any  license   under such  intellectual
# property rights must be express and approved by Intel in writing.
#
# Unless otherwise agreed by Intel in writing,  you may not remove or alter this
# notice or  any  other  notice   embedded  in  Materials  by  Intel  or Intel's
# suppliers or licensors in any way.
#===============================================================================

#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."

# Set total number of MPI processes for the HPL (should be equal to PxQ).
export MPI_PROC_NUM=4

# Set the MPI per node and number of MICs attached to each node.
# MPI_PER_NODE should be equal to 1 or number of sockets in the system. Otherwise,
# the HPL performance will be low. 
# MPI_PER_NODE is same as -perhost or -ppn paramaters in mpirun/mpiexec
export MPI_PER_NODE=4

# Set number of MICs that HPL will access per node
export NUMMIC=1

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
export I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360

#         "export I_MPI_PIN_CELL=core"
#         You can use this variable (beginning Intel MPI 4.0.1 for cases if HT is enabled. 
#         The variable forces to pin MPI processes and threads to real cores, 
#         so logical processors will not be involved.
#         It can be used together with the variable below, when Hydra Process Manager:
#         "export I_MPI_PIN_DOMAIN=auto" This allows uniform distribution of
#	      the processes and thread domains

# export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt
export HPL_EXE=xhpl_intel64_dynamic

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be also be set on the Intel MPI command line
# using the -genv option (to appear before the -np 1):

# mpirun -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

mpirun -perhost ${MPI_PER_NODE} -np ${MPI_PROC_NUM} ./runme_intel64_prv "$@" | tee -a $OUT

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
Environment variables: 
MKLROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl
LC_PAPER=ru_RU.UTF-8
MPS_STAT_DIR_POSTFIX=_%D-%T
MPS_INTEL_LIBITTNOTIFY64=libmps.so
MANPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/man:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/man/en_US:/opt/software/intel/documentation_2016/en/debugger/gdb-ia/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/man/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/man/:/opt/ibutils/share/man::/opt/software/intel/man/common:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/software/intel//itac/2017.4.034/man:/usr/share/man:/usr/local/share/man
MPI_PROC_NUM=4
LC_ADDRESS=ru_RU.UTF-8
VT_MPI=impi4
HOSTNAME=login1.cluster
LC_MONETARY=ru_RU.UTF-8
IPPROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp
INTEL_LICENSE_FILE=28518@license
TERM=xterm
SHELL=/bin/bash
MPS_LD_PRELOAD=libmps.so
HISTSIZE=1000
GDBSERVER_MIC=/opt/software/intel/debugger_2016/gdb/targets/mic/bin/gdbserver
SSH_CLIENT=5.44.169.193 47258 22
LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4
LC_NUMERIC=ru_RU.UTF-8
OUT=xhpl_intel64_dynamic_outputs.txt
QTDIR=/usr/lib64/qt-3.3
QTINC=/usr/lib64/qt-3.3/include
MIC_LD_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/mic:/opt/intel/mic/coi/device-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
SSH_TTY=/dev/pts/85
VTUNE_AMPLIFIER_XE_2017_DIR=/opt/software/intel/vtune_amplifier_xe
QT_GRAPHICSSYSTEM_CHECKED=1
USER=snytav
LD_LIBRARY_PATH=:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/intel64/gcc4.4:/opt/software/intel/debugger_2016/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/../compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64/gcc4.7:/opt/software/intel/debugger_2017/iga/lib:/opt/software/intel/debugger_2017/libipt/intel64/lib:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/intel64_lin:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/intel64_lin/gcc4.4:/opt/software/intel/itac/2017.4.034/mic/slib:/opt/software/intel/itac/2017.4.034/intel64/slib:/opt/software/intel//itac/2017.4.034/mic/slib:/opt/software/intel//itac/2017.4.034/intel64/slib
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
LC_TELEPHONE=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE_VAL=1
MIC_LIBRARY_PATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/mic/lib:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/mic:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/lib/mic
CPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/ipp/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/tbb/include:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/include
MPI_PER_NODE=4
NUMMIC=1
MC_TMPDIR=/tmp/mc-snytav
NLSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2016/gdb/intel64/share/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/compiler/lib/intel64/locale/%l_%t/%N:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mkl/lib/intel64/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64_mic/share/locale/%l_%t/%N:/opt/software/intel/debugger_2017/gdb/intel64/share/locale/%l_%t/%N
MPS_STAT_LEVEL=5
VT_ADD_LIBS=-ldwarf -lelf -lvtunwind -lm -lpthread
MAIL=/var/spool/mail/snytav
PATH=/opt/software/intel/inspector/bin64:/opt/software/intel/vtune_amplifier_xe/bin64:/opt/software/intel/debugger_2016/gdb/intel64_mic/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi/intel64/bin:/opt/software/intel/compilers_and_libraries_2016.3.210/linux/bin/intel64:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/bin/intel64:/opt/software/intel/debugger_2017/gdb/intel64_mic/bin:/opt/software/intel/itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/opt/software/intel//itac/2017.4.034/intel64/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/opt/software/numeca/bin:/home/icmmg/snytav/.local/bin:/home/icmmg/snytav/bin
I_MPI_DAPL_DIRECT_COPY_THRESHOLD=655360
MPS_KMP_FORKJOIN_FRAMES_MODE=3
TBBROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/tbb
LC_IDENTIFICATION=ru_RU.UTF-8
HPL_EXE=xhpl_intel64_dynamic
PWD=/home/icmmg/snytav/HPL
_LMFILES_=/opt/basis/modules/intel_license:/opt/basis/modules/dev/intel/traceanalyzer:/opt/basis/modules/compiler/intel/2017.2.174:/opt/basis/modules/compiler/intel/2016.3.210:/opt/basis/modules/mpi/impi/5.1.3.210:/opt/basis/modules/dev/intel/vtune:/opt/basis/modules/dev/intel/inspector
GDB_CROSS=/opt/software/intel/debugger_2016/gdb/intel64_mic/bin/gdb-mic
LANG=en_US.UTF-8
MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/opt/basis/modules:/home/icmmg/snytav/.billing:/opt/basis/modules:/home/icmmg/snytav/.billing
VT_LIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/lib
LOADEDMODULES=intel_license:dev/intel/traceanalyzer:compiler/intel/2017.2.174:compiler/intel/2016.3.210:mpi/impi/5.1.3.210:dev/intel/vtune:dev/intel/inspector
LC_MEASUREMENT=ru_RU.UTF-8
MPS_STAT_ENABLE_IDLE=I_MPI_PVAR_IDLE
VT_ROOT=/opt/software/intel/itac/2017.4.034
DAALROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal
MPS_TOOL_ROOT=/opt/software/intel/itac/2017.4.034
MPM_LAUNCHER=/opt/software/intel/debugger_2016/mpm/mic/bin/start_mpm.sh
CXX=icpc
HISTCONTROL=ignorespace
INTEL_PYTHONHOME=/opt/software/intel/debugger_2016/python/intel64/
SHLVL=3
HOME=/home/icmmg/snytav
FC=ifort
VT_SLIB_DIR=/opt/software/intel//itac/2017.4.034/intel64/slib
VT_ARCH=intel64
MC_SID=56657
LOGNAME=snytav
QTLIB=/usr/lib64/qt-3.3/lib
CLASSPATH=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/daal/lib/daal.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/mpi/intel64/lib/mpi.jar:/opt/software/intel/compilers_and_libraries_2017.2.174/linux/daal/lib/daal.jar
SSH_CONNECTION=5.44.169.193 47258 195.209.233.210 22
MPS_STAT_MESSAGES=1
MODULESHOME=/usr/share/Modules
LESSOPEN=||/usr/bin/lesspipe.sh %s
INSPECTOR_2017_DIR=/opt/software/intel/inspector
INFOPATH=/opt/software/intel/documentation_2016/en/debugger/gdb-ia/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-mic/info/:/opt/software/intel/documentation_2016/en/debugger/gdb-igfx/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-ia/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-mic/info/:/opt/software/intel/documentation_2017/en/debugger//gdb-igfx/info/
CC=icc
LC_TIME=ru_RU.UTF-8
I_MPI_ROOT=/opt/software/intel/compilers_and_libraries_2016.3.210/linux/mpi
LC_NAME=ru_RU.UTF-8
module=() {  eval `/usr/bin/modulecmd bash $*`
}
_=/usr/bin/env
Actual run: 
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
This script does not support this usage model. Please change number of MPI processes per node (MPI_PER_NODE variable inside runme_intel64)!
For 1 Intel Xeon Phi co-processor, use 1 or 2 MPI processes per node. Current value = 4.
Done: Вс окт 14 16:18:12 MSK 2018
