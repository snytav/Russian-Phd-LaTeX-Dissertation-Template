\chapter{Комплексная оценка производительности ВС}



В настоящий момент списки Top50 и Top500
выстроены в порядке убывания пиковой производительности и производительности на тесте LinPack что, разумеется, дает определенную информацию
о сравнительной скорости работы представленных там машин. Но очень многие факторы, такие как скорость работы и объем дисков, пропускная 
способность шины памяти и коммуникационной сети, неоднородность оборудования и т.д. - остаются за пределами рассмотрения. А это именно те 
проблемы, с которыми придется столкнуться при попытке посчитать на кластере большую задачу. По этой причине тестирование проводится с помощью измерения времени, затрачиваемого на различные этапы программы, решающей реальную физическую задачу.




Предложена методика комплексной оценки тестируемой ВС с точки зрения возможности эффективной реализации математических моделей на основе определения баланса между скоростью счета и скоростью пересылки данных между узлами ВС. Баланс определяется на основе усреднения данных расчетов по методу частиц в ячейках, который используется в качестве оценки снизу по скорости счета и оценки сверху по памяти для большинства существующих математических методов.

Кроме того, на основе проведенных расчетов измерена скорость счета и скорость перемещения данных для нескольких протестированных ВС. Результаты, показанные в этой главе опубликованы в \cite{VestnikNNSU,NumMethMultiLevel,SuperFrI,integrApproach}   

		


\section{О влиянии организации данных на результат измерения производительности процессоров}
\label{procs_influence}

Модельные частицы расположены внутри расчетной области случайным образом. Если даже модельные частицы расположены рядом в массиве, где хранятся их координаты,  то сами значения координат будут близкими только вначале. Частицы с близкими значениями координат находятся в соседних ячейках, или даже просто в одной и той же ячейке. В дальнейшем модельные частицы движутся в рамках расчетной области непредсказуемым образом, и таким образом, перестают находится в соседних ячейках. Это означает, что обращения к трехмерным массивам, содержащим электрическое и магнитное поля, являются неупорядоченными. Если для частицы с номером j требуется обратиться к ячейке трехмерной сетки (трехмерного массива) с индексами i,l,k, то для частицы с номером j+1, c большой вероятностью, потребуется обращение не к ячейке с индексами (i,l,k-1) или (i,l,k+1) и т.д., то есть к соседней ячейке, а наоборот, потребуется обращение к ячейке, значительно удаленной в рамках расчетной области. 
Из этого можно сделать вывод, что использование кэш-памяти в данном случае не позволяет сократить время счета. 

Здесь важно отметить, что предсказать заранее движение модельных частиц нельзя: знание траекторий  движения модельных частиц составляет сущность решения задачи о  динамике плазмы, если такое знание есть, то по сути дела задача решена, и нет необходимости проводить расчет.


Использование кэш-памяти было бы более эффективным, если бы частицы были упорядочены. Тогда значения полей, загруженных в кэш при расчете движения некоторой частицы, могли бы быть использованы и для следующей частицы, если она расположена близко. 

Для этого достаточно упорядочить частицы по ячейкам сетки, то есть, хранить каким-то образом вместе все частицы, которые расположены внутри каждой ячейки. Это означает, что полная сортировка массива частиц не нужна, так как с точки зрения использования кэш-памяти не имеет значения, как частицы расположены внутри ячейки. 

Модельные частицы, принадлежащие некоторой ячейке сетки, можно хранить в виде связанного списка или в виде массива. Преимущества списка очевидны: нет ограничения на число частиц в ячейке, простота добавления/удаления, но есть и недостатки, а именно большее по сравнению с массивом время доступа. Если же частицы каждой ячейки хранятся в виде массива (статического массива), то применительно к трехмерной задаче для двух сортов частиц это даст 5-мерный массив для одной только координаты X всех частиц (напомним, что модельная частица в данном случае характеризуется шестью признаками). 

Но основная проблема в случае статического массива - это максимальное число частиц в ячейке. Это означает, что заранее неизвестно, какой длины массив потребуется для хранения всех частиц в каждой ячейке. Из проведенных расчетов известно, что максимальное значение плотности электронов было равно 5 (в единицах начальной плотности). Таким образом, можно было бы задать длину массива частиц в каждой ячейке $5N$, где $N$ - число частиц в ячейке в начальный момент времени. Но в этом случае размер массива частиц увеличится в 5 раз, а его размер составляет 70 Гб, например, для сетки $512\times64\times64$ и $N = 150$. 

Использование для этой цели динамических массивов решает проблему перерасхода памяти, но создает другую: необходимость иметь внутри программы свой эффективный менеджер динамической памяти, что, возможно, является решаемой задачей, но едва ли приведет к существенному уменьшению времени работы программы в целом. 

Поэтому был реализован компромиссный вариант: для каждого сорта частиц (в данном случае 2 сорта: электроны и ионы) в каждой ячейке в целочисленном массиве длины 5N хранить номера частиц, находящихся в данный момент в данной ячейке. Номер задает позицию частицы в больших (порядка 100 млн. элементов) вещественных массивах, в которых хранятся координаты и импульсы модельных частиц. Таким образом, при перемещении частицы из одной ячейки в другую (обязательно в соседнюю - это определяется соображениями устойчивости метода частиц) перемещается только номер частицы: он удаляется из массива номеров, описывающих текущую ячейку, и добавляется в массив номеров одной из соседних ячеек. Внутри самих массивов координат и импульсов частицы никогда не перемещаются. 

Также был реализован вариант с хранением частиц каждой ячейки в виде связанного списка. В этом случае имеется 4-мерный массив указателей, задающий первый элемент списка в каждой ячейке, и отсутствуют большие массивы: вся информация по частицам хранится только в списках. 

В обоих вариантах на вход процедуры интегрирования уравнений движения модельных частиц подаются шесть небольших (размером не более 5N) массивов, хранящих координаты и импульс частиц для каждой конкретной ячейки. Эти массивы формируются либо на основе списка частиц, либо на основе массива номеров частиц этой ячейки. 

Таким образом, имеются следующие варианты организации частиц в программе:
\begin{enumerate}
	\item Исходный неоптимизированный вариант; 
	\item Хранение значений поля в 4-мерном массиве; 
	\item Упорядочивание частиц с помощью массивов номеров; 
	\item Упорядочивание частиц с помощью связанного списка; 
\end{enumerate}

Далее рассмотрим результаты тестов, показывающих эффективность выполненной оптимизации. Тестовые расчеты проводились на рабочей станции с процессором AMD Phenom (Phenom II X6 1055T),  производительность (раздел  \ref{app_phenom} в приложении \ref{AppendixA}) 41.9 GFLOPS, и на кластере Новосибирского Государственного Университета, оснащенного процессорами процессор Intel Xeon  E5540 производительность (раздел \ref{app_E5540} в приложении \ref{AppendixA}) на LU-разложении 2.5 GFLOPS). В обоих случая была выбрана сетка такого размера, что даже один трехмерный массив, содержащий, например, одну из компонент поля, заведомо не помещается в кэш. 
Размер сетки для рабочей станции на базе процессора Phenom  $64\times32\times32$ узла, 150 частиц в ячейке, всего 9.8 млн. частиц. Размер сетки для кластера на базе процессора Intel Xeon  E5540 в расчете на одно ядро, $512\times2\times64$ узла, 150 частиц в ячейке, те же 9.8 млн. частиц на ядро. С учетом определенного в главе 1 количества операций в расчете на одну частицу (440, см. подсчет в разделе \ref{push}) можно рассчитать производительность в единицах GFLOPS.

%\begin{table}[ht]
	
	\begin{center}
	%	\caption{Время вычислений,  в секундах, и производительность, GFLOPS.}
\captionof{table}{Время вычислений,  в секундах, и производительность, GFLOPS.}
\label{part_optim}	
\begin{tabular}{|c|c|c|c|c|c|}
\hline			

&& \multicolumn{2}{|c|}{Время} &	
   \multicolumn{2}{|c|}{Производительность}		\\		\cline{3-4} \cline{5-6}
№ &		 Вариант оптимизации                      & Phenom & Xeon  E5540  & Phenom & Xeon  E5540\\ \hline   	
1&Исходный                                          &        &            &        &            \\ 
 &неоптимизированный вариант                        & 13.25  & 7.22       &  0.369 & 0.67           \\ \hline  
2&Хранение значений поля                            &        &            &        &            \\
 & в 4-мерном массиве                               & 8.8    & 6.72       &  0.55  & 0.72       \\ \hline
3&Упорядочивание частиц                             &        &            &        &            \\ 
 & с помощью массивов номеров                       & 12.51  & 5.67       &  0.39  & 0.86           \\ \hline
4 &Упорядочивание частиц                             &        &           &        &            \\   
  & с помощью связанного списка                      & 10.5   & 10.3      &  0.46  & 0.475           \\ \hline
5 &                                                  &        &           &        &            \\
  &Сочетание вариантов 2 и 3			              & 10.92  & 3.67     &  0.44  & 1.33       \\ \hline 
		
\end{tabular}
\end{center}
%\end{table}			



Из таблицы \ref{part_optim} видно, что наибольшее сокращение времени вычислений получено при использованиии двух вариантов оптимизации:хранения значений поля в  4-мерном массиве, и упорядочивание частиц с помощью массивов номеров, причем эти два варианта являются независимыми. Таким образом, из таблицы \ref{part_optim} можно сделать вывод, что сочетание упорядочивания модельных частиц и хранения значений поля в одном 4-мерном массиве приводит к значительному сокращению времени вычислений с частицами, в данном случае, почти в 2 раза. Хранение частиц в виде связанных списков оказалось неэффективным для процессора Xeon  E5540, но, возможно, окажется полезным на других архитектурах (так позволяют думать измерения времени на процессоре Phenom)или в тех случаях, когда установить максимальное число частиц в ячейке невозможно.

Относительно небольшая доля от пиковой производительности, полученная в этих тестах, показывает значительную разницу между расчетом по методу частиц в ячейках, и например, методами решения линейных уравнений, которые являются наиболее распространенным тестом производительности ВС. Это подчеркивает необходиость отдельного тестирования также и на методе частиц в ячейках, и кроме того, подчеркивает важность также и проверки в рамках тестов не только производительности, но и скорости доступа к оперативной памяти, что будет предметом рассмотрения в одном из следующих разделов (раздел \ref{perfRAM}). 

Основная ценность этих экспериментов в том, что установлено влияние, которое способ организации частиц в памяти оказывает на производительность, а значит и на результаты работы создаеваемой программы-теста, например, какое влияние на результат тестирования может оказать более или менее эффективно работающий кэш: по результатам, показанным в таблице \ref{part_optim}, производительность может измениться н более чем в 1.5-2 раза.


\section{Расчет пропускной способности системы памяти}
\label{perfRAM}
В этом разделе описано измерение пропускной способности системы памяти, основанное на измерении времени расчета движения модельных частиц, при этом благодаря алгоритмически особенностям метода частиц в ячейках удается исключить использование кэш-памяти и производить измерение пропускной способности именно оперативной памяти. Основные характеристики высокопроизводительных вычислительных систем (называемых в данном случае в силу особенностей их архитектуры кластерами) приведены в таблице \ref{top50_2010}

\begin{table}[ht]
\caption{
Основные характеристики кластеров, на которых производились расчеты,рассмотренные в разделах \ref{perfRAM},\ref{calc_PE} и \ref{perfCommNet}, Номера даны по списку Top50 от 2009 года, В колонке TFLOPS указана пиковая производительность в терафлопсах.}
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|}
			\hline
			№                 & Название & Узлы               & Сеть                                   &  TFLOPS\\
		          \hline 
			1                & МВС-100К & 4xXeon E5450,      &  Infiniband 4x DDR/                    & 95.04 \\
			&          & 3 GHz              &  2xGigabit Ethernet/                   &       \\
			&          & 8.192 GB RAM       &  Gigabit Ethernet                      &    \\ \hline 
			2                 & СКИФ-МГУ & 2xXeon E5472,      & InfiniBand/                             & 60   \\
			&          &   3 GHz            & Gigabit Ethernet/                       &      \\
			&          &  8.192 GB RAM      & СКИФ-ServNet + IPMI                    &   \\ \hline 
			14                & СКИФ-Cyberia & 2xXeon 5150,   &  QLogic InfiniPath/                     & 12.002 \\
			&              &  2.667 GHz,    & Gigabit Ethernet/                       &   \\
			&           &     4.096 GB RAM  & СКИФ-ServNet                            & \\ \hline 
			20                & Кластер НГУ & 2xXeon 5355,    &  Infiniband 4x DDR/                    & 5.4 \\ 
			&           & 2.66 GHz          &   Gigabit Ethernet/                    &  \\
			&           &                   &   Gigabit Ethernet                     &  \\ \hline 
			
		\end{tabular}
	\end{center}

	\label{top50_2010}
\end{table}

Переход от фактически измеренной величины (времени выполнения расчета движения модельных частиц) к пропускной способности памяти выполнялся из следующих соображений: на каждое из используемых ядер приходится 2.5 млн. модельных частиц, каждая частица занимает 48 байт, кроме того, для расчета движения частицы необходимы значения электрического и магнитного полей в той ячейке сетки, где находится частица. Это означает, что для каждой из 6 компонент электромагнитного поля загружается 8 значений, соответствующих вершинам параллелепипеда, то есть ячейки сетки. 

Более того, по результатам расчета движения модельной частицы вычисляется вклад данной частицы в ток. Для каждой из трех компонент тока меняются значения в 4 узлах сетки компоненты тока, которые вместе с новыми значениями координаты и импульса модельной частицы сохраняются в оперативную память.

Таким образом для каждой модельной частицы загружается из памяти 432 байта и сохраняется 144 байта, общий поток данных составляет 576 байт на одну частицу.

В итоге, для вычисления пропускной способности памяти (в GB/sec) при расчете движения модельных частиц $W_{PIC,GB/sec}$ использовалась следующая формула:
\begin{equation}
W_{PIC,GB/sec} = \frac{W_P\times N_P \times P_{core}}{\Delta t}
\label{RAM_performance}
\end{equation}
здесь:
\begin{itemize}
	\item $W_P$ - количество байт на одну модельную частицу, $W_P = 576$;
	\item $N_P$ - количество модельных частиц на одно процессорное ядро (в рассмотренном случае $2.5\times 10^6$);  
	\item $P_{core}$ - количество процессорных ядер;
	\item $\Delta t$  - длительность временного шага, сек.
\end{itemize}	




\begin{figure}[htb]
	\begin{center}
		\includegraphics[height=7cm,keepaspectratio]{images/data_proc_throughput_GBsec.png}
	\end{center}
	\caption{Пропускная способность памяти на этапе расчета движения модельных частиц на некоторых кластерах. Количество модельных частиц: 2.5 млн. на каждое процессорное ядро. Основные параметры ВС, использованных в эксперименте, показаны в таблице \ref{top50_2010}.}
	\label{PIC_RAM}
\end{figure}
Следует отметить, что вопрос о сравнении чисел на рис. \ref{PIC_RAM} с заявленной максимальной пропускной способностью 
является второстепенным, тем не менее, сравнение показано в таблице \ref{PIC_vs_PROC_RAM}. Основной вопрос в данном случае - это измерение пропускной способности памяти,  фактически доступной для расчетного приложения.

Вывод, который можно сделать по таблице \ref{PIC_vs_PROC_RAM}: для реального расчетного приложения доступно не более половины заявленной максимальной пропускной способности оперативной памяти, причем даже этот показатель получен только лишь на ВВС СКИФ-МГУ <<Чебышев>>, в отношении которой проводилась специальная оптимизация взаимодействия процессоров с оперативной памятью.

\begin{table}[ht]
\caption{Сравнение пропускной способности памяти, измеренной с помощью теста на основе метода частиц с характеристиками процессора.}
\label{PIC_vs_PROC_RAM}
\begin{tabular}{|c|c|c|c|}
	\hline
             &            & \multicolumn{2}{|c|}{Пропускная способность памяти, GB/sec} \\ \cline{3-4}  	
Название ВС  & Процессор  & Данные теста PIC-MANAS & Максимум \\ \hline
СКИФ-Cyberia & Xeon 5150  &     1.53           & 10.6     \\ \hline
МВС-100К     & Xeon E5450 &     6.56           & 21       \\ \hline 
СКИФ-МГУ     & Xeon E5472 &     13.62          & 21       \\ \hline     
Кластер НГУ  & Xeon 5355  &     4.81           & 21       \\ \hline
\end{tabular}	
\end{table}

\section{Расчет производительности процессорных элементов}
\label{calc_PE}
В этом разделе описана методика измерения производительности процессорных элементов.
Для того, чтобы отделить время счета от времени обращения к оперативной памяти было рассмотрено время работы процедуры,
<<<<<<< HEAD
реализующей одномерное преобразование Фурье, которая является частью физической диагностики, используемой при моделировании динамики плазмы. Измеренное время с учетом известного размера данных и количества операций в БПФ \cite{FFT_OVS}, переводится во флопсы: размер массива для одномерного фурье-преобразования 64, количество операций, в соответствии с приведенным в статье \cite{FFT_OVS} 1190. Сравнительная производительность процессорных элементов некоторых из рассмотренных в диссертационной работе ВС выглядит как показано на рисунке  \ref{procs_flops}:
=======
реализующей одномерное преобразование Фурье, которая является частью физической диагностики, используемой в при моделировании динамики плазмы. Измеренное время с учетом известного размера данных и и количества операций в БПФ , переводится во флопсы (1 флопс - 1 операция с плавающей точкой в секунду). Сравнительная производительность процессорных элементов некоторых из рассмотренных в диссертационной работе ВС выглядит как показано на рисунке  \ref{procs_flops}:
>>>>>>> 38b5ee5beae1ddecf6326d2e98b09bf70a491a22

\begin{figure}[htb]
	\begin{center}
		\includegraphics[height=7cm,keepaspectratio]{images/processor_FLOPS.png}
	\end{center}
	\caption{Производительность процессоров Intel Xeon, измеренная в ходе выполнения одномерного преобразования Фурье на некоторых кластерах. Размерность преобразования $N=64$. Измерения выполнены в 2010 г.}
	\label{procs_flops}
\end{figure} 


\section{Расчет производительности процессорных элементов на основе движения модельных частиц}
\label{calc_PE}
 Сравнительная производительность процессорных элементов некоторых из рассмотренных в диссертационной работе ВС выглядит как показано на рисунке  \ref{procs_flops_pic}.  Сравнение производительности 
 на методе частиц в ячейках с производительностью на LU-разложении показано в таблице в таблице \ref{PIC_vs_LU}. Как видно из таблицы \ref{PIC_vs_LU} производительность отличается в 1.5-2 раза, что можно считать совпадением, учитывая сложности определения производительности процессоров с помощью нагрузочных тестов. 
   
\begin{figure}[htb]
	\begin{center}
		\includegraphics[height=7cm,keepaspectratio]{images/processor_FLOPS_PIC.png}
	\end{center}
	\caption{Производительность отдельного ядра процессоров Intel Xeon, измеренная на основе времени вычисления движения модельных частиц. Измерения выполнены в 2010 г.}
	\label{procs_flops_pic}
\end{figure} 

Расчет количества операций с плавающей точкой в секунду (FLOPS) при расчете движения модельных частиц $N_{PIC,FLOPS}$ производился следующим образом:
\begin{equation}
N_{PIC,FLOPS} = \frac{F_P\times N_P \times P_{core}}{\Delta t}
\label{PIC_FLOPS}
\end{equation}

здесь:
\begin{itemize}
	\item $F_P$ - количество операций на одну модельную частицу, $F_P = 440$;
	\item $N_P$ - количество модельных частиц на одно процессорное ядро (в рассмотренном случае $2.5\times 10^6$);  
	\item $P_{core}$ - количество ядер процессора;
	\item $\Delta t$  - длительность временного шага, сек.
\end{itemize}	

\begin{table}[ht]
	\caption{Производительность ядер процессоров Intel Xeon, измеренная на основе времени вычисления движения модельных частиц.}
	\label{PIC_vs_LU}
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		&            &            &             &       \multicolumn{2}{|c|}{Производительность, GFLOPS} \\ \cline{5-6}  	
		Название ВС  & Процессор  &  $\Delta t$ &$P_{core}$ & Данные теста  &  \\
		             &            &             &           & PIC-MANAS     & LU-разложение \\ \hline
		СКИФ-Cyberia & Xeon 5150  &  1.882      & 2     &  1.17          & 4.65    \\ \hline
		МВС-100К     & Xeon E5450 &  0.878      & 4     & 5.01           & 4.6     \\ \hline 
		СКИФ-МГУ     & Xeon E5472 &  0.423      & 4     & 10.41          & 2.37       \\ \hline     
		Кластер НГУ  & Xeon 5355  &  1.196      & 4     & 3.68           & 1.82       \\ \hline
	\end{tabular}	
\end{table}






\section{Расчет пропускной способности коммуникационной сети}
\label{perfCommNet}
Разработана методика измерения пропускной способности коммуникационной сети на основе анализа времени работы MPI-процедур, осуществляющих обмен граничными значениями между отдельными подобластями при решении уравнений Максвелла и при пересылке модельных частиц. В силу того, что при этом используются различные виды коммуникационных функций  - как блокирующие, так и не блокирующие, как парные, так и коллективные, при использовании эйлерово-лагранжевой декомпозиции - это позволяет набрать в течение одного расчета большую базу данных для получения знаний о структуре коммуникационной сети, времени прохождения сообщений в зависимости от размера, системных таймаутах и пр. 

В данном случае показан более простой и более ограниченный тест, полученный на основе измерения времени пересылки модельных частиц, перелетающих из одной подобласти в другую (эйлерова или эйлерово-лагранжева декомпозиция). Эмпирические факты таковы, что из подобласти в подобласть перелетает около 5 \% имеющихся частиц. В принципе, может перемещаться и больше, если выполняется моделирование плазменной турбулентности, приводящей к возникновению больших потоков вещества, в таком случае просто измеряется количество перемещенных частиц. Но это уже другая физическая постановка задачи.

Далее, количество частиц в данном расчете составляет 2.5 млн. на одно процессорное ядро, каждая частица занимает 48 байт (три координаты и три компоненты импульса в двойной точности), всего 114.4 Мб на ядро. Если перемещается около 5\%, то это 5.72 Мб в течение каждого временного шага в методе частиц в ячейках. В таблице \ref{tab_net_gb_sec} показано время работы процедуры, выполняющей передачу модельных частиц. Вычисленная на основе этого пропускная способность коммуникационной сети показана на рисунке \ref{plot_net_gb_sec} и также в таблице \ref{tab_net_gb_sec}.



Вычисление пропускной способности коммуникационной сети $W_S$ на основе данных о пересылке модельных частиц между  производится по следующией формуле:
\begin{equation}
W_S =  \nu \frac{U_P\times N_P \times P_{core}}{T_{S,PIC}}
\label{Net_performance_peer}
\end{equation}


здесь:
\begin{itemize}
	\item $\nu$ - доля пересылаемых частиц (напомним, что обычно $\nu \approx 0.05$);
	\item $U_P$ - количество байт на одну модельную частицу, $U_P = 48$;
	\item $N_P$ - количество модельных частиц на одно процессорное ядро (в рассмотренном случае $2.5\times 10^6$);  
	\item $P_{core}$ - количество ядер процессора;
	\item $T_{S,PIC}$  - время пересылки частиц, сек.
\end{itemize}	



\begin{figure}[htb]
	\begin{center}
		\includegraphics[height=7cm,keepaspectratio]{images/network_throughput_GB_sec.png}
	\end{center}
	\caption{Пропускная способность коммуникационной сети, измеренная на основе скорости пересылки модельных частиц. Измерения выполнены в 2010 г.}
	\label{plot_net_gb_sec}
\end{figure} 

Измеренные данные необходимо сравнивать с заявленными показателями оборудования. Так, пропускная способность сети Infiniband 4x составляла до 32.96 Гбит/с на 2010 г.,  а для Gigabit Ethernet - 10 Гбит/с. Сравнение показано в таблице  \ref{tab_net_gb_sec}. Из таблицы  \ref{tab_net_gb_sec} видно, что измеренные значения в целом совпадают с характеристиками коммуникационного оборудования. Для ВВС СКИФ-Cyberia по данным теста PIC-MANAS получилось даже больше. Это можно объяснить использованием на данной ВВС сетевой технологии СКИФ-ServNet. 

%\begin{table}[ht]
	\captionof{table}{Сравнение пропускной способности коммуникационной сети, измеренной с помощью теста на основе метода частиц (используются операции MPI\_Send/MPI\_Recv) с характеристиками оборудования.}
	\label{tab_net_gb_sec}
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		&                     &        &    \multicolumn{2}{|c|}{Производительность,} \\ 
		&                     & Время            &    \multicolumn{2}{|c|}{ГБ/сек.} \\ \cline{4-5}              
		Название ВС  & Сеть                & пересылки   & Данные теста       & Максимум  \\
		&                     & частиц, сек.&   PIC-MANAS        &           \\  \hline
		СКИФ-Cyberia &  QLogic InfiniPath/ &  0.007      &      3.42          & 1.25    \\ 
		&  Gigabit Ethernet/  &             &                    &          \\
		&  СКИФ-ServNet       &             &                    &          \\ \hline
		
		МВС-100К     &  Infiniband 4x DDR/ &  0.011           &     2.08      & 4       \\ 
		&  2xGigabit Ethernet/&             &                    &          \\
		&                     &             &                    &          \\ \hline  
		СКИФ-МГУ     & InfiniBand/         &  0.005           &     4.22      & 4       \\   
		&  Gigabit Ethernet/  &              &                    &          \\
		&  СКИФ-ServNet       &              &                    &          \\   
		&   + IPMI            &             &                     &          \\ \hline  
		Кластер НГУ  & Infiniband 4x DDR/  &  0.009        &     2.5          & 4       \\ 
		&   Gigabit Ethernet/ &           &                      &          \\
		&   Gigabit Ethernet  &           &                      &          \\ \hline
	\end{tabular}	
	%\end{table}


\clearpage

Тем не менее, поскольку не во всех случаях используется эйлерова декомпозиция (геометрическое разделение на подобласти), и соотвественно, измеряется время пересылки модельных частиц, наоборот, во многих случаях достаточно будет ограничится лагранжевой декомпозицией. Таким образом, необходимо иметь также вариант расчета пропускной способности коммуникационной сети на основе коллективных операций (MPI\_Allreduce).

В случае лагранжевой декомпозиции выполняется сложение трехмерных массивов тока, вычисленных каждым процессом по тем модельным частицам, которые принадлежат этому процессу. Таким образом пропускную способность коммуникационной сети при выполнении коллективных операций можно вычислять следующим образом:
\begin{equation}
W_A = \frac{1}{P_{SUB}}\frac{N_X\times N_Y \times N_Z \times 24}{T_A}
\label{Net_performance_collective}
\end{equation}

здесь:
\begin{itemize}
	\item $N_X, N_Y, N_Z$ - количество узлов сетки по X,Y и Z соответственно;
	\item $P_{SUB}$ - количество подобластей (если используется эйлерова декомпозиция)
	\item $T_{A}$ - длительность операции MPI\_Allreduce (суммирование токов по всей области), сек.
	\item множитель 24 появляется в силу того, что каждый элемент массива при двойной точности имеет размер 8, и таких массивов 3 (по одному для каждой из компонент тока).
\end{itemize}	

При использовании этой формулы для первого из расчетов, перечисленных в таблице \ref{modern_PIC_params}, можно получить 
$W_A = 1.117$ ГБ/сек., что закономерно меньше, чем число, полученное для этой же ВС (кластер НГУ) на основе парных пересылок
(таблица \ref{tab_net_gb_sec}).





%		На  рисунке приведено скорость обмена данными между процессами (график из статьи в Мб/сек) 
%		\textbf{перерисовать графики МВС-100К и Ломоносов в общей части}	
%		
%		
%		Сравнение графиков ускорения, полученных на МВС-100К, Ломоносов НГУ и пр.

\section{Оценка возможности выполнения крупномасштабных трехмерных расчетов}
\label{Big3D}

Целью расчетов,  является ответ на вопрос, какие расчеты (т.е. какой размерности) могут быть проведены на доступных высокопроизводительных  ВС (ВВС), на каком количестве процессоров (или процессорных ядер) и за какое время. 
Для того, чтобы получить ответ на этот вопрос, было запущено большое количество тестовых расчетов. Эти тестовые расчеты проводятся также с целью выяснения реальных возможностей ВВС для проведения физически содержательных расчетов. 	Расчеты проводились на следующих ВВС: кластер СпбПУ “Политехник”, кластер НКС-1П (ССКЦ СО РАН), кластер НГУ,  вычислительная система “Ломоносов” в  НИВЦ МГУ. 

Основные параметры использованных ВС перечислены в таблице \ref{top50_2018}. Для тех ВС в составе которых имеются различные типы процессоров, указаны те, которые реально использовались в расчетах. Также указана полная пиковая производительность ВС с учетом тех узлов, которые не использовались в данном случае.

\begin{table}[ht]
	\caption{
		Основные характеристики ВС, на которых производились расчеты, рассмотренные в разделе \ref{Big3D}. Номера даны по списку Top50 от 03.04.2018 года, В колонке TFLOPS указана пиковая производительность в терафлопсах.}
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|}
			\hline
			
			№ & Название       & Процессор                & Сеть                &  TFlOPS\\
			\hline 
			3 & <<Ломоносов>>  &  2xIntel Xeon 5570       &  Infiniband QDR/   &   1,700.21 \\
			&                &                          &  Gigabit Ethernet/ &            \\
			&                &                          &  Gigabit Ethernet  &            \\ \hline
			
			5 & <<Политехник>> & 2xIntel Xeon CPU E5-2697 &  Infiniband FDR/   &   1,015.10 \\
			&                & 3 GHz                    &  Gigabit Ethernet/ &            \\
			&                & 8.192 GB RAM             &  Gigabit Ethernet  &            \\ \hline
			
			38& НКС-1П         & 2xIntel Xeon E5-2697Av4  & OmniPath           & 91.24      \\
			&                 &                          & Gigabit Ethernet/  &            \\
			&                 &                          & Fast Ethernet      &            \\ \hline
			
			- & Кластер НГУ    & 2xIntel Xeon 5355,       &  Infiniband 4x DDR/& 5.4 \\ 
			&			       &                          &   Gigabit Ethernet/&  \\
			&			       &                          &   Gigabit Ethernet &  \\ \hline                    
			
		\end{tabular}
	\end{center}
	\label{top50_2018}
\end{table}


В ходе проведения тестовых расчетов было получено большое количество числовых характеристик – время расчета для различных сеток (таблица \ref{modern_PIC_params} ), продолжительность коммуникационных операций, эффективность в сильном и слабом смысле, причем все это как для лагранжевой, так и для эйлеровой и декомпозиции и для четырех различных ВВС. 

Кроме того, приведены основные параметры и числовые характеристики тестовых расчетов, обозначенные следующим образом:
\begin{itemize}
	\item $N_X, N_Y, N_Z$  - размер сетки по каждому из измерений
	\item $P_{ALL}$  - общее количество процессорных ядер
	\item $P_{SUB}$  - число подобластей
	\item $T$ – длительность тестового расчета (50 временных шагов), сек.
	\item $\Delta t$  - длительность временного шага, сек.
	\item $T_{A}$ - длительность операции MPI\_Allreduce (суммирование токов по всей области), сек.
	\item $T_{S,B}$ - длительность операции MPI\_Sendrecv (обмен граничными значениями), сек.
\end{itemize}


\begin{center}
\begin{table}[ht]
\caption{Время вычислений и время комуникаций в зависимости от числа  процессов.}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
			\hline			
			Кластер & $N_X$ & $N_Y$ & $N_Z$ &$P_{ALL}$  & $P_{SUB}$ & $T$ & $\Delta t$ & $T_{A}$ &  $T_{S,B}$ \\\hline
			НГУ     & 100   & 100   & 20    &  1        & 1         & 39.1  & 0.78 & 0.004         & 0         \\\hline
			НГУ     & 100   & 100   & 20    &  2        & 1         & 21.49 & 0.42 & 0.0029         & 0         \\\hline
			НГУ     & 100   & 100   & 20    &  2        & 2         & 40.37 & 0.8 & 0.097         & 0.022       \\\hline
			НГУ     & 100   & 100   & 20    &  4        & 1         & 9.9 & 0.19 & 0.0036         & 0           \\\hline
			НГУ     & 100   & 100   & 20    &  4        & 2         & 16.1 & 0.32 & 0.004         & 0.0094      \\\hline
			НГУ     & 100   & 100   & 20    &  10       & 1         & 6.7 & 0.13 & 0.0026         & 0           \\\hline
			НГУ     & 100   & 100   & 20    &  100      & 1         & 4.0   & 0.08 & 0.0059         & 0         \\ \hline
			НГУ     & 500   & 500   & 20    &  20       & 1         & 714.9 & 14.2 & 6.89         & 0           \\\hline
			<<Политехник>> & 100   & 100   & 20    &  4       & 2         & 13.8 & 0.27 & 0.0069  & 0.0035      \\\hline
			<<Политехник>> & 100   & 100   & 20    &  100     & 10        & 2.4 & 0.048 & 0.00223 & 0.001       \\\hline
			<<Политехник>> & 500   & 500   & 20    &  50       & 5        & 70.7 & 1.4 & 0.0014   & 0.006       \\\hline
			<<Политехник>> & 500   & 500   & 20    &  100       & 10      & 64.0 & 1.28 & 0.054   & 0.029       \\\hline
			<<Политехник>> & 500   & 500   & 20    &  200       & 20      & 70.2 & 1.4 & 0.096    & 0.009      \\\hline
			<<Ломоносов>> & 100   & 100   & 20    &  10       & 1         & 2.0 & 0.04 & 0.003    & 0           \\\hline
			<<Ломоносов>> & 100   & 100   & 20    &  100       & 1        & 2.5 & 0.05 & 0.005    & 0           \\\hline
			НКС-1П        & 100   & 100   & 20    &  100       & 1        & 28.9 & 0.57 & 0.0075  & 0           \\\hline
			НКС-1П        & 100   & 100   & 20    &  200       & 1        & 35.1 & 0.7 & 0.069    & 0           \\\hline
			
\end{tabular}
\label{modern_PIC_params}
\end{table}
\end{center}
	
	
\begin{figure}[htb]
	\begin{center}
		\includegraphics[height=10cm,keepaspectratio]{images/modern_PIC_params_FLOPS_new.png}
	\end{center}
	\caption{Расчет производительности процессоров на основе данных вычислительных экспериментов из таблицы \ref{modern_PIC_params}. }
	\label{xi_flops}
\end{figure} 
Относительно результатов, показанных на рис. \ref{xi_flops}, необходимо отметить, что они получены усреднением по большому количеству расчетов на каждом из кластеров. 

Объяснение тому, что кластер НГУ, оснащенный более старыми и номинально более слабыми процессорами, на рис. \ref{xi_flops} имеет более высокие показатели, чем кластер НКС-1П, заключается в том, что измерение времени движения модельных частиц для НКС-1П выполнено с недостаточной точностью.

\clearpage








\section{Формула для комплексной оценки ВС}
\label{complex_evaluation}
В данном разделе приведено обоснование формулы, на основании которой выносится оценка ВС по материалам проведенных тестов. При этом важно отметить, что оценка является не сравнительной - относительно других ВС, а абсолютной - с точки зрения математического моделирования. 

В частности, для того, чтобы параллельная ВС могла быть признана адаптированной к задачам математического моделирования, она должна соответствовать следующим требованиям:
\begin{enumerate}
	\item Очень высокая производительность коммуникационной сети ($W_S$, формула \ref{Net_performance_peer} и $W_A$, формула \ref{Net_performance_collective} ), позволяющая пересылать все необходимые для расчета данные, не задерживая вычислений;
	
	\item Относительно высокая производительность оперативной памяти ($W_{PIC,GB/sec}$, формула \ref{RAM_performance}), позволяющая эффективно использовать ресурсы процессоров, т.е. фактически совпадающая с производительностью процессора.  	
\end{enumerate}

Важно отметить, что названы относительные показатели, обеспечивающие возможность пересылать данные, без ущерба для скорости вычислений. Именно это и означает  комплексную пригодность ВС к решению задач математического моделирования.

В случае использования эйлеро-лагранжевой декомпозиции, т.е. если определены обе величины $W_S$ и $W_A$, будем использовать усредненную величину
\begin{equation}
W_{MPI} = \frac{W_S + W_A}{2}
\end{equation}
в случае только лишь эйлеровой или только лагранжевой декомпозиции, $W_{MPI}$ равна соотвественно, $W_S$ или $W_A$

В итоге предлагается формула оценки $\xi$ в виде:
\begin{equation}
\xi = \frac{W_{MPI}} { W_{PIC,GB/sec}}, 
\label{complex_rating}
\end{equation}
Комплекснная оценка ВС, вычисленная по формуле \ref{complex_rating}
на материале расчетов, показанных в таблице \ref{modern_PIC_params}
показана на рисунке \ref{xi}

\begin{figure}[htb]
	\begin{center}
		\includegraphics[height=7cm,keepaspectratio]{images/modern_PIC_params_xi_new.png}
	\end{center}
	\caption{Критерий комплексной оценки пригодности ВС для решения задач математического моделирования.}
	\label{xi}
\end{figure} 
Данный критерий, напомним, выражает степень сбалансированности производительности процессоров ВС и коммуникационной системы. Поэтому он может быть низким для некоторых ВС, стоящих высоко в рейтинге Top50 или построенных на основе быстрых современных процессоров (как кластер СПбПУ <<Политехник>>).

Дополнительно приведем два переводных множителя, позволяющих оценивать соответствие описанных выше пропускных способностей памяти и коммуникационной подсистемы ВС и вычислительной призводительности процессоров. Дя этого нужен множитель для перевода флопсов в байты в секунду.

Коэффициент перевода из флопсов в байты в секунду для расчетов с частицами равен
%\begin{center}
\begin{equation}
\label{kf2b}
k_{f2b} = 440/576 = 0.86
\end{equation}  
 
и коээфициент для перевода объема данных, сохраняемых на диск к объему данных, пересылаемых по коммуникационной сети, аналогично, для частиц равен (усредненно):
$k_{MPI} = 0.05$ 
Это объясняется тем, что в среднем не более 5\% частиц пересылается между подобластями.




\section{Сравнение с известными тестами производительности}

\subsection{Тест HPL}

\subsubsection{Краткое описание теста HPL}
Тест HPL (High Performance Linpack) - это многопроцессорный вариант широко известного теста Linpack. В свою очередь Linpack - это набор вычислений с использованием матричного умножения, который масштабирует размер массивов, чтобы попытаться создать максимально возможную нагрузку для вычислительной системы и таким образом достичь максимальной производительности на всех процессорных элементах в кластере. Общепринятый подход заключался в том, что вначале в рамках теста Linpack решалась система линейных уравнений с плотной матрицей размером $ 100 \times 100$, затем по мере роста производительности размерность была увеличена до $1000 \times 1000$, когда машины становились более мощными.

В рамках настоящей диссертационной работы также было проведено тестирование некоторых из рассматриваемых ВС с помощью теста HPL, который является частью пакета Intel Parallel Studio. 

\begin{table}[ht]
\caption{Производительность на тесте HPL, размер матрицы 4000}
\begin{center}
\begin{tabular}{|c|c|}
	\hline
	Название ВС                & GFLOPS \\ \hline
кластер СПбПУ <<Политехник>>   &  4.34125 	          \\  
кластер ССКЦ СО РАН <<НКС-1П>> &  3.14126 	      \\ \hline
\end{tabular}
\end{center}
\label{}
\end{table}

Как видно, производительность получается значительно меньше, чем при расчете движения модельных частиц в тесте PIC-MANAS. Объяснение этому заключается  в том, что  подбор правильной конфигурации для теста Linpack, адекватно показывающий производительность рассматриваемой ВС представляет собой отдельную сложную задачу. Также важно отметить, что результаты теста PIC-MANAS в значительно меньшей степени зависят от конфигурации запуска в силу того, что в ходе выполнения вычилений по методу частиц в ячейках происходит многократное усреднение всех показателей.



\subsection{Актуальность создания нового теста для определения производительности ВВС}
Необходимость создания нового теста (а именно, HPCG) для ранжирования ВВС его авторы формулируют следующим образом, \cite{HerouxHPCG}. В данном случае имеет смысл привести длинную цитату по той причине, что диссертационная работа также посвящена созданию нового теста для ВВС, и для вновь создаваемого теста PIC-MANAS актуальны все те же самые соображения.

Итак, тест HPCG:
<<1.Обеспечивает охват основных коммуникационных и вычислительных моделей:
основные виды коммуникаций (глобальные и локальные коллективные коммуникации) и вычислительные модели
(векторные сложения, точечные произведения, умножения разреженных матриц на вектора и локальные решение систем линейных уравнений с треугольными матрицами), присутствующие в наших кодах для решения дифференциальных уравнений с использованием как явных, так и неявных методов,
присутствуют в этом тесте. Возникающие асинхронные коллективные коммуникации и другие операции со скрытой латентностью методы могут быть изучены в контексте HPCG, и таким образом будет внесен вклад в оптимизацию будущих вычислительных систем.

2. Представляет собой минимальный набор основных вычислительных моделей: HPCG является наименьшим
эталонным кодом, содержащим эти основные шаблоны, и в то же время представляющий собой
реальные математические вычисления.

3. Показывает результаты повышения эффективности коллективных операций, зависящих от пропускной способности внутренней сети ВС. Определение соседства и редукция представляют собой существенные затруднения для многих приложений. Таким образом, повышение производительности на тесте HPCG будет
имеет серьезную корреляцию с улучшением производительность наших реальных приложений.

4. Показывает результаты повышения эффективности локальной памяти: производительность процессора
на тесте HPCG во многом определяется эффективным использованием локальной памяти.
Усовершенствования в реализации структур данных HPCG, компиляции кода HPCG
и производительности системы в целом улучшит базовый уровень результатов HPCG
в вместе с этим производительность реальных приложений, а также проинформирует разработчиков приложений о новых подходах к оптимизации.

5. Обнаруживает и измеряет отклонения от побитового совпадения результатов вычислений.
Существует опасение, что будущие компьютерные системы не смогут обеспечить детерминированное исполнение
 вычислений с плавающей точкой. Поскольку сложение с плавающей точкой не является ассоциативным,
это означает, что мы, как правило, не будем иметь побитовые воспроизводимые результаты, даже при повторном исполнении на том же числе процессоров одной и той же системы.
Это важное отличие от многих приложений MPI сегодня, и представляет большой
вызов для приложений, которые должны сертифицировать свои вычислительные результаты. В тесте  HPCG нарушение побитовой воспроизводимости очевидно.>>

Легко заметить, что высказанные авторами теста HPCG соображения во многом похожи на содержание раздела <<Актуальность>> во введении настоящей работы. Важное отличие теста PIC-MANAS от HPCG заключается в том, что тест PIC-MANAS позволяет четко определять, какая именно из подсистем ВС (память, коммуникационная подсистема, процессоры) оказывает основное влияние на снижение производительности, а не просто в целом реагирует на оптимизацию их работы, как описано выше в пунктах 3 и 4.

\subsection{Тест HPCG}
Тест HPCG представляет собой предобусловленный метод сопряженных градиентов
(англ., Preconditioned Conjugate Gradient, PCG) с локальным симметричным предобуславливателем Гаусса-Зейделя, реализованный на C ++ 2 с использованием MPI и OpenMP. 

HPCG (High Performance Conjugate Gradient) \cite{Dongarra2016HighperformanceCB} - это сравнительно новый тест производительности высокопроизводительных вычислительных систем, претендующий на более адекватное по сравнению с наиболее часто используемым тестом HPL.

Определенные соображения по поводу того, почему HPCG может заменить HPL при составлении рейтинга высокопроизводительных вычислительных систем, были высказаны в статье \cite{HPCGreplaceHPL}. Они заключаются в следующем. Тесты, выполняемые на ВВС должны позволять произвести сравнительное ранжирование систем с точки зрения производительности по различным архитектурам и пакетам программного обеспечения, и давать некоторое представление о производительности относительно финансовых и временных затрат для разных систем, чтобы пользователи могли взвешивать относительную экономическую целесообразность вычислительных систем, которые могут запускать конкретное приложение. К сожалению, выполняемы на высокопроизводительных ВС тесты, в основном делают первое, и редко делают второе. 

Автор теста HPCG Джек Донгарра говорит \cite{Dongarra2016HighperformanceCB}, что проблемы с текущими рейтингами на основе LinPack (или, что то же самое, HPL) в том, что они уже не так сильно коррелируют с реальной производительностью приложений, особенно для приложений, предназначенных для работы на ВВС. В частности речь идет о приложениях на основе решения дифференциальных уравнений, которые нуждаются в гораздо более высокой пропускной способности и низкой латентности, и имеют все более нерегулярный доступа к данным. Таким образом, проектирование ВВС на основе HPL может привести к плохой производительности для реальных приложений или добавлению ненужной сложности в систему.


 
\subsubsection{Результаты тестирования кластера СПбПУ <<Политехник>> на тесте HPCG}

В рамках настоящей диссертационной работы также было проведено тестирование некоторых из рассматриваемых ВС с помощью теста HPCG, который является частью пакета Intel Parallel Studio. 


Были получены следующие результаты (с высокой указанной в отчетном файле погрешностью):
\begin{itemize}
\item Для операции DDOT (скалярное произведение в двойной точности): 1237.46 GFLOPS
\item Для операции WAXPBY (сложение векторов с множителем): 10.766 GFLOPS
\item Для операции SpMV (умножение разреженной матрицы на вектор): 13.0012  GFLOPS
\item Для операции MG (трехуровневый многосеточный метод): 13.8033 GFLOPS.
\end{itemize}

Отметим значительную разницу с результатами теста HPL, что позволяет еще раз сделать вывод о необходимости разработки нового комплексного теста производительности ВС.
