@article{Keyes201170,
title = ыExaflop/s: The why and the how ы,
journal = ыComptes Rendus Mécanique ы,
volume = ы339ы,
number = ы2–3ы,
pages = ы70 - 77ы,
year = ы2011ы,
note = ыHigh Performance ComputingLe Calcul Intensif ы,
issn = ы1631-0721ы,
doi = ыhttp://dx.doi.org/10.1016/j.crme.2010.11.002ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S1631072110002032ы,
author = ыDavid E. Keyesы,
keywords = ыComputer scienceы,
keywords = ыExaflop-clésы,
keywords = ыInformatiqueы,
keywords = ыalgorithmiqueы,
keywords = ыExaflop ы,
abstract = ыThe best paths to the exascale summit are debatable, but all are narrow and treacherous, constrained by fundamental laws of physics, capital cost, operating cost, power requirements, programmability, and reliability. Many scientific and engineering applications force the modeling community to attempt to scale this summit. Drawing on vendor projections and experiences with scientific codes on contemporary platforms, we outline the challenges and propose roles and essential adaptations for mathematical modelers in one of the great global scientific quests the next decade. ы
}

@article{Murugan2013,
title = ыOn the interconnect energy efficiency of high end computing systems ы,
journal = ыSustainable Computing: Informatics and Systems ы,
volume = ы3ы,
number = ы2ы,
pages = ы49 - 57ы,
year = ы2013ы,
note = ыы,
issn = ы2210-5379ы,
doi = ыhttp://dx.doi.org/10.1016/j.suscom.2012.03.002ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S2210537912000194ы,
author = ыMuthukumar Murugan and David Hung Chang Du and Krishna Kantы,
keywords = ыGreen HPCы,
keywords = ыInterconnectы,
keywords = ыEnergy efficiencyы,
keywords = ыHPC schedulingы,
keywords = ыExtensible bin packing ы,
abstract = ыHigh performance computing systems are moving towards the exaflops era. The tremendous increase in computational speed is accompanied by enormous power consumption in these systems. It is necessary to harvest any potential opportunities to save power in these high end computing systems. The goal of this paper is to explore possibilities of power savings in the interconnects between the nodes. By careful scheduling of jobs in a 3D torus-connected cluster of nodes, we show that significant amounts of power can be saved by switching certain portions of the network elements to low power modes. We also present an estimation method that more accurately estimates the actual runtime of jobs from the user provided runtimes and enhances the performance of the scheduling scheme. We validate our results via detailed \{MATLAB\} simulations. ы
}

@article{Attig2011,
title = ыTrends in supercomputing: The European path to exascale ы,
journal = ыComputer Physics Communications ы,
volume = ы182ы,
number = ы9ы,
pages = ы2041 - 2046ы,
year = ы2011ы,
note = ыComputer Physics Communications Special Edition for Conference on Computational Physics Trondheim, Norway, June 23-26, 2010 ы,
issn = ы0010-4655ы,
doi = ыhttp://dx.doi.org/10.1016/j.cpc.2010.11.011ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0010465510004571ы,
author = ыN. Attig and P. Gibbon and Th. Lippertы,
keywords = ыSupercomputingы,
keywords = ыExascaleы,
keywords = ыSimulation Laboratory ы,
abstract = ыRecent developments in European supercomputing are reviewed covering both the latest hardware trends and the increasing difficulties faced by scientists in utilising these machines to perform large-scale numerical simulations. These challenges are reflected in the large number of international initiatives which have come into being over the last few years, founded in anticipation of exascale hardware which is foreseen within the next decade. The role of a key institution in supercomputing within these programmes is described using the example of the Jülich Supercomputing Centre (JSC), and progress in setting up its own community-oriented support units for scientific computing – Simulation Laboratories – is reported on. Finally, an assessment is made of some common grand challenges and their suitability for scaling to exaflop-scale computation. ы
}

@article{Attig2009,
title = ыComputational physics with PetaFlops computers ы,
journal = ыComputer Physics Communications ы,
volume = ы180ы,
number = ы4ы,
pages = ы555 - 558ы,
year = ы2009ы,
note = ыSpecial issue based on the Conference on Computational Physics 2008CCP 2008 ы,
issn = ы0010-4655ы,
doi = ыhttp://dx.doi.org/10.1016/j.cpc.2008.12.032ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0010465508004499ы,
author = ыNorbert Attigы,
keywords = ыSupercomputingы,
keywords = ыIBM Blue Geneы,
keywords = ыCPMD ы,
abstract = ыDriven by technology, Scientific Computing is rapidly entering the PetaFlops era. The Jülich Supercomputing Centre (JSC), one of three German national supercomputing centres, is focusing on the \{IBM\} Blue Gene architecture to provide computer resources of this class to its users, the majority of whom are computational physicists. Details of the system will be discussed and applications will be described which significantly benefit from this new architecture. ы
}

@article{Yavits2014,
title = ыThe effect of communication and synchronization on Amdahl’s law in multicore systems ы,
journal = ыParallel Computing ы,
volume = ы40ы,
number = ы1ы,
pages = ы1 - 16ы,
year = ы2014ы,
note = ыы,
issn = ы0167-8191ы,
doi = ыhttp://dx.doi.org/10.1016/j.parco.2013.11.001ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0167819113001324ы,
author = ыL. Yavits and A. Morad and R. Ginosarы,
keywords = ыMulticoreы,
keywords = ыAnalytical Performance Modelsы,
keywords = ыAmdahl’s law ы,
abstract = ыAbstract This work analyses the effects of sequential-to-parallel synchronization and inter-core communication on multicore performance, speedup and scaling from Amdahl’s law perspective. Analytical modeling supported by simulation leads to a modification of Amdahl’s law, reflecting lower than originally predicted speedup, due to these effects. In applications with high degree of data sharing, leading to intense inter-core connectivity requirements, the workload should be executed on a smaller number of larger cores. Applications requiring intense sequential-to-parallel synchronization, even highly parallelizable ones, may better be executed by the sequential core. To improve the scalability and performance speedup of a multicore, it is as important to address the synchronization and connectivity intensities of parallel algorithms as their parallelization factor. ы
}

@article{Peterson1989,
title = ыComputational challenges in aerospace ы,
journal = ыFuture Generation Computer Systems ы,
volume = ы5ы,
number = ы2–3ы,
pages = ы243 - 258ы,
year = ы1989ы,
note = ыGrand Challenges to Computational Science ы,
issn = ы0167-739Xы,
doi = ыhttp://dx.doi.org/10.1016/0167-739X(89)90044-7ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/0167739X89900447ы,
author = ыVictor L. Petersonы,
abstract = ыComputer speed and memory requirements needed for meeting various computational challenges in human vision modeling, chemistry, turbulence physics research and aerodynamics are discussed and compared with the capabilities of various existing computers and those projected to be available before the mid 1990s. Example results for problems illustrative of those currently being solved in each of the disciplines are also presented. Meeting some of the challenges using currently available solution algorithms is shown to require computer speeds in excess of exaFLOPs (1018 FLOPs) and memories in excess of petawords (1015 words), if problems are to be solved in periods of time currently believed to be acceptable. Even without these levels of computer power, it is shown how work can proceed towards meeting the ultimate challenges by treating stepping-stone problems with complexity increasing to match the computational power available at any point in time. Finally, it is speculated that improvements in algorithms ultimately will reduce these requirements to levels that can be met with computers projected to be available beyond the year 2000. ы
}

@article{Schreiber2014,
title = ыA few bad ideas on the way to the triumph of parallel computing ы,
journal = ыJournal of Parallel and Distributed Computing ы,
volume = ы74ы,
number = ы7ы,
pages = ы2544 - 2547ы,
year = ы2014ы,
note = ыSpecial Issue on Perspectives on Parallel and Distributed Processing ы,
issn = ы0743-7315ы,
doi = ыhttp://dx.doi.org/10.1016/j.jpdc.2013.10.006ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0743731513002177ы,
author = ыRobert Schreiberы,
keywords = ыParallelismы,
keywords = ыAmdahlы,
keywords = ыAutomatic parallelizationы,
keywords = ыAcceleratorsы,
keywords = ыExascale ы,
abstract = ыAbstract Parallelism has become mainstream, in the multicore chip, the GPU, and the internet datacenter running MapReduce. In my field, large-scale scientific computing, parallelism now reigns triumphant. It was no simple, direct route that led to this triumph. Along the way, we were confused by ideas that, in retrospect, turned out to be distractions and errors. The thinking behind them was reasonable, but wrong. One can learn from a dissection of mistakes, so I will retell part of the story here. ы
}

@article{Mittal20161065,
title = ыComputational modeling of cardiac hemodynamics: Current status and future outlook ы,
journal = ыJournal of Computational Physics ы,
volume = ы305ы,
number = ыы,
pages = ы1065 - 1082ы,
year = ы2016ы,
note = ыы,
issn = ы0021-9991ы,
doi = ыhttp://dx.doi.org/10.1016/j.jcp.2015.11.022ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0021999115007627ы,
author = ыRajat Mittal and Jung Hee Seo and Vijay Vedula and Young J. Choi and Hang Liu and H. Howie Huang and Saurabh Jain and Laurent Younes and Theodore Abraham and Richard T. Georgeы,
keywords = ыHemodynamicsы,
keywords = ыComputational fluid dynamicsы,
keywords = ыCardiac physicsы,
keywords = ыBlood flowы,
keywords = ыCardiovascular diseaseы,
keywords = ыHeart diseaseы,
keywords = ыCardiac surgeryы,
keywords = ыLeft ventricular thrombosisы,
keywords = ыHeart murmursы,
keywords = ыCardiac auscultationы,
keywords = ыImage segmentationы,
keywords = ыImmersed boundary methods ы,
abstract = ыAbstract The proliferation of four-dimensional imaging technologies, increasing computational speeds, improved simulation algorithms, and the widespread availability of powerful computing platforms is enabling simulations of cardiac hemodynamics with unprecedented speed and fidelity. Since cardiovascular disease is intimately linked to cardiovascular hemodynamics, accurate assessment of the patient's hemodynamic state is critical for the diagnosis and treatment of heart disease. Unfortunately, while a variety of invasive and non-invasive approaches for measuring cardiac hemodynamics are in widespread use, they still only provide an incomplete picture of the hemodynamic state of a patient. In this context, computational modeling of cardiac hemodynamics presents as a powerful non-invasive modality that can fill this information gap, and significantly impact the diagnosis as well as the treatment of cardiac disease. This article reviews the current status of this field as well as the emerging trends and challenges in cardiovascular health, computing, modeling and simulation and that are expected to play a key role in its future development. Some recent advances in modeling and simulations of cardiac flow are described by using examples from our own work as well as the research of other groups. ы
}

@article{Lim2015128,
title = ыTechnological forecasting of supercomputer development: The March to Exascale computing ы,
journal = ыOmega ы,
volume = ы51ы,
number = ыы,
pages = ы128 - 135ы,
year = ы2015ы,
note = ыы,
issn = ы0305-0483ы,
doi = ыhttp://dx.doi.org/10.1016/j.omega.2014.09.009ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0305048314001200ы,
author = ыDong-Joon Lim and Timothy R. Anderson and Tom Shottы,
keywords = ыData envelopment analysisы,
keywords = ыTechnological forecastingы,
keywords = ыState of the artы,
keywords = ыRate of changeы,
keywords = ыSupercomputer ы,
abstract = ыAbstract Advances in supercomputers have come at a steady pace over the past 20 years. The next milestone is to build an Exascale computer however this requires not only speed improvement but also significant enhancements for energy efficiency and massive parallelism. This paper examines technological progress of supercomputer development to identify the innovative potential of three leading technology paths toward Exascale development: hybrid system, multicore system and manycore system. Performance measurement and rate of change calculation were made by technology forecasting using data envelopment analysis (TFDEA.) The results indicate that the current level of technology and rate of progress can achieve Exascale performance between early 2021 and late 2022 as either hybrid systems or manycore systems. ы
}

@incollection{Onishi2014,
title = ыOptimized preprocessing of tens of billions of grids in a full-vehicle aerodynamic simulation on the K-computer ы,
editor = ыPark, Holywell ы,
booktitle = ыThe International Vehicle Aerodynamics Conference ы,
publisher = ыWoodhead Publishingы,
edition = ыы,
address = ыOxfordы,
year = ы2014ы,
pages = ы149 - 158ы,
isbn = ы978-0-08-100199-8ы,
doi = ыhttp://dx.doi.org/10.1533/9780081002452.4.149ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/B9780081001998500137ы,
author = ыK. Onishi and M. Tsubokuraы,
abstract = ы\{ABSTRACT\} A vehicle aerodynamics simulation was conducted using 2.3 billion elements of an unstructured grid and 19 billion elements of a Cartesian grid with dirty computeraided-design data on the supercomputer K-computer. This methodology allows the user to avoid a large amount of manual work in preparing computational grids was developed using a mesh refinement technique and immersed boundary method. This methodology was indispensable in conducting fine-resolution analysis in a massively parallel environment. The calculation results show that the method was successfully adopted for full-vehicle aerodynamics and that the accuracy of drag prediction can be improved using fine grid resolution. ы
}

@article{Xu2015200,
title = ыEngineering molecular dynamics simulation in chemical engineering ы,
journal = ыChemical Engineering Science ы,
volume = ы121ы,
number = ыы,
pages = ы200 - 216ы,
year = ы2015ы,
note = ы2013 Danckwerts Special Issue on Molecular Modelling in Chemical Engineering ы,
issn = ы0009-2509ы,
doi = ыhttp://dx.doi.org/10.1016/j.ces.2014.09.051ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0009250914005557ы,
author = ыJi Xu and Xiaoxia Li and Chaofeng Hou and Limin Wang and Guangzheng Zhou and Wei Ge and Jinghai Liы,
keywords = ыEngineering \{MD\} simulationы,
keywords = ыChemical processesы,
keywords = ыMeso-scaleы,
keywords = ыMultiscaleы,
keywords = ыEMMS paradigmы,
keywords = ыParticle methods ы,
abstract = ыAbstract Chemical engineering systems usually involve multiple spatio-temporal scales, grouped into different levels, from the molecular scale of reactants to the industrial scale of reactors. Molecular dynamics (MD) simulation is one of the most fundamental methods for the study of such systems, but it is too costly and hence formidable for simulating large-scale behavior directly. However, there are two great potentials in extending this method. First, the logic and algorithms of traditional \{MD\} simulations can be generalized from the material level to higher levels since the elements of each level are all discrete in nature, and can be well defined, allowing an MD-style simulation based on different elements. Second, \{MD\} simulations can be accelerated by realizing the structural consistency among the problem, model, software and hardware (the so-called \{EMMS\} paradigm). These two potentials give possibilities to engineer the method of \{MD\} simulation to deal with the whole spectrum of chemical engineering phenomena. In this review, we summarize our discrete simulation studies to explore such potentials, from the establishment of a general software and hardware framework, to the typical applications at different levels, including the reactions in coal pyrolysis, the dynamics in virion, the atomic behavior in silicon at millimeter scale, and finally continuum flow. The possibility of engineering \{MD\} simulation into a virtual experiment platform is discussed finally. ы
}

@article{Rajovic2014322,
title = ыTibidabo1: Making the case for an ARM-based \{HPC\} system ы,
journal = ыFuture Generation Computer Systems ы,
volume = ы36ы,
number = ыы,
pages = ы322 - 334ы,
year = ы2014ы,
note = ыSpecial Section: Intelligent Big Data ProcessingSpecial Section: Behavior Data Security Issues in Network Information PropagationSpecial Section: Energy-efficiency in Large Distributed Computing ArchitecturesSpecial Section: eScience Infrastructure and Applications ы,
issn = ы0167-739Xы,
doi = ыhttp://dx.doi.org/10.1016/j.future.2013.07.013ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0167739X13001581ы,
author = ыNikola Rajovic and Alejandro Rico and Nikola Puzovic and Chris Adeniyi-Jones and Alex Ramirezы,
keywords = ыHigh-performance computingы,
keywords = ыEmbedded processorsы,
keywords = ыMobile processorsы,
keywords = ыLow powerы,
keywords = ыCortex-A9ы,
keywords = ыCortex-A15ы,
keywords = ыEnergy efficiency ы,
abstract = ыAbstract It is widely accepted that future \{HPC\} systems will be limited by their power consumption. Current \{HPC\} systems are built from commodity server processors, designed over years to achieve maximum performance, with energy efficiency being an after-thought. In this paper we advocate a different approach: building \{HPC\} systems from low-power embedded and mobile technology parts, over time designed for maximum energy efficiency, which now show promise for competitive performance. We introduce the architecture of Tibidabo, the first large-scale \{HPC\} cluster built from \{ARM\} multicore chips, and a detailed performance and energy efficiency evaluation. We present the lessons learned for the design and improvement in energy efficiency of future \{HPC\} systems based on such low-power cores. Based on our experience with the prototype, we perform simulations to show that a theoretical cluster of 16-core \{ARM\} Cortex-A15 chips would increase the energy efficiency of our cluster by 8.7×, reaching an energy efficiency of 1046 MFLOPS/W. ы
}

@article{Straatsma2013,
title = ыOn eliminating synchronous communication in molecular simulations to improve scalability ы,
journal = ыComputer Physics Communications ы,
volume = ы184ы,
number = ы12ы,
pages = ы2634 - 2640ы,
year = ы2013ы,
note = ыы,
issn = ы0010-4655ы,
doi = ыhttp://dx.doi.org/10.1016/j.cpc.2013.01.009ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S001046551300026Xы,
author = ыT.P. Straatsma and Daniel G. Chavarría-Mirandaы,
keywords = ыOne-sided communicationы,
keywords = ыGlobal arraysы,
keywords = ыMolecular dynamics ы,
abstract = ыMolecular dynamics simulation, as a complementary tool to experimentation, has become an important methodology for the understanding and design of molecular systems as it provides access to properties that are difficult, impossible or prohibitively expensive to obtain experimentally. Many of the available software packages have been parallelized to take advantage of modern massively concurrent processing resources. The challenge in achieving parallel efficiency is commonly attributed to the fact that molecular dynamics algorithms are communication intensive. This paper illustrates how an appropriately chosen data distribution and asynchronous one-sided communication approach can be used to effectively deal with the data movement within the Global Arrays/ARMCI programming model framework. A new put_notify capability is presented here, allowing the implementation of the molecular dynamics algorithm without any explicit global or local synchronization or global data reduction operations. In addition, this push-data model is shown to very effectively allow hiding data communication behind computation. Rather than data movement or explicit global reductions, the implicit synchronization of the algorithm becomes the primary challenge for scalability. Without any explicit synchronous operations, the scalability of molecular simulations is shown to depend only on the ability to evenly balance computational load. ы
}

@article{Decyk2011,
title = ыAdaptable Particle-in-Cell algorithms for graphical processing units ы,
journal = ыComputer Physics Communications ы,
volume = ы182ы,
number = ы3ы,
pages = ы641 - 648ы,
year = ы2011ы,
note = ыы,
issn = ы0010-4655ы,
doi = ыhttp://dx.doi.org/10.1016/j.cpc.2010.11.009ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0010465510004558ы,
author = ыViktor K. Decyk and Tajendra V. Singhы,
keywords = ыParticle-in-Cellы,
keywords = ыGPUы,
keywords = ыParallel algorithms ы,
abstract = ыWe developed new parameterized Particle-in-Cell algorithms and data structures for emerging multi-core and many-core architectures. Four parameters allow tuning of this \{PIC\} code to different hardware configurations. Particles are kept ordered at each time step. The first application of these algorithms is to \{NVIDIA\} graphical processing units, where speedups of about 15–25 compared to an Intel Nehalem processor were obtained for a simple 2D electrostatic code. Electromagnetic codes are expected to get higher speedups due to their greater computational intensity. ы
}

@article{Decyk2014,
title = ыParticle-in-Cell algorithms for emerging computer architectures ы,
journal = ыComputer Physics Communications ы,
volume = ы185ы,
number = ы3ы,
pages = ы708 - 719ы,
year = ы2014ы,
note = ыы,
issn = ы0010-4655ы,
doi = ыhttp://dx.doi.org/10.1016/j.cpc.2013.10.013ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S001046551300341Xы,
author = ыViktor K. Decyk and Tajendra V. Singhы,
keywords = ыParallel algorithmsы,
keywords = ыParticle-in-Cellы,
keywords = ыGPUы,
keywords = ыCUDAы,
keywords = ыPlasma simulation ы,
abstract = ыAbstract We have designed Particle-in-Cell algorithms for emerging architectures. These algorithms share a common approach, using fine-grained tiles, but different implementations depending on the architecture. On the GPU, there were two different implementations, one with atomic operations and one with no data collisions, using \{CUDA\} C and Fortran. Speedups up to about 50 compared to a single core of the Intel i7 processor have been achieved. There was also an implementation for traditional multi-core processors using OpenMP which achieved high parallel efficiency. We believe that this approach should work for other emerging designs such as Intel Phi coprocessor from the Intel \{MIC\} architecture. ы
}

@article{Stantchev20081339,
title = ыFast parallel Particle-To-Grid interpolation for plasma \{PIC\} simulations on the \{GPU\} ы,
journal = ыJournal of Parallel and Distributed Computing ы,
volume = ы68ы,
number = ы10ы,
pages = ы1339 - 1349ы,
year = ы2008ы,
note = ыGeneral-Purpose Processing using Graphics Processing Units ы,
issn = ы0743-7315ы,
doi = ыhttp://dx.doi.org/10.1016/j.jpdc.2008.05.009ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0743731508000944ы,
author = ыGeorge Stantchev and William Dorland and Nail Gumerovы,
keywords = ы\{GPU\} computingы,
keywords = ыScientific computingы,
keywords = ыParallel algorithmsы,
keywords = ыNumerical simulationsы,
keywords = ыParticle-In-cell methodsы,
keywords = ыPlasma physics ы,
abstract = ыParticle-In-Cell (PIC) methods have been widely used for plasma physics simulations in the past three decades. To ensure an acceptable level of statistical accuracy relatively large numbers of particles are needed. State-of-the-art Graphics Processing Units (GPUs), with their high memory bandwidth, hundreds of \{SPMD\} processors, and half-a-teraflop performance potential, offer a viable alternative to distributed memory parallel computers for running medium-scale \{PIC\} plasma simulations on inexpensive commodity hardware. In this paper, we present an overview of a typical plasma \{PIC\} code and discuss its \{GPU\} implementation. In particular we focus on fast algorithms for the performance bottleneck operation of Particle-To-Grid interpolation. ы
}

@article{Kong2011,
title = ыParticle-in-cell simulations with charge-conserving current deposition on graphic processing units ы,
journal = ыJournal of Computational Physics ы,
volume = ы230ы,
number = ы4ы,
pages = ы1676 - 1685ы,
year = ы2011ы,
note = ыы,
issn = ы0021-9991ы,
doi = ыhttp://dx.doi.org/10.1016/j.jcp.2010.11.032ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0021999110006479ы,
author = ыXianglong Kong and Michael C. Huang and Chuang Ren and Viktor K. Decykы,
keywords = ыGraphics processing unit (GPU)ы,
keywords = ыComputer unified device architecture (CUDA)ы,
keywords = ыParticle-in-cell (PIC) plasma simulation ы,
abstract = ыWe present an implementation of a 2D fully relativistic, electromagnetic particle-in-cell code, with charge-conserving current deposition, on parallel graphics processors (GPU) with CUDA. The \{GPU\} implementation achieved a one particle-step process time of 2.52 ns for cold plasma runs and 9.15 ns for extremely relativistic plasma runs, which are respectively 81 and 27 times faster than a single threaded state-of-art \{CPU\} code. A particle-based computation thread assignment was used in the current deposition scheme and write conflicts among the threads were resolved by a thread racing technique. A parallel particle sorting scheme was also developed and used. The implementation took advantage of fast on-chip shared memory, and can in principle be extended to 3D. ы
}

@article{Trefethen2013,
title = ыEnergy-aware software: Challenges, opportunities and strategies ы,
journal = ыJournal of Computational Science ы,
volume = ы4ы,
number = ы6ы,
pages = ы444 - 449ы,
year = ы2013ы,
note = ыScalable Algorithms for Large-Scale Systems Workshop (ScalA2011), Supercomputing 2011 ы,
issn = ы1877-7503ы,
doi = ыhttp://dx.doi.org/10.1016/j.jocs.2013.01.005ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S1877750313000173ы,
author = ыAnne E. Trefethen and Jeyarajan Thiyagalingamы,
abstract = ыEnergy consumption of computing systems has become a major concern. Constrained by cost, environmental concerns and policy, minimising the energy foot-print of computing systems is one of the primary goals of many initiatives. As we move towards exascale computing, energy constraints become very real and are a major driver in design decisions. The issue is also apparent at the scale of desk top machines, where many core and accelerator chips are common and offer a spectrum of opportunities for balancing energy and performance. Conventionally, approaches for reducing energy consumption have been either at the operational level (such as powering down all or part of systems) or at the hardware design level (such as utilising specialised low-energy components). In this paper, we are interested in a different approach; energy-aware software. By measuring the energy consumption of a computer application and understanding where the energy usage lies, may allow a change of the software to provide opportunities for energy savings. In order to understand the complexities of this approach, we specifically look at multithreaded algorithms and applications. By an evaluation of a benchmark suite on multiple architectures and multiple environments, we show how basic parameters, such as threading options, compilers and frequencies, can impact energy consumption. As such, we provide an overview of the challenges that face software developers in this regard. We then offer a view of the directions that need to be taken and possible strategies needed for building energy-aware software. ы
}

@article{Gicquel2012782,
title = ыLarge Eddy Simulations of gaseous flames in gas turbine combustion chambers ы,
journal = ыProgress in Energy and Combustion Science ы,
volume = ы38ы,
number = ы6ы,
pages = ы782 - 817ы,
year = ы2012ы,
note = ыы,
issn = ы0360-1285ы,
doi = ыhttp://dx.doi.org/10.1016/j.pecs.2012.04.004ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0360128512000366ы,
author = ыL.Y.M. Gicquel and G. Staffelbach and T. Poinsotы,
keywords = ыLarge Eddy Simulationsы,
keywords = ыComplex geometryы,
keywords = ыSwirled flowsы,
keywords = ыGaseous combustionы,
keywords = ыTurbulent combustionы,
keywords = ыGas turbine ы,
abstract = ыRecent developments in numerical schemes, turbulent combustion models and the regular increase of computing power allow Large Eddy Simulation (LES) to be applied to real industrial burners. In this paper, two types of \{LES\} in complex geometry combustors and of specific interest for aeronautical gas turbine burners are reviewed: (1) laboratory-scale combustors, without compressor or turbine, in which advanced measurements are possible and (2) combustion chambers of existing engines operated in realistic operating conditions. Laboratory-scale burners are designed to assess modeling and fundamental flow aspects in controlled configurations. They are necessary to gauge \{LES\} strategies and identify potential limitations. In specific circumstances, they even offer near model-free or DNS-like \{LES\} computations. \{LES\} in real engines illustrate the potential of the approach in the context of industrial burners but are more difficult to validate due to the limited set of available measurements. Usual approaches for turbulence and combustion sub-grid models including chemistry modeling are first recalled. Limiting cases and range of validity of the models are specifically recalled before a discussion on the numerical breakthrough which have allowed \{LES\} to be applied to these complex cases. Specific issues linked to real gas turbine chambers are discussed: multi-perforation, complex acoustic impedances at inlet and outlet, annular chambers…. Examples are provided for mean flow predictions (velocity, temperature and species) as well as unsteady mechanisms (quenching, ignition, combustion instabilities). Finally, potential perspectives are proposed to further improve the use of \{LES\} for real gas turbine combustor designs. ы
}

@article{Subotić2013,
title = ыProgrammability and portability for exascale: Top down programming methodology and tools with StarSs ы,
journal = ыJournal of Computational Science ы,
volume = ы4ы,
number = ы6ы,
pages = ы450 - 456ы,
year = ы2013ы,
note = ыScalable Algorithms for Large-Scale Systems Workshop (ScalA2011), Supercomputing 2011 ы,
issn = ы1877-7503ы,
doi = ыhttp://dx.doi.org/10.1016/j.jocs.2013.01.008ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S1877750313000203ы,
author = ыVladimir Subotić and Steffen Brinkmann and Vladimir Marjanović and Rosa M. Badia and Jose Gracia and Christoph Niethammer and Eduard Ayguade and Jesus Labarta and Mateo Valeroы,
keywords = ыParallel programming modelsы,
keywords = ыPerformance analysis toolsы,
keywords = ыDevelopment tools ы,
abstract = ыStarSs is a task-based programming model that allows to parallelize sequential applications by means of annotating the code with compiler directives. The model further supports transparent execution of designated tasks on heterogeneous platforms, including clusters of GPUs. This paper focuses on the methodology and tools that complements the programming model forming a consistent development environment with the objective of simplifying the live of application developers. The programming environment includes the tools \{TAREADOR\} and TEMANEJO, which have been designed specifically for StarSs. TAREADOR, a Valgrind-based tool, allows a top-down development approach by assisting the programmer in identifying tasks and their data-dependencies across all concurrency levels of an application. \{TEMANEJO\} is a graphical debugger supporting the programmer by visualizing the task dependency tree on one hand, but also allowing to manipulate task scheduling or dependencies. These tools are complemented with a set of performance analysis tools (Scalasca, Cube and Paraver) that enable to fine tune StarSs application. ы
}

@article{Dongarra2015,
title = ыHPC Programming on Intel Many-Integrated-Core Hardware with MAGMA Port to Xeon Phiы,
journal = ыScientific Programmingы,
volume = ы2015ы,
year = ы2015ы,
author = ыJack Dongarra Mark Gates Azzam Haidar Yulu Jia Khairul Kabir Piotr Luszczek and Stanimire Tomovы,
}

@article{Reed2015,
title = ыExascale Computing and Big Dataы,
journal = ыCommunications of the ACMы,
volume = ы58ы,
number = ы7ы,
pages = ы56-68ы,
year = ы2015ы,
author = ыReed, Daniel A., and Dongarra J.ы,
}

@article{Vázquez2016,
title = ыAlya: Multiphysics engineering simulation toward exascale ы,
journal = ыJournal of Computational Science ы,
volume = ыы,
number = ыы,
pages = ы - ы,
year = ы2016ы,
note = ыы,
issn = ы1877-7503ы,
doi = ыhttp://dx.doi.org/10.1016/j.jocs.2015.12.007ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S1877750315300521ы,
author = ыMariano Vázquez and Guillaume Houzeaux and Seid Koric and Antoni Artigues and Jazmin Aguado-Sierra and Ruth Arís and Daniel Mira and Hadrien Calmet and Fernando Cucchietti and Herbert Owen and Ahmed Taha and Evan Dering Burness and José María Cela and Mateo Valeroы,
keywords = ыMulti-physics couplingы,
keywords = ыParallelizationы,
keywords = ыComputational mechanics ы,
abstract = ыAbstract Alya is a multi-physics simulation code developed at Barcelona Supercomputing Center (BSC). From its inception Alya code is designed using advanced High Performance Computing programming techniques to solve coupled problems on supercomputers efficiently. The target domain is engineering, with all its particular features: complex geometries and unstructured meshes, coupled multi-physics with exotic coupling schemes and physical models, ill-posed problems, flexibility needs for rapidly including new models, etc. Since its beginnings in 2004, Alya has scaled well in an increasing number of processors when solving single-physics problems such as fluid mechanics, solid mechanics, acoustics, etc. Over time, we have made a concerted effort to maintain and even improve scalability for multi-physics problems. This poses challenges on multiple fronts, including: numerical models, parallel implementation, physical coupling models, algorithms and solution schemes, meshing process, etc. In this paper, we introduce Alya's main features and focus particularly on its solvers. We present Alya's performance up to 100.000 processors in Blue Waters, the \{NCSA\} supercomputer with selected multi-physics tests that are representative of the engineering world. The tests are incompressible flow in a human respiratory system, low Mach combustion problem in a kiln furnace, and coupled electro-mechanical contraction of the heart. We show scalability plots for all cases and discuss all aspects of such simulations, including solver convergence. ы
}

@article{Engelmann2014,
title = ыScaling to a million cores and beyond: Using light-weight simulation to understand the challenges ahead on the road to exascale ы,
journal = ыFuture Generation Computer Systems ы,
volume = ы30ы,
number = ыы,
pages = ы59 - 65ы,
year = ы2014ы,
note = ыSpecial Issue on Extreme Scale Parallel Architectures and Systems, Cryptography in Cloud Computing and Recent Advances in Parallel and Distributed Systems, \{ICPADS\} 2012 Selected Papers ы,
issn = ы0167-739Xы,
doi = ыhttp://dx.doi.org/10.1016/j.future.2013.04.014ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0167739X13000745ы,
author = ыChristian Engelmannы,
keywords = ыParallel discrete event simulationы,
keywords = ыMessage passing interfaceы,
keywords = ыCollective communicationы,
keywords = ыHigh performance computingы,
keywords = ыExascale ы,
abstract = ыAbstract As supercomputers scale to 1000 PFlop/s over the next decade, investigating the performance of parallel applications at scale on future architectures and the performance impact of different architecture choices for high-performance computing (HPC) hardware/software co-design is crucial. This paper summarizes recent efforts in designing and implementing a novel \{HPC\} hardware/software co-design toolkit. The presented Extreme-scale Simulator (xSim) permits running an \{HPC\} application in a controlled environment with millions of concurrent execution threads while observing its performance in a simulated extreme-scale \{HPC\} system using architectural models and virtual timing. This paper demonstrates the capabilities and usefulness of the xSim performance investigation toolkit, such as its scalability to 227 simulated Message Passing Interface (MPI) ranks on 960 real processor cores, the capability to evaluate the performance of different \{MPI\} collective communication algorithms, and the ability to evaluate the performance of a basic Monte Carlo application with different architectural parameters. ы
}

@article{Dosanjh2014,
title = ыExascale design space exploration and co-design ы,
journal = ыFuture Generation Computer Systems ы,
volume = ы30ы,
number = ыы,
pages = ы46 - 58ы,
year = ы2014ы,
note = ыSpecial Issue on Extreme Scale Parallel Architectures and Systems, Cryptography in Cloud Computing and Recent Advances in Parallel and Distributed Systems, \{ICPADS\} 2012 Selected Papers ы,
issn = ы0167-739Xы,
doi = ыhttp://dx.doi.org/10.1016/j.future.2013.04.018ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0167739X13000782ы,
author = ыS.S. Dosanjh and R.F. Barrett and D.W. Doerfler and S.D. Hammond and K.S. Hemmert and M.A. Heroux and P.T. Lin and K.T. Pedretti and A.F. Rodrigues and T.G. Trucano and J.P. Luitjensы,
keywords = ыHigh performance computingы,
keywords = ыScientific computingы,
keywords = ыCo-designы,
keywords = ыExascale preparation ы,
abstract = ыAbstract The co-design of architectures and algorithms has been postulated as a strategy for achieving Exascale computing in this decade. Exascale design space exploration is prohibitively expensive, at least partially due to the size and complexity of scientific applications of interest. Application codes can contain millions of lines and involve many libraries. Mini-applications, which attempt to capture some key performance issues, can potentially reduce the order of the exploration by a factor of a thousand. However, we need to carefully understand how representative mini-applications are of the full application code. This paper describes a methodology for this comparison and applies it to a particularly challenging mini-application. A multi-faceted methodology for design space exploration is also described that includes measurements on advanced architecture testbeds, experiments that use supercomputers and system software to emulate future hardware, and hardware/software co-simulation tools to predict the behavior of applications on hardware that does not yet exist. ы
}

@article{Norman2015,
title = ыDeveloping A Large Time Step, Robust, and Low Communication Multi-Moment \{PDE\} Integration Scheme for Exascale Applications ы,
journal = ыProcedia Computer Science ы,
volume = ы51ы,
number = ыы,
pages = ы1848 - 1857ы,
year = ы2015ы,
note = ыInternational Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature ы,
issn = ы1877-0509ы,
doi = ыhttp://dx.doi.org/10.1016/j.procs.2015.05.413ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S1877050915012211ы,
author = ыMatthew R. Normanы,
keywords = ыMCVы,
keywords = ыMulti-momentы,
keywords = ыFinite-volumeы,
keywords = ыADERы,
keywords = ыTransport ы,
abstract = ыAbstract The Boundary Averaged Multi-moment Constrained finite-Volume (BA-MCV) method is de- rived, explained, and evaluated for 1-D transport to assess accuracy, maximum stable time step (MSTS), oscillations for discontinuous data, and parallel communication burden. The BA-MCV scheme is altered from the original \{MCV\} scheme to compute the updates of point wise cell boundary derivatives entirely locally. Then it is altered such that boundary moments are replaced with the interface upwind value. The scheme is stable at a maximum stable \{CFL\} (MSCFL) value of one no matter how high-order the scheme is, giving significantly larger time steps than Galerkin methods, for which the \{MSCFL\} decreases nearly quadratically with in- creasing order. The BA-MCV method is compared against a \{SE\} method at varying order, both using the ADER-DT time discretization. BA-MCV error for a sine wave was comparable to the same order of accuracy for a \{SE\} method. The resulting large time step, multi-moment, low communication scheme is of great interest for exascale architectures. ы
}

@incollection{Talia2016,
title = ыChapter 5 - Research Trends in Big Data Analysis ы,
editor = ыMarozzo, Domenico TaliaPaolo TrunfioFabrizio ы,
booktitle = ыData Analysis in the Cloud ы,
publisher = ыElsevierы,
edition = ыы,
address = ыBostonы,
year = ы2016ы,
pages = ы123 - 138ы,
series = ыComputer Science Reviews and Trendsы,
isbn = ы978-0-12-802881-0ы,
doi = ыhttp://dx.doi.org/10.1016/B978-0-12-802881-0.00005-6ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/B9780128028810000056ы,
author = ыDomenico Talia and Paolo Trunfio and Fabrizio Marozzoы,
keywords = ыData-intensive exascale computingы,
keywords = ыmanycore systemsы,
keywords = ыexascale computingы,
keywords = ыsocial network analysisы,
keywords = ыurban computingы,
keywords = ыtrajectory miningы,
keywords = ыresearch trendsы,
keywords = ыin-memory data analysis ы,
abstract = ыAbstract Big data analysis is a very active research area with significant impact on industrial and scientific domains where is important to analyze very large and complex data repositories. In particular, in many cases data to be analyzed are stored in cloud platforms and elastic computing clouds facilities are exploited to speedup the analysis. This chapter outlines and discusses main research trends in big data analytics and cloud systems for managing and mining large-scale data repositories. Topics and trends in the areas of exascale computing and social data analysis are reported. Section 5.1 discusses issues and challenges for implementing massively parallel and/or distributed applications in the area of big data analysis on exascale systems. Section 5.2 discusses recent trends in social data analysis, with a focus on mining mobility patterns from large volumes of trajectory data from online social network data. Finally, Section 5.3 discusses key research areas for the implementation of scalable data analytics dealing with huge, distributed data sources. ы
}

@article{Zounmevo2014,
title = ыA fast and resource-conscious \{MPI\} message queue mechanism for large-scale jobs ы,
journal = ыFuture Generation Computer Systems ы,
volume = ы30ы,
number = ыы,
pages = ы265 - 290ы,
year = ы2014ы,
note = ыSpecial Issue on Extreme Scale Parallel Architectures and Systems, Cryptography in Cloud Computing and Recent Advances in Parallel and Distributed Systems, \{ICPADS\} 2012 Selected Papers ы,
issn = ы0167-739Xы,
doi = ыhttp://dx.doi.org/10.1016/j.future.2013.07.003ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0167739X13001489ы,
author = ыJudicael A. Zounmevo and Ahmad Afsahiы,
keywords = ыMPIы,
keywords = ыMessage queuesы,
keywords = ыMultidimensional searchesы,
keywords = ыScalabilityы,
keywords = ыExascale ы,
abstract = ыAbstract The Message Passing Interface (MPI) message queues have been shown to grow proportionately to the job size for many applications. With such a behaviour and knowing that message queues are used very frequently, ensuring fast queue operations at large scales is of paramount importance in the current and the upcoming exascale computing eras. Scalability, however, is two-fold. With the growing processor core density per node, and the expected smaller memory density per core at larger scales, a queue mechanism that is blind on memory requirements poses another scalability issue even if it solves the speed of operation problem. In this work we propose a multidimensional queue management mechanism whose operation time and memory overhead grow sub-linearly with the job size. We show why a novel approach is justified in spite of the existence of well-known and fast data structures such as binary search trees. We compare our proposal with a linked list-based approach which is not scalable in terms of speed of operation, and with an array-based method which is not scalable in terms of memory consumption. Our proposed multidimensional approach yields queue operation time speedups that translate to up to 4-fold execution time improvement over the linked list design for the applications studied in this work. It also shows a consistent lower memory footprint compared to the array-based design. Finally, compared to the linked list-based queue, our proposed design yields cache miss rate improvements which are on average on par with the array-based design. ы
}

@article{Mosby201668,
title = ыComputational homogenization at extreme scales ы,
journal = ыExtreme Mechanics Letters ы,
volume = ы6ы,
number = ыы,
pages = ы68 - 74ы,
year = ы2016ы,
note = ыы,
issn = ы2352-4316ы,
doi = ыhttp://dx.doi.org/10.1016/j.eml.2015.12.009ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S2352431615300134ы,
author = ыMatthew Mosby and Karel Matoušы,
keywords = ыComputational homogenizationы,
keywords = ыHigh-performance computingы,
keywords = ыExtreme scale computingы,
keywords = ыHeterogeneous interfacesы,
keywords = ыMulti-scale interfacial damage modeling ы,
abstract = ыAbstract Multi-scale simulations at extreme scales in terms of both physical length scales and computational resources are presented. In this letter, we introduce a hierarchically parallel computational homogenization solver that employs hundreds of thousands of computing cores and resolves O ( 10 5 ) in material length scales (from O ( cm ) to O ( 100 nm ) ). Simulations of this kind are important in understanding the multi-scale essence of many natural and synthetically made materials. Thus, we present a simulation consisting of 53.8 Billion finite elements with 28.1 Billion nonlinear equations that is solved on 393,216 computing cores (786,432 threads). The excellent parallel performance of the computational homogenization solver is demonstrated by a strong scaling test from 4,096 to 262,144 cores. A fully coupled multi-scale damage simulation shows a complex crack profile at the micro-scale and the macroscopic crack tunneling phenomenon. Such large and predictive simulations are an important step towards Virtual Materials Testing and can aid in development of new material formulations with extreme properties. Furthermore, the high computational efficiency of our computational homogenization solver holds great promise for utilizing the next generation of exascale parallel computing platforms that are expected to accelerate computations through orders of magnitude increase in parallelism rather than speed of each processor. ы
}

@article{Nakashima201581,
title = ыManycore challenge in particle-in-cell simulation: How to exploit 1 \{TFlops\} peak performance for simulation codes with irregular computation ы,
journal = ыComputers & Electrical Engineering ы,
volume = ы46ы,
number = ыы,
pages = ы81 - 94ы,
year = ы2015ы,
note = ыы,
issn = ы0045-7906ы,
doi = ыhttp://dx.doi.org/10.1016/j.compeleceng.2015.03.010ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S004579061500097Xы,
author = ыHiroshi Nakashimaы,
keywords = ыManycore processorsы,
keywords = ыSIMD-vectorizationы,
keywords = ыMultithreadingы,
keywords = ыParticle-in-cell simulationы,
keywords = ыHigh-performance computing ы,
abstract = ыAbstract This paper discusses the challenge in post-Peta and Exascale era especially that brought by manycore processors of ordinary (i.e., non-GPU type) \{CPU\} cores. Though such a processor like Intel Xeon Phi gives us TFlops-class computational power and may lead us to Exascale computing, full exploitation of its potential is far from an easy job due to its source of high performance, namely a large scale multithreading and a wide \{SIMD\} mechanism. In fact, in the three-tier parallelism namely inter-node, intra-node and intra-core ones, we found their order does not represent the toughness in \{HPC\} programming but the order should be reversed to do that. Our case study with a particle-in-cell plasma simulation code supports our observation revealing that a simple porting of an existing code to Xeon Phi is infeasible from the viewpoint of performance and we have to make a significant change of the code structure so that it conforms with the features of the processor. However the study also confirms that the recoding effort is well rewarded achieving a good single-node performance higher than that obtained from an execution on four dual-socket nodes of Cray XE6. ы
}

@article{Yu2015,
title = ыQuantitative modeling of power performance tradeoffs on extreme scale systems ы,
journal = ыJournal of Parallel and Distributed Computing ы,
volume = ы84ы,
number = ыы,
pages = ы1 - 14ы,
year = ы2015ы,
note = ыы,
issn = ы0743-7315ы,
doi = ыhttp://dx.doi.org/10.1016/j.jpdc.2015.06.006ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0743731515001045ы,
author = ыLi Yu and Zhou Zhou and Sean Wallace and Michael E. Papka and Zhiling Lanы,
keywords = ыHigh performance computingы,
keywords = ыPower performance analysisы,
keywords = ыColored Petri netы,
keywords = ыExtreme scale systemsы,
keywords = ыPower capping ы,
abstract = ыAbstract As high performance computing (HPC) continues to grow in scale and complexity, energy becomes a critical constraint in the race to exascale computing. The days of “performance at all cost” are coming to an end. While performance is still a major objective, future \{HPC\} will have to deliver desired performance under the energy constraint. Among various power management methods, power capping is a widely used approach. Unfortunately, the impact of power capping on system performance, user jobs, and power-performance efficiency are not well studied due to many interfering factors imposed by system workload and configurations. To fully understand power management in extreme scale systems with a fixed power budget, we introduce a power-performance modeling tool named PuPPET (Power Performance \{PETri\} net). Unlike the traditional performance modeling approaches such as analytical methods or trace-based simulators, we explore a new approach–colored Petri nets–for the design of PuPPET. PuPPET is fast and extensible for navigating through different configurations. More importantly, it can scale to hundreds of thousands of processor cores and at the same time provide high levels of modeling accuracy. We validate PuPPET by using system traces (i.e., workload log and power data) collected from the production 48-rack \{IBM\} Blue Gene/Q supercomputer at Argonne National Laboratory. Our trace-based validation demonstrates that PuPPET is capable of modeling the dynamic execution of parallel jobs on the machine by providing an accurate approximation of energy consumption. In addition, we present two case studies of using PuPPET to study power-performance tradeoffs on petascale systems. ы
}

@article{Sitaraman2016,
title = ыBalancing conflicting requirements for grid and particle decomposition in continuum-Lagrangian solvers ы,
journal = ыParallel Computing ы,
volume = ы52ы,
number = ыы,
pages = ы1 - 21ы,
year = ы2016ы,
note = ыы,
issn = ы0167-8191ы,
doi = ыhttp://dx.doi.org/10.1016/j.parco.2015.10.010ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0167819115001428ы,
author = ыHariswaran Sitaraman and Ray Groutы,
keywords = ыLoad balancingы,
keywords = ыLagrangian particle trackingы,
keywords = ыParticle in cellы,
keywords = ыExascale simulations ы,
abstract = ыAbstract Load balancing strategies for hybrid solvers that involve grid based partial differential equation solution coupled with particle tracking are presented in this paper. A typical Message Passing Interface (MPI) based parallelization of grid based solves are done using a spatial domain decomposition while particle tracking is primarily done using either of the two techniques. One of the techniques is to distribute the particles to \{MPI\} ranks to whose grid they belong to while the other is to share the particles equally among all ranks, irrespective of their spatial location. The former technique provides spatial locality for field interpolation but cannot assure load balance in terms of number of particles, which is achieved by the latter. The two techniques are compared for a case of particle tracking in a homogeneous isotropic turbulence box as well as a turbulent jet case. A strong scaling study is performed to more than 32,000 cores, which results in particle densities representative of anticipated exascale machines. The use of alternative implementations of \{MPI\} collectives and efficient load equalization strategies are studied to reduce data communication overheads. ы
}

@article{Wuyts2015,
title = ыHelsim: A Particle-in-cell Simulator for Highly Imbalanced Particle Distributions ы,
journal = ыProcedia Computer Science ы,
volume = ы51ы,
number = ыы,
pages = ы2923 - 2927ы,
year = ы2015ы,
note = ыInternational Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature ы,
issn = ы1877-0509ы,
doi = ыhttp://dx.doi.org/10.1016/j.procs.2015.05.479ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S1877050915012879ы,
author = ыRoel Wuyts and Tom Haber and Giovanni Lapentaы,
keywords = ыParticle-in-cellы,
keywords = ыComputational Scienceы,
keywords = ыHigh Performance Computing ы,
abstract = ыAbstract Helsim is a 3D electro-magnetic particle-in-cell simulator used to simulate the behaviour of plasma in space. Particle-in-cell simulators track the movement of particles through space, with the particles generating and being subjected to various fields (electric, magnetic and or gravitational). Helsim dissociates the particles data structure from the fields, allowing them to be distributed and load- balanced independently and can simulate experiments with highly im-balanced particle distributions with ease. This paper shows weak scaling results of a highly im-balanced particle setup on up to 32 thousand cores. The results validate the basic claims for scal-ability for imbalanced particle distributions, but also highlights a problem with a workaround we had to implement to circumvent an OpenMPI bug we encountered. ы
}

@article{Tucker2016,
title = ыEddy resolving simulations in aerospace – Invited paper (Numerical Fluid 2014) ы,
journal = ыApplied Mathematics and Computation ы,
volume = ы272, Part 3ы,
number = ыы,
pages = ы582 - 592ы,
year = ы2016ы,
note = ыThe 9th International Symposium on Numerical Analysis of Fluid Flow and Heat Transfer - Numerical Fluids 2014 ы,
issn = ы0096-3003ы,
doi = ыhttp://dx.doi.org/10.1016/j.amc.2015.02.018ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S009630031500171Xы,
author = ыPaul G. Tucker and James C. Tyackeы,
keywords = ыLESы,
keywords = ыDESы,
keywords = ыTurbulenceы,
keywords = ыAerospaceы,
keywords = ыNumerical methods ы,
abstract = ыAbstract The future use of eddy resolving simulations (ERS) such as Large Eddy Simulation (LES), Direct Numerical Simulation (DNS) and related approaches in aerospace is explored. The turbulence modeling requirements with respect to aeroengines and aircraft is contrasted. For the latter, higher Reynolds numbers are more prevalent and this especially gives rise to the need for the hybridization of \{ERS\} methods with Reynolds Averaged Navier–Stokes (RANS) approaches. Zones where future use of pure \{ERS\} methods is now possible and those where hybridizations with \{RANS\} will be needed is outlined. The major focus is the aeroengine for which the component scales are much smaller. This gives rise to generally more benign Reynolds numbers. The use of eddy resolving methods in a wide range of zones in an aeroengine is discussed and the potential benefits and also cost drawbacks with such approaches noted. The tension when using such computationally intensive calculations in an area where the coupling of components and even the airframe and engine is becoming increasingly important is explored. Also, the numerical methods and meshing requirements are considered and the implications of \{ERS\} methods for future numerical algorithms. It is postulated that such simulations are ready now for niche uses in industry. However, to perform the scale of simulations that industry requires, to meet pressing environmental needs, challenges remain. For example, there is the need to develop optimal numerical methods that both map to the accuracy requirements for \{ERS\} and also future computer architectures. ы
}

@article{Collins2015,
title = ыProgress in Fast, Accurate Multi-scale Climate Simulations ы,
journal = ыProcedia Computer Science ы,
volume = ы51ы,
number = ыы,
pages = ы2006 - 2015ы,
year = ы2015ы,
note = ыInternational Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature ы,
issn = ы1877-0509ы,
doi = ыhttp://dx.doi.org/10.1016/j.procs.2015.05.465ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S1877050915012739ы,
author = ыW.D. Collins and H. Johansen and K.J. Evans and C.S. Woodward and P.M. Caldwellы,
keywords = ыEarth system modelsы,
keywords = ыMulti-scale climateы,
keywords = ыTime integrationы,
keywords = ыMany-core ы,
abstract = ыAbstract We present a survey of physical and computational techniques that have the potential to contribute to the next generation of high-fidelity, multi-scale climate simulations. Examples of the climate science problems that can be investigated with more depth with these computational improvements include the capture of remote forcings of localized hydrological extreme events, an accurate representation of cloud features over a range of spatial and temporal scales, and parallel, large ensembles of simulations to more effectively explore model sensitivities and un- certainties. Numerical techniques, such as adaptive mesh refinement, implicit time integration, and separate treatment of fast physical time scales are enabling improved accuracy and fidelity in simulation of dynamics and allowing more complete representations of climate features at the global scale. At the same time, partnerships with computer science teams have focused on taking advantage of evolving computer architectures such as many-core processors and GPUs. As a result, approaches which were previously considered prohibitively costly have become both more efficient and scalable. In combination, progress in these three critical areas is poised to transform climate modeling in the coming decades. These topics have been presented within a workshop titled, “Numerical and Computational Developments to Advance Multiscale Earth System Models (MSESM ‘15),” as part of the International Conference on Computational Sciences, Reykjavik, Iceland, June 1-3, 2015. ы
}

@article{Löhner201353,
title = ыHandling tens of thousands of cores with industrial/legacy codes: Approaches, implementation and timings ы,
journal = ыComputers & Fluids ы,
volume = ы85ы,
number = ыы,
pages = ы53 - 62ы,
year = ы2013ы,
note = ыInternational Workshop on Future of \{CFD\} and Aerospace Sciences ы,
issn = ы0045-7930ы,
doi = ыhttp://dx.doi.org/10.1016/j.compfluid.2012.09.030ы,
url = ыhttp://www.sciencedirect.com/science/article/pii/S0045793012004112ы,
author = ыRainald Löhner and Joseph D. Baumы,
keywords = ыMassive parallelismы,
keywords = ыOpenMPы,
keywords = ыMPIы,
keywords = ыGPUsы,
keywords = ыCFD ы,
abstract = ыAbstract The consequences that the recent stagnation in clockrates for \{CPUs\} has had on large-scale \{CFD\} runs are examined. At first sight, the conclusion is that only massive parallelism at the loop or domain decomposition level will lead to higher \{FLOP\} counts. However, the significant differences in advances for CPUs/GPUs versus \{RAM\} and interprocessor communication bandwidth lead to a so-called ‘limiting domain size’, below which communication dominates execution times and performance degrades drastically. The consequences of this ‘red-shift’ for the future of \{CFD\} are manifold: the time to advance the solution one timestep is limited, implying that even with unlimited number of processors/cores, LES, \{DES\} and \{DNS\} runs for realistic Reynolds-numbers will require days or weeks of execution. ы
}
























