% This file was created with JabRef 2.10b2.
% Encoding: UTF-8

@ARTICLE{Yee,
author={Kane Yee},
journal={IEEE Transactions on Antennas and Propagation},
title={Numerical solution of initial boundary value problems involving maxwell's equations in isotropic media},
year={1966},
volume={14},
number={3},
pages={302-307},
keywords={EMP radiation effects.;Magnetic scattering by absorbing media;Boundary conditions;Boundary value problems;Conductors;Difference equations;Differential equations;EMP radiation effects;Electromagnetic scattering;Finite difference methods;Maxwell equations;Partial differential equations},
doi={10.1109/TAP.1966.1138693},
ISSN={0018-926X},
month={May},
}
@article{Scalability,
 author = {Hill, Mark D.},
 title = {What is Scalability?},
 journal = {SIGARCH Comput. Archit. News},
 issue_date = {Dec. 1990},
 volume = {18},
 number = {4},
 month = dec,
 year = {1990},
 issn = {0163-5964},
 pages = {18--21},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/121973.121975},
 doi = {10.1145/121973.121975},
 acmid = {121975},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {multiprocessor, parallel random access machine (PRAM), scalability and speedup},
} 
@inproceedings{Amdahl,
 author = {Amdahl, Gene M.},
 title = {Validity of the Single Processor Approach to Achieving Large Scale Computing Capabilities},
 booktitle = {Proceedings of the April 18-20, 1967, Spring Joint Computer Conference},
 series = {AFIPS '67 (Spring)},
 year = {1967},
 location = {Atlantic City, New Jersey},
 pages = {483--485},
 numpages = {3},
 url = {http://doi.acm.org/10.1145/1465482.1465560},
 doi = {10.1145/1465482.1465560},
 acmid = {1465560},
 publisher = {ACM},
 address = {New York, NY, USA},
} 
@Article{AbdelKhalik201328,
  Title                    = {Overview of hybrid subspace methods for uncertainty quantification, sensitivity analysis },
  Author                   = {Hany S. Abdel-Khalik and Youngsuk Bang and Congjian Wang},
  Journal                  = {Annals of Nuclear Energy },
  Year                     = {2013},
  Note                     = {Nuclear Reactor Safety Simulation and Uncertainty Analysis },
  Pages                    = {28 - 46},
  Volume                   = {52},

  Abstract                 = {The role of modeling and simulation has been heavily promoted in recent years to improve understanding of complex engineering systems. To realize the benefits of modeling and simulation, concerted efforts in the areas of uncertainty quantification and sensitivity analysis are required. The manuscript intends to serve as a pedagogical presentation of the material to young researchers and practitioners with little background on the subjects. We believe this is important as the role of these subjects is expected to be integral to the design, safety, and operation of existing as well as next generation reactors. In addition to covering the basics, an overview of the current state-of-the-art will be given with particular emphasis on the challenges pertaining to nuclear reactor modeling. The second objective will focus on presenting our own development of hybrid subspace methods intended to address the explosion in the computational overhead required when handling real-world complex engineering systems. },
  Doi                      = {http://dx.doi.org/10.1016/j.anucene.2012.07.020},
  ISSN                     = {0306-4549},
  Keywords                 = {Uncertainty quantification},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0306454912002678}
}

@InCollection{AbdulJabbar2015xv,
  Title                    = {Contributors },
  Author                   = {Mustafa AbdulJabbar and Jefferson Amstutz and Cédric Andreolli and Edoardo Aprà and Nikita Astafiev and Troy Baer and Carsten Benthin and Per Berg and Vincent Betro and Leonardo Borges and Ryan Braby and Glenn Brook and Ilya Burylov and Ki Sing Chan and Gilles Civario and Guillaume Colin de Verdière and Eduardo D’Azevedo and Jim Dempsey and Alejandro Duran and Manfred Ernst and Kerry Evans and Rob Farber and Louis Feng and Evgeny Fiksman and Jeff Hammond and Michael Hebenstreit and Christopher Hughes and Sverre Jarp and Jim Jeffers and Gregory S. Johnson and Vadim Karpusenko and Michael Klemm and Karol Kowalski and Michael Lysaght and Anton Malakhov and Tim Mattson and Simon McIntosh-Smith and Larry Meadows and Karl Meerbergen and Iosif Meyerov and Kent Milfeld and Paul Peltz Jr. and Simon John Pennycook and Jacob Weismann Poulsen and Karthik Raman and James Reinders and Alexander Reinefeld and Dirk Roose and Carlos Rosales-Fernandez and Karl Schulz and Jason Sewall and Gregg Skinner and Mikhail Smelyanskiy and Thomas Steinke and Shi-Quan Su and Alexander Sysoyev and Philippe Thierry and Antonio Valles and Jerome Vienne and Andrey Vladimirov and Ingo Wald and Florian Wende and Kwai Lam Wong and Sven Woop and Claude Wright and Rio Yokota and Charles Yount and Albert-Jan Nicholas Yzelman and Weiqun Zhang},
  Booktitle                = {High Performance Parallelism Pearls },
  Publisher                = {Morgan Kaufmann},
  Year                     = {2015},

  Address                  = {Boston},
  Editor                   = {Jeffers, James ReindersJim },
  Pages                    = {xv - xxxvii},

  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-802118-7.09989-1},
  ISBN                     = {978-0-12-802118-7},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780128021187099891}
}

@Article{Abramson20141,
  Title                    = {Big Data Meets Computational Science, Preface for \{ICCS\} 2014 },
  Author                   = {David Abramson and Michael Lees and Valeria V. Krzhizhanovskaya and Jack Dongarra and Peter M.A. Sloot},
  Journal                  = {Procedia Computer Science },
  Year                     = {2014},
  Note                     = {2014 International Conference on Computational Science },
  Pages                    = {1 - 7},
  Volume                   = {29},

  Doi                      = {http://dx.doi.org/10.1016/j.procs.2014.04.002},
  ISSN                     = {1877-0509},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S187705091400177X}
}

@Article{Acebron2013224,
  Title                    = {Highly efficient numerical algorithm based on random trees for accelerating parallel Vlasov–Poisson simulations },
  Author                   = {Juan A. Acebrón and Ángel Rodríguez-Rozas},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2013},
  Pages                    = {224 - 245},
  Volume                   = {250},

  Abstract                 = {Abstract An efficient numerical method based on a probabilistic representation for the Vlasov–Poisson system of equations in the Fourier space has been derived. This has been done theoretically for arbitrary dimensional problems, and particularized to unidimensional problems for numerical purposes. Such a representation has been validated theoretically in the linear regime comparing the solution obtained with the classical results of the linear Landau damping. The numerical strategy followed requires generating suitable random trees combined with a Padé approximant for approximating accurately a given divergent series. Such series are obtained by summing the partial contributions to the solution coming from trees with arbitrary number of branches. These contributions, coming in general from multi-dimensional definite integrals, are efficiently computed by a quasi-Monte Carlo method. It is shown how the accuracy of the method can be effectively increased by considering more terms of the series. The new representation was used successfully to develop a Probabilistic Domain Decomposition method suited for massively parallel computers, which improves the scalability found in classical methods. Finally, a few numerical examples based on classical phenomena such as the non-linear Landau damping, and the two streaming instability are given, illustrating the remarkable performance of the algorithm, when compared the results with those obtained using a classical method. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2013.05.025},
  ISSN                     = {0021-9991},
  Keywords                 = {Monte Carlo and quasi Monte-Carlo methods},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999113003653}
}

@Article{Acebron20117891,
  Title                    = {A new parallel solver suited for arbitrary semilinear parabolic partial differential equations based on generalized random trees },
  Author                   = {Juan A. Acebrón and Ángel Rodríguez-Rozas},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2011},
  Number                   = {21},
  Pages                    = {7891 - 7909},
  Volume                   = {230},

  Abstract                 = {A probabilistic representation for initial value semilinear parabolic problems based on generalized random trees has been derived. Two different strategies have been proposed, both requiring generating suitable random trees combined with a Pade approximant for approximating accurately a given divergent series. Such series are obtained by summing the partial contribution to the solution coming from trees with arbitrary number of branches. The new representation greatly expands the class of problems amenable to be solved probabilistically, and was used successfully to develop a generalized probabilistic domain decomposition method. Such a method has been shown to be suited for massively parallel computers, enjoying full scalability and fault tolerance. Finally, a few numerical examples are given to illustrate the remarkable performance of the algorithm, comparing the results with those obtained with a classical method. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2011.06.033},
  ISSN                     = {0021-9991},
  Keywords                 = {Monte Carlo methods},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999111004165}
}

@Article{Adamatzky2013242,
  Title                    = {Bio-Imitation of Mexican Migration Routes to the \{USA\} with Slime Mould on 3D Terrains },
  Author                   = {Andrew Adamatzky and Genaro J Martinez},
  Journal                  = {Journal of Bionic Engineering },
  Year                     = {2013},
  Number                   = {2},
  Pages                    = {242 - 250},
  Volume                   = {10},

  Abstract                 = {Abstract Plasmodium of Physarum polycephalum (P. polycephalum) is a large single cell visible by an unaided eye. It shows sophisticated behavioural traits in foraging for nutrients and developing an optimal transport network of protoplasmic tubes spanning sources of nutrients. When placed in an environment with distributed sources of nutrients the cell ‘computes’ an optimal graph spanning the nutrients by growing a network of protoplasmic tubes. P. polycephalum imitates development of man-made transport networks of a country when configuration of nutrients represents major urban areas. We employed this feature of the slime mould to imitate mexican migration to USA. The Mexican migration to \{USA\} is the World's largest migration system. We bio-physically imitated the migration using slime mould P. polycephalum. In laboratory experiments with 3D Nylon terrains of \{USA\} we imitated development of migratory routes from Mexico-USA border to ten urban areas with high concentration of Mexican migrants. From results of laboratory experiments we extracted topologies of migratory routes, and highlighted a role of elevations in shaping the human movement networks. },
  Doi                      = {http://dx.doi.org/10.1016/S1672-6529(13)60220-6},
  ISSN                     = {1672-6529},
  Keywords                 = {biomimetics},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1672652913602206}
}

@Article{Aguilar20132197,
  Title                    = {Scalability analysis of Dalton, a molecular structure program },
  Author                   = {Xavier Aguilar and Michael Schliephake and Olav Vahtras and Judit Gimenez and Erwin Laure},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2013},
  Note                     = {Including Special sections: Advanced Cloud Monitoring Systems \&amp; The fourth \{IEEE\} International Conference on e-Science 2011 — e-Science Applications and Tools \&amp; Cluster, Grid, and Cloud Computing },
  Number                   = {8},
  Pages                    = {2197 - 2204},
  Volume                   = {29},

  Abstract                 = {Abstract Dalton is a molecular electronic structure program featuring common methods of computational chemistry that are based on pure quantum mechanics (QM) as well as hybrid quantum mechanics/molecular mechanics (QM/MM). It is specialized and has a leading position in calculation of molecular properties with a large world-wide user community (over 2000 licenses issued). In this paper, we present a performance characterization and optimization of Dalton. We also propose a solution to avoid the master/worker design of Dalton to become a performance bottleneck for larger process numbers. With these improvements we obtain speedups of 4x, increasing the parallel efficiency of the code and being able to run in it in a much bigger number of cores. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2013.04.013},
  ISSN                     = {0167-739X},
  Keywords                 = {Performance analysis},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X13000733}
}

@Article{Agullo2011357,
  Title                    = {QCG-OMPI: \{MPI\} applications on grids },
  Author                   = {Emmanuel Agullo and Camille Coti and Thomas Herault and Julien Langou and Sylvain Peyronnet and Ala Rezmerita and Franck Cappello and Jack Dongarra},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2011},
  Number                   = {4},
  Pages                    = {357 - 369},
  Volume                   = {27},

  Abstract                 = {Computational grids present promising computational and storage capacities. They can be made by punctual aggregation of smaller resources (i.e., clusters) to obtain a large-scale supercomputer. Running general applications is challenging for several reasons. The first one is inter-process communication: processes running on different clusters must be able to communicate with one another in spite of security equipments such as firewalls and NATs. Another problem raised by grids for communication-intensive parallel application is caused by the heterogeneity of the available networks that interconnect processes with one another. In this paper we present how QCG-OMPI can execute efficient parallel applications on computational grids. We first present an \{MPI\} programming, communication and execution middleware called QCG-OMPI. We then present how applications can make use of the capabilities of QCG-OMPI by presenting two typical, parallel applications: a geophysics application combining collective operations and a master–worker scheme, and a linear algebra application. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2010.11.015},
  ISSN                     = {0167-739X},
  Keywords                 = {Grid computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X10002359}
}

@Article{Agullo201196,
  Title                    = {Parallel hierarchical hybrid linear solvers for emerging computing platforms },
  Author                   = {Emmanuel Agullo and Luc Giraud and Abdou Guermouche and Jean Roman},
  Journal                  = {Comptes Rendus Mécanique },
  Year                     = {2011},
  Note                     = {High Performance ComputingLe Calcul Intensif },
  Number                   = {2–3},
  Pages                    = {96 - 103},
  Volume                   = {339},

  Abstract                 = {The design of the extreme-scale platforms that are expected to become available in the forthcoming decade will represent a convergence of technological trends and the boundary conditions imposed by over half a century of algorithm and application software development. These platforms will be hierarchical because they provide coarse grain parallelism between nodes and fine grain parallelism within each node. They are also expected to be very heterogeneous since multi-core chips and accelerators have completely different architectures and potentials. It is clear that such a degree of complexity will embody radical changes that will render obsolete the current software infrastructure for large-scale scientific applications. In this paper, we illustrate a hierarchical algorithmic approach for the implementation of an efficient parallel sparse linear solver that combines direct and iterative methods. Such a hybrid approach exploits the advantages of both numerical techniques and enables the use of several levels and grains of parallelism. This combination express different levels of parallelism and permits an optimal trade-off between numerical and parallel efficiency. Consequently, such a numerical technique appears as a promising candidate for intensive simulations on future many-core parallel platforms. },
  Doi                      = {http://dx.doi.org/10.1016/j.crme.2010.11.005},
  ISSN                     = {1631-0721},
  Keywords                 = {Computer science},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1631072110002068}
}

@Article{Ajwani20131362,
  Title                    = {Generating synthetic task graphs for simulating stream computing systems },
  Author                   = {Deepak Ajwani and Shoukat Ali and Kostas Katrinis and Cheng-Hong Li and Alfred J. Park and John P. Morrison and Eugen Schenfeld},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2013},
  Number                   = {10},
  Pages                    = {1362 - 1374},
  Volume                   = {73},

  Abstract                 = {Abstract Stream-computing is an emerging computational model for performing complex operations on and across multi-source, high-volume data flows. The pool of mature publicly available applications employing this model is fairly small, and therefore the availability of workloads for various types of applications is scarce. Thus, there is a need for synthetic generation of large-scale workloads to drive simulations and estimate the performance of stream-computing applications at scale. We identify the key properties shared by most task graphs of stream-computing applications and use them to extend known random graph generation concepts with stream computing specific features, providing researchers with realistic input stream graphs. Our graph generation techniques serve the purpose of covering a disparity of potential applications and user input. Our first “domain-specific” framework exhibits high user-controlled configurability while the second “application-agnostic” framework focuses solely on emulating the key properties of general stream-computing systems, at the loss of domain-specific fine-tuning. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2013.06.002},
  ISSN                     = {0743-7315},
  Keywords                 = {Stream computing systems},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731513001172}
}

@Article{Alexandrou2012101,
  Title                    = {Hadron structure in lattice \{QCD\} },
  Author                   = {Constantia Alexandrou},
  Journal                  = {Progress in Particle and Nuclear Physics },
  Year                     = {2012},
  Note                     = {From Quarks and Gluons to Hadrons and NucleiInternational Workshop on Nuclear Physics, 33rd Course },
  Number                   = {2},
  Pages                    = {101 - 116},
  Volume                   = {67},

  Abstract                 = {Recent progress in hadron structure calculations within lattice \{QCD\} is reviewed. Results on key observables such as the axial charge, the quark momentum fraction and the spin content of the nucleon are discussed with focus on open issues. Lattice \{QCD\} studies of the γ ∗ N → Δ transition as well as the Δ form factors are also presented. },
  Doi                      = {http://dx.doi.org/10.1016/j.ppnp.2011.12.003},
  ISSN                     = {0146-6410},
  Keywords                 = {Hadron structure},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0146641011001207}
}

@Article{Alexandrov20151685,
  Title                    = {Computational Science Research Methods for Science Education at \{PG\} Level },
  Author                   = {Nia Alexandrov and Vassil Alexandrov},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {1685 - 1693},
  Volume                   = {51},

  Abstract                 = {Abstract The role of Computational Science research methods teaching to science students at \{PG\} level is to enhance their research profile developing their abilities to investigate complex problems, analyze the resulting data and use adequately \{HPC\} environments and tools for computation and visualization. The paper analyses the current state and proposes a program that encompasses mathematical modelling, data science, advanced algorithms development, parallel programming and visualization tools. It also gives examples of specific scientific domains with explicitly taught and embedded Computational Science subjects. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.305},
  ISSN                     = {1877-0509},
  Keywords                 = {Computational Science Research Methods},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915011138}
}

@Article{Alexandrov20121789,
  Title                    = {The Role of Computational Science and Emerging Technologies in the Natural Sciences Education at University Level },
  Author                   = {Nia Alexandrov and Vassil Alexandrov and Raul Ramirez},
  Journal                  = {Procedia Computer Science },
  Year                     = {2012},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2012 },
  Pages                    = {1789 - 1798},
  Volume                   = {9},

  Abstract                 = {This paper is focused on the role of Computational Science and emerging technologies in the natural sciences education at university level. We outline our Integrated Metacognitive Process Model (IMPM) and our Collaborative Learning approach based on Collaborative Creative Cross-Pollination activity model at postgraduate level. We present our multidisciplinary approach based on the following three components: the existence of multidisciplinary research environment (non-silos departmental culture), computational science research methods as core part of the curricula and collaborative teaching activities facilitated by novel collaborative tools using Collaborative Creative Cross-Pollination. Some results showing the advantages of such an environment and approach are presented. The initial results have shown overall average improvement of the average marks with around 5% plus clear satisfaction of the students as evident from their responses to the course evaluation. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2012.04.197},
  ISSN                     = {1877-0509},
  Keywords                 = {Computational Science education},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050912003183}
}

@Article{Alexandrov20141888,
  Title                    = {Scalable Stochastic and Hybrid Methods and Algorithms for Extreme Scale Computing },
  Author                   = {Vassil Alexandrov},
  Journal                  = {Procedia Computer Science },
  Year                     = {2014},
  Note                     = {2014 International Conference on Computational Science },
  Pages                    = {1888 - 1892},
  Volume                   = {29},

  Abstract                 = {Abstract Novel mathematics and mathematical modelling approaches together with scalable algorithms are needed to enable key applications at extreme-scale. This is especially true as \{HPC\} systems continue to scale up in compute node and processor core count. At the moment computational scientists are at the critical point/threshold of novel mathematics development as well as large-scale algorithm development and re-design and implementation that will affect most of the application areas. Thus the paper will focus on the mathematical and algorithmic challenges and approaches towards exascale and beyond and in particular on stochastic and hybrid methods that in turn lead to scalable scientific algorithms with minimal or no global communication, hiding network and memory latency, have very high computation/communication overlap, have no synchronization points. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2014.05.173},
  ISSN                     = {1877-0509},
  Keywords                 = {Scalable Stochastic and Hybrid Mathematical Methods},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050914003500}
}

@Article{Alexandrov2013iii,
  Title                    = {Towards scalable mathematics and scalable algorithms for extreme scale computing },
  Author                   = {Vassil Alexandrov},
  Journal                  = {Journal of Computational Science },
  Year                     = {2013},
  Note                     = {Scalable Algorithms for Large-Scale Systems Workshop (ScalA2011), Supercomputing 2011 },
  Number                   = {6},
  Pages                    = {iii - v},
  Volume                   = {4},

  Doi                      = {http://dx.doi.org/10.1016/S1877-7503(13)00120-8},
  ISSN                     = {1877-7503},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877750313001208}
}

@Article{Alexandrov20131,
  Title                    = {Computation at the Frontiers of Science, Preface for \{ICCS\} 2013 },
  Author                   = {Vassil Alexandrov and Michael Lees and Valeria Krzhizhanovskaya and Jack Dongarra and Peter M.A. Sloot},
  Journal                  = {Procedia Computer Science },
  Year                     = {2013},
  Note                     = {2013 International Conference on Computational Science },
  Pages                    = {1 - 9},
  Volume                   = {18},

  Doi                      = {http://dx.doi.org/10.1016/j.procs.2013.05.163},
  ISSN                     = {1877-0509},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050913003062}
}

@Article{Alexandrov20111708,
  Title                    = {Monte Carlo scalable algorithms for Computational Finance },
  Author                   = {V.N. Alexandrov and Christian González Martel and J. Straßburg},
  Journal                  = {Procedia Computer Science },
  Year                     = {2011},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2011 },
  Pages                    = {1708 - 1715},
  Volume                   = {4},

  Abstract                 = {With the latest developments in the area of advanced computer architectures, we are already seeing large scale machines at petascale level and we are faced with the exascale computing challenge. All these require scalability at system, algorithmic and mathematical model level. In particular, e_cient scalable algorithms are required to bridge the performance gap. In this paper, examples of various approaches of designing scalable algorithms for such advanced architectures will be given. We will briefly present our approach to Monte Carlo scalable algorithms for Linear Algebra and explain how these approaches are extended to the field of Computational Finance. Implementation examples will be presented using Linear Algebra Problems and problems from Computational Finance. Furthermore, the corresponding properties of these algorithms will be outlined and discussed. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2011.04.185},
  ISSN                     = {1877-0509},
  Keywords                 = {Scalable Algorithms},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050911002432}
}

@Article{Alhubail2016110,
  Title                    = {The swept rule for breaking the latency barrier in time advancing \{PDEs\} },
  Author                   = {Maitham Alhubail and Qiqi Wang},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2016},
  Pages                    = {110 - 121},
  Volume                   = {307},

  Abstract                 = {Abstract This article investigates the swept rule of space–time domain decomposition, an idea to break the latency barrier via communicating less often when explicitly solving time-dependent PDEs. The swept rule decomposes space and time among computing nodes in ways that exploit the domains of influence and the domain of dependency, making it possible to communicate once per many timesteps without redundant computation. The article presents simple theoretical analysis to the performance of the swept rule which then was shown to be accurate by conducting numerical experiments. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2015.11.026},
  ISSN                     = {0021-9991},
  Keywords                 = {Swept rule},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999115007664}
}

@Article{Ali2011556,
  Title                    = {A case for on-machine load balancing },
  Author                   = {Shoukat Ali and Behdis Eslamnour and Zehra Shah},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2011},
  Number                   = {4},
  Pages                    = {556 - 564},
  Volume                   = {71},

  Abstract                 = {This paper diverges from the traditional load balancing, and introduces a new principle called the on-machine load balance rule. The on-machine load balance rule leads to resource allocations that are better in tolerating uncertainties in the processing times of the tasks allocated to the resources when compared to other resource allocations that are derived using the conventional “across-the-machines” load balancing rule. The on-machine load balance rule calls for the resource allocation algorithms to allocate similarly sized tasks on a machine (in addition to optimizing some primary performance measures such as estimated makespan and average response time). The on-machine load balance rule is very different from the usual across-the-machines load balance rule that strives to balance load across resources so that all resources have similar finishing times. We give a mathematical justification for the on-machine load balance rule requiring only liberal assumptions about task processing times. Then we validate with extensive simulations that the resource allocations derived using on-machine load balance rule are indeed more tolerant of uncertain task processing times. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2010.11.003},
  ISSN                     = {0743-7315},
  Keywords                 = {Load balancing and task assignment},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731510002352}
}

@Article{Almási201631,
  Title                    = {Review of advances in neural networks: Neural design technology stack },
  Author                   = {Adela-Diana Almási and Stanisław Woźniak and Valentin Cristea and Yusuf Leblebici and Ton Engbersen},
  Journal                  = {Neurocomputing },
  Year                     = {2016},
  Pages                    = {31 - 41},
  Volume                   = {174, Part A},

  Abstract                 = {Abstract This review provides a high-level synthesis of significant recent advances in artificial neural network research, as well as multi-disciplinary concepts connected to the far-reaching goal of obtaining intelligent systems. We assume that a global outlook of these interconnected fields can benefit researchers by providing alternative viewpoints. Therefore, we present different network and neuron models, we discuss model parameters and the means to obtain them, and we draw a quick outline of information encoding, before proceeding to an overview of the relevant learning mechanisms, ranging from established approaches to novel ideas. We specifically focus on comparing the classical artificial model with the biologically-feasible spiking neuron, and we take this comparison further into a discussion on the biological plausibility of various learning approaches. },
  Doi                      = {http://dx.doi.org/10.1016/j.neucom.2015.02.092},
  ISSN                     = {0925-2312},
  Keywords                 = {Neural networks},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0925231215010358}
}

@Article{Altunay201161,
  Title                    = {Optimal response to attacks on the open science grid },
  Author                   = {Mine Altunay and Sven Leyffer and Jeffrey T. Linderoth and Zhen Xie},
  Journal                  = {Computer Networks },
  Year                     = {2011},
  Number                   = {1},
  Pages                    = {61 - 73},
  Volume                   = {55},

  Abstract                 = {Cybersecurity is a growing concern, especially in open grids, where attack propagation is easy because of prevalent collaborations among thousands of users and hundreds of institutions. The collaboration rules that typically govern large science experiments as well as social networks of scientists span across the institutional security boundaries. A common concern is that the increased openness may allow malicious attackers to spread more readily around the grid. We consider how to optimally respond to attacks in open grid environments. To show how and why attacks spread more readily around the grid, we first discuss how collaborations manifest themselves in the grids and form the collaboration network graph, and how this collaboration network graph affects the security threat levels of grid participants. We present two mixed-integer program (MIP) models to find the optimal response to attacks in open grid environments, and also calculate the threat level associated with each grid participant. Given an attack scenario, our optimal response model aims to minimize the threat levels at unaffected participants while maximizing the uninterrupted scientific production (continuing collaborations). By adopting some of the collaboration rules (e.g., suspending a collaboration or shutting down a site), the model finds optimal response to subvert an attack scenario. },
  Doi                      = {http://dx.doi.org/10.1016/j.comnet.2010.07.012},
  ISSN                     = {1389-1286},
  Keywords                 = {Cybersecurity},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1389128610002410}
}

@Article{Ammendola201590,
  Title                    = {A hierarchical watchdog mechanism for systemic fault awareness on distributed systems },
  Author                   = {Roberto Ammendola and Andrea Biagioni and Ottorino Frezza and Francesca Lo Cicero and Alessandro Lonardo and Pier Stanislao Paolucci and Davide Rossetti and Francesco Simula and Laura Tosoratto and Piero Vicini},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2015},
  Pages                    = {90 - 99},
  Volume                   = {53},

  Abstract                 = {Abstract Systemic fault tolerance is usually pursued with a number of strategies, like redundancy and checkpoint/restart; any of them needs to be triggered by safe and fast fault detection. We devised a hardware/software approach to fault detection that enables a system-level Fault Awareness by implementing a hierarchical Mutual Watchdog. It relies on an improved high performance Network Interface Card (NIC), implementing an n -dimensional mesh topology and a Service Network. The hierarchical watchdog mechanism is able to quickly detect faults on each node, as the Host and the high performance \{NIC\} guard each other while every node monitors its own first neighbours in the mesh. Duplicated and distributed Supervisor Nodes receive communication by means of diagnostic messages routed through either the Service Network or the N -dimensional Network, then assemble a global picture of the system status. In this way our approach allows achieving a Fault Awareness with no-single-point-of-failure. We describe an implementation of this hardware/software co-design for our high performance 3D torus NIC, with a focus on how routed diagnostic messages do not affect the system performances. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2014.12.015},
  ISSN                     = {0167-739X},
  Keywords                 = {Distributed architectures},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X14002751}
}

@InCollection{Amstutz2015xvii,
  Title                    = {Contributors },
  Author                   = {Jefferson Amstutz and Cedric Andreolli and Meenakshi Arunachalam and Gaurav Bansal and Martin Berzins and Paul Besl and Ashraf Bhuiyan and Stephen Blair-Chappell and Leonardo Borges and James P. Briggs and Mikhail Brinskiy and Michal Brylinski and Vlad Calina and James Dinan and Jussi Enkovaara and Rob Farber and Julia Fedorova and Wei P. Feinstein and Evan Felix and James R. Fergusson and Evgeny Fiksman and Indraneil Gokhale and Christiaan Gribble and Diana Guttman and Tom Henderson and John Holmen and Allen H.-L. Huang and Bormin Huang and Alan Humphrey and Juha Jäykkä and Jim Jeffers and Ashish Jha and Bálint Joó and Dhiraj D. Kalamkar and Mahmut Taylan Kandemir and Rahul Khanna and Taylor Kidd and Jeongnim Kim and Michael Klemm and Shuo Li and Yongchao Liu and Belinda Liviero and Mark Lubin and Luke Mason and Zakhar A. Matveev and Lawrence Meadows and John Michalakes and Jarno Mielikainen and Ravi A. Murty and Perri Needham and Chris J. Newburn and Matthias Noack and Enda O'Brien and Klaus-Dieter Oertel and Simon J. Pennycook and Dmitry Prohorov and Narayan Ranganathan and George M. Raskulinec and James Reinders and Bertil Schmidt and Michael Seaton and Edward P. Shellard and Mikhail Smelyanskiy and Paulo Souza and Dan Stanzione and Philippe Thierry and Prashanth Thinakaran and Karthikeyan Vaidyanathan and Sergei Vinogradov and Ross C. Walker and Florian Wende and Freddie Witherden and Praveen Yedlapalli},
  Booktitle                = {High Performance Parallelism Pearls },
  Publisher                = {Morgan Kaufmann},
  Year                     = {2015},

  Address                  = {Boston},
  Editor                   = {Reinders, James and Jeffers, Jim },
  Pages                    = {xvii - xli},

  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-803819-2.09998-5},
  ISBN                     = {978-0-12-803819-2},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780128038192099985}
}

@Article{Anderson20151828,
  Title                    = {Transmathematical Basis of Infinitely Scalable Pipeline Machines },
  Author                   = {James A.D.W. Anderson},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {1828 - 1837},
  Volume                   = {51},

  Abstract                 = {Abstract We describe infinitely scalable pipeline machines with perfect parallelism, in the sense that every instruction of an inline program is executed, on successive data, on every clock tick. Programs with shared data effectively execute in less than a clock tick. We show that pipeline machines are faster than single or multi-core, von Neumann machines for sufficiently many program runs of a sufficiently time consuming program. Our pipeline machines exploit the totality of transreal arithmetic and the known waiting time of statically compiled programs to deliver the interesting property that they need no hardware or software exception handling. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.408},
  ISSN                     = {1877-0509},
  Keywords                 = {Transreal arihtmetic},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915012168}
}

@Article{Anzt20131613,
  Title                    = {A block-asynchronous relaxation method for graphics processing units },
  Author                   = {Hartwig Anzt and Stanimire Tomov and Jack Dongarra and Vincent Heuveline},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2013},
  Note                     = {Heterogeneity in Parallel and Distributed Computing },
  Number                   = {12},
  Pages                    = {1613 - 1626},
  Volume                   = {73},

  Abstract                 = {Abstract In this paper, we analyze the potential of asynchronous relaxation methods on Graphics Processing Units (GPUs). We develop asynchronous iteration algorithms in \{CUDA\} and compare them with parallel implementations of synchronous relaxation methods on CPU- or GPU-based systems. For a set of test matrices from \{UFMC\} we investigate convergence behavior, performance and tolerance to hardware failure. We observe that even for our most basic asynchronous relaxation scheme, the method can efficiently leverage the \{GPUs\} computing power and is, despite its lower convergence rate compared to the Gauss–Seidel relaxation, still able to provide solution approximations of certain accuracy in considerably shorter time than Gauss–Seidel running on CPUs- or GPU-based Jacobi. Hence, it overcompensates for the slower convergence by exploiting the scalability and the good fit of the asynchronous schemes for the highly parallel \{GPU\} architectures. Further, enhancing the most basic asynchronous approach with hybrid schemes–using multiple iterations within the “subdomain” handled by a \{GPU\} thread block–we manage to not only recover the loss of global convergence but often accelerate convergence of up to two times, while keeping the execution time of a global iteration practically the same. The combination with the advantageous properties of asynchronous iteration methods with respect to hardware failure identifies the high potential of the asynchronous methods for Exascale computing. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2013.05.008},
  ISSN                     = {0743-7315},
  Keywords                 = {Asynchronous relaxation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731513001147}
}

@Article{Anzt20127,
  Title                    = {Block-asynchronous Multigrid Smoothers for GPU-accelerated Systems },
  Author                   = {Hartwig Anzt and Stanimire Tomov and Mark Gates and Jack Dongarra and Vincent Heuveline},
  Journal                  = {Procedia Computer Science },
  Year                     = {2012},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2012 },
  Pages                    = {7 - 16},
  Volume                   = {9},

  Abstract                 = {This paper explores the need for asynchronous iteration algorithms as smoothers in multigrid methods. The hardware target for the new algorithms is top-of-the-line, highly parallel hybrid architectures – multicore-based systems enhanced with GPGPUs. These architectures are the most likely candidates for future high-end supercomputers. To pave the road for their effcient use, we must resolve challenges related to the fact that data movement, not floatingpoint operations, is the bottleneck to performance. Our work is in this direction — we designed block-asynchronous multigrid smoothers that perform more flops in order to reduce synchronization, and hence data movement. We show that the extra flops are done for “free,” while synchronization is reduced and the convergence properties of multigrid with classical smoothers like Gauss-Seidel can be preserved. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2012.04.002},
  ISSN                     = {1877-0509},
  Keywords                 = {Block-asynchronous Iteration},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050912001238}
}

@Article{Appeloe201019,
  Title                    = {Development of arbitrary-order hermite methods for simulation and analysis of turbulent jet noise },
  Author                   = {Daniel Appelö and Tim Colonius and Thomas Hagstrom and Matthew Inkman},
  Journal                  = {Procedia Engineering },
  Year                     = {2010},
  Note                     = {\{IUTAM\} Symposium on Computational Aero-Acoustics for Aircraft Noise PredictionIUTAM Symposium on Computational Aero-Acoustics for Aircraft Noise Prediction },
  Pages                    = {19 - 27},
  Volume                   = {6},

  Abstract                 = {In this short note a brief description of Hermite methods is given. Previous and ongoing development of arbitrary order Hermite methods for the simulation of turbulent jets is also presented. In addition we outline how Hermite methods can be hybridized with discontinuous Galerkin methods to handle boundary conditions in a straightforward way. },
  Doi                      = {http://dx.doi.org/10.1016/j.proeng.2010.09.003},
  ISSN                     = {1877-7058},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877705810005497}
}

@Article{Araújo2010773,
  Title                    = {Boundary-element parallel-computing algorithm for the microstructural analysis of general composites },
  Author                   = {F.C. Araújo and E.F. d’Azevedo and L.J. Gray},
  Journal                  = {Computers \& Structures },
  Year                     = {2010},
  Number                   = {11–12},
  Pages                    = {773 - 784},
  Volume                   = {88},

  Abstract                 = {A standard continuum-mechanics-based 3D boundary-element (BE) algorithm has been devised to the microstructural modeling of complex heterogeneous solids such as general composites. In the particular applications of this paper, the mechanical properties of carbon-nanotube–reinforced composites are estimated from three-dimensional representative volume elements (RVEs). The shell-like thin-walled carbon nanotubes (CNTs) are also simulated with 3D \{BE\} models, and a generic subregion-by-subregion (SBS) algorithm makes the microstructural description of the CNT–polymer systems possible. In fact, based on this algorithm, a general scalable \{BE\} parallel code is proposed. Square and hexagonal fiber-packing patterns are considered to simulate the 3D composite microstructures. },
  Doi                      = {http://dx.doi.org/10.1016/j.compstruc.2010.03.001},
  ISSN                     = {0045-7949},
  Keywords                 = {3D standard BEM},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045794910000568}
}

@Article{Aroca20121770,
  Title                    = {Towards green data centers: A comparison of x86 and \{ARM\} architectures power efficiency },
  Author                   = {Rafael Vidal Aroca and Luiz Marcos Garcia Gonçalves},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2012},
  Number                   = {12},
  Pages                    = {1770 - 1780},
  Volume                   = {72},

  Abstract                 = {Servers and clusters are fundamental building blocks of high performance computing systems and the \{IT\} infrastructure of many companies and institutions. This paper analyzes the feasibility of building servers based on low power computers through an experimental comparison of server applications running on x86 and \{ARM\} computer architectures. The comparison executed on web and database servers includes power usage, \{CPU\} load, temperature, request latencies and the number of requests handled by each tested system. Floating point performance and power usage are also evaluated. The use of \{ARM\} based systems has shown to be a good choice when power efficiency is needed without losing performance. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2012.08.005},
  ISSN                     = {0743-7315},
  Keywords                 = {Low power},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731512002122}
}

@Article{Arteaga2015727,
  Title                    = {A stencil-based implementation of Parareal in the C++ domain specific embedded language \{STELLA\} },
  Author                   = {Andrea Arteaga and Daniel Ruprecht and Rolf Krause},
  Journal                  = {Applied Mathematics and Computation },
  Year                     = {2015},
  Note                     = {The Fourth European Seminar on Computing (ESCO 2014) },
  Pages                    = {727 - 741},
  Volume                   = {267},

  Abstract                 = {Abstract In view of the rapid rise of the number of cores in modern supercomputers, time-parallel methods that introduce concurrency along the temporal axis are becoming increasingly popular. For the solution of time-dependent partial differential equations, these methods can add another direction for concurrency on top of spatial parallelization. The paper presents an implementation of the time-parallel Parareal method in a C++ domain specific language for stencil computations (STELLA). \{STELLA\} provides both an OpenMP and a \{CUDA\} backend for a shared memory parallelization, using the \{CPU\} or \{GPU\} inside a node for the spatial stencils. Here, we intertwine this node-wise spatial parallelism with the time-parallel Parareal. This is done by adding an MPI-based implementation of Parareal, which allows us to parallelize in time across nodes. The performance of Parareal with both backends is analyzed in terms of speedup, parallel efficiency and energy-to-solution for an advection–diffusion problem with a time-dependent diffusion coefficient. },
  Doi                      = {http://dx.doi.org/10.1016/j.amc.2014.12.055},
  ISSN                     = {0096-3003},
  Keywords                 = {Parareal},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0096300314017093}
}

@InBook{Arykov2009,
  Title                    = {Parallel Computing Technologies: 10th International Conference, PaCT 2009, Novosibirsk, Russia, August 31-September 4, 2009. Proceedings},
  Author                   = {Arykov, Sergey and Malyshkin, Victor},
  Chapter                  = {Asynchronous Language and System of Numerical Algorithms Fragmented Programming},
  Editor                   = {Malyshkin, Victor},
  Pages                    = {1--7},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2009},

  Address                  = {Berlin, Heidelberg},

  Doi                      = {10.1007/978-3-642-03275-2_1},
  ISBN                     = {978-3-642-03275-2},
  Url                      = {http://dx.doi.org/10.1007/978-3-642-03275-2_1}
}

@Article{Atanassov20152719,
  Title                    = {Energy aware performance study for a class of computationally intensive Monte Carlo algorithms },
  Author                   = {E. Atanassov and T. Gurov and A. Karaivanova},
  Journal                  = {Computers \& Mathematics with Applications },
  Year                     = {2015},
  Note                     = {Numerical Methods for Scientific Computations and Advanced Applications },
  Number                   = {11},
  Pages                    = {2719 - 2725},
  Volume                   = {70},

  Abstract                 = {Abstract The latest developments in the domain of \{HPC\} have lead to the deployment of complex extreme-scale systems, based on diverse computing devices (CPU, GPU, accelerators) thus posing the question of scalability in the light not only of parallel efficiency, but also in terms of energy efficiency. In this paper we propose a new metrics for energy aware performance estimation based on our experience and the analysis of the existing metrics. We study the performance of computationally intensive Monte Carlo applications deployed on heterogeneous \{HPC\} systems with focus on energy efficiency and equipment costs. We compare the energy aware performance results of \{CPU\} and \{GPU\} variants of the tested algorithms with respect to the introduced measures and metrics. The results of our study demonstrate the importance of taking into account not only scalability of the \{HPC\} applications but also energy efficiency and equipment cost. They also show how to optimize the selection of \{CPU\} computing or computing with GPGPUs. The results can be used by application developers/users and also by resource providers. },
  Doi                      = {http://dx.doi.org/10.1016/j.camwa.2015.07.014},
  ISSN                     = {0898-1221},
  Keywords                 = {Energy aware performance},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0898122115003491}
}

@Article{Attig2009,
  Title                    = {Computational physics with PetaFlops computers },
  Author                   = {Norbert Attig},
  Journal                  = {Computer Physics Communications },
  Year                     = {2009},
  Note                     = {Special issue based on the Conference on Computational Physics 2008CCP 2008 },
  Number                   = {4},
  Pages                    = {555 - 558},
  Volume                   = {180},

  Abstract                 = {Driven by technology, Scientific Computing is rapidly entering the PetaFlops era. The Jülich Supercomputing Centre (JSC), one of three German national supercomputing centres, is focusing on the \{IBM\} Blue Gene architecture to provide computer resources of this class to its users, the majority of whom are computational physicists. Details of the system will be discussed and applications will be described which significantly benefit from this new architecture. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2008.12.032},
  ISSN                     = {0010-4655},
  Keywords                 = {Supercomputing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465508004499}
}

@Article{Attig2011,
  Title                    = {Trends in supercomputing: The European path to exascale },
  Author                   = {N. Attig and P. Gibbon and Th. Lippert},
  Journal                  = {Computer Physics Communications },
  Year                     = {2011},
  Note                     = {Computer Physics Communications Special Edition for Conference on Computational Physics Trondheim, Norway, June 23-26, 2010 },
  Number                   = {9},
  Pages                    = {2041 - 2046},
  Volume                   = {182},

  Abstract                 = {Recent developments in European supercomputing are reviewed covering both the latest hardware trends and the increasing difficulties faced by scientists in utilising these machines to perform large-scale numerical simulations. These challenges are reflected in the large number of international initiatives which have come into being over the last few years, founded in anticipation of exascale hardware which is foreseen within the next decade. The role of a key institution in supercomputing within these programmes is described using the example of the Jülich Supercomputing Centre (JSC), and progress in setting up its own community-oriented support units for scientific computing – Simulation Laboratories – is reported on. Finally, an assessment is made of some common grand challenges and their suitability for scaling to exaflop-scale computation. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2010.11.011},
  ISSN                     = {0010-4655},
  Keywords                 = {Supercomputing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465510004571}
}

@Article{Attig20112041,
  Title                    = {Trends in supercomputing: The European path to exascale },
  Author                   = {N. Attig and P. Gibbon and Th. Lippert},
  Journal                  = {Computer Physics Communications },
  Year                     = {2011},
  Note                     = {Computer Physics Communications Special Edition for Conference on Computational Physics Trondheim, Norway, June 23-26, 2010 },
  Number                   = {9},
  Pages                    = {2041 - 2046},
  Volume                   = {182},

  Abstract                 = {Recent developments in European supercomputing are reviewed covering both the latest hardware trends and the increasing difficulties faced by scientists in utilising these machines to perform large-scale numerical simulations. These challenges are reflected in the large number of international initiatives which have come into being over the last few years, founded in anticipation of exascale hardware which is foreseen within the next decade. The role of a key institution in supercomputing within these programmes is described using the example of the Jülich Supercomputing Centre (JSC), and progress in setting up its own community-oriented support units for scientific computing – Simulation Laboratories – is reported on. Finally, an assessment is made of some common grand challenges and their suitability for scaling to exaflop-scale computation. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2010.11.011},
  ISSN                     = {0010-4655},
  Keywords                 = {Supercomputing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465510004571}
}

@Article{Aupy20142048,
  Title                    = {Checkpointing algorithms and fault prediction },
  Author                   = {Guillaume Aupy and Yves Robert and Frédéric Vivien and Dounia Zaidouni},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2014},
  Number                   = {2},
  Pages                    = {2048 - 2064},
  Volume                   = {74},

  Abstract                 = {Abstract This paper deals with the impact of fault prediction techniques on checkpointing strategies. We extend the classical first-order analysis of Young and Daly in the presence of a fault prediction system, characterized by its recall and its precision. In this framework, we provide optimal algorithms to decide whether and when to take predictions into account, and we derive the optimal value of the checkpointing period. These results allow us to analytically assess the key parameters that impact the performance of fault predictors at very large scale. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2013.10.010},
  ISSN                     = {0743-7315},
  Keywords                 = {Algorithms},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731513002219}
}

@Article{Austin20124694,
  Title                    = {Semi-automatic sparse preconditioners for high-order finite element methods on non-uniform meshes },
  Author                   = {Travis M. Austin and Marian Brezina and Ben Jamroz and Chetan Jhurani and Thomas A. Manteuffel and John Ruge},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2012},
  Number                   = {14},
  Pages                    = {4694 - 4708},
  Volume                   = {231},

  Abstract                 = {High-order finite elements often have a higher accuracy per degree of freedom than the classical low-order finite elements. However, in the context of implicit time-stepping methods, high-order finite elements present challenges to the construction of efficient simulations due to the high cost of inverting the denser finite element matrix. There are many cases where simulations are limited by the memory required to store the matrix and/or the algorithmic components of the linear solver. We are particularly interested in preconditioned Krylov methods for linear systems generated by discretization of elliptic partial differential equations with high-order finite elements. Using a preconditioner like Algebraic Multigrid can be costly in terms of memory due to the need to store matrix information at the various levels. We present a novel method for defining a preconditioner for systems generated by high-order finite elements that is based on a much sparser system than the original high-order finite element system. We investigate the performance for non-uniform meshes on a cube and a cubed sphere mesh, showing that the sparser preconditioner is more efficient and uses significantly less memory. Finally, we explore new methods to construct the sparse preconditioner and examine their effectiveness for non-uniform meshes. We compare results to a direct use of Algebraic Multigrid as a preconditioner and to a two-level additive Schwarz method. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2012.03.013},
  ISSN                     = {0021-9991},
  Keywords                 = {High-order},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999112001556}
}

@Article{Badia201532,
  Title                    = {\{COMP\} Superscalar, an interoperable programming framework },
  Author                   = {Rosa M. Badia and Javier Conejero and Carlos Diaz and Jorge Ejarque and Daniele Lezzi and Francesc Lordan and Cristian Ramon-Cortes and Raul Sirvent},
  Journal                  = {SoftwareX },
  Year                     = {2015},
  Pages                    = {32 - 36},
  Volume                   = {3–4},

  Abstract                 = {Abstract \{COMPSs\} is a programming framework that aims to facilitate the parallelization of existing applications written in Java, C/C++ and Python scripts. For that purpose, it offers a simple programming model based on sequential development in which the user is mainly responsible for (i) identifying the functions to be executed as asynchronous parallel tasks and (ii) annotating them with annotations or standard Python decorators. A runtime system is in charge of exploiting the inherent concurrency of the code, automatically detecting and enforcing the data dependencies between tasks and spawning these tasks to the available resources, which can be nodes in a cluster, clouds or grids. In cloud environments, \{COMPSs\} provides scalability and elasticity features allowing the dynamic provision of resources. },
  Doi                      = {http://dx.doi.org/10.1016/j.softx.2015.10.004},
  ISSN                     = {2352-7110},
  Keywords                 = {Parallel programming models},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S2352711015000151}
}

@Article{Badia20151,
  Title                    = {On the scalability of inexact balancing domain decomposition by constraints with overlapped coarse/fine corrections },
  Author                   = {Santiago Badia and Alberto F. Martín and Javier Principe},
  Journal                  = {Parallel Computing },
  Year                     = {2015},
  Pages                    = {1 - 24},
  Volume                   = {50},

  Abstract                 = {Abstract In this work, we analyze the scalability of inexact two-level balancing domain decomposition by constraints (BDDC) preconditioners for Krylov subspace iterative solvers, when using a highly scalable asynchronous parallel implementation where fine and coarse correction computations are overlapped in time. This way, the coarse-grid problem can be fully overlapped by fine-grid computations (which are embarrassingly parallel) in a wide range of cases. Further, we consider inexact solvers to reduce the computational cost/complexity and memory consumption of coarse and local problems and boost the scalability of the solver. Out of our numerical experimentation, we conclude that the \{BDDC\} preconditioner is quite insensitive to inexact solvers. In particular, one cycle of algebraic multigrid (AMG) is enough to attain algorithmic scalability. Further, the clear reduction of computing time and memory requirements of inexact solvers compared to sparse direct ones makes possible to scale far beyond state-of-the-art \{BDDC\} implementations. Excellent weak scalability results have been obtained with the proposed inexact/overlapped implementation of the two-level \{BDDC\} preconditioner, up to 93,312 cores and 20 billion unknowns on JUQUEEN. Further, we have also applied the proposed setting to unstructured meshes and partitions for the pressure Poisson solver in the backward-facing step benchmark domain. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2015.09.004},
  ISSN                     = {0167-8191},
  Keywords                 = {Domain decomposition},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819115001180}
}

@Article{Balaji20161,
  Title                    = {Special Issue on Parallel Programming Models and Systems Software for High-End Computing },
  Author                   = {Pavan Balaji and Abhinav Vishnu and Yong Chen},
  Journal                  = {Parallel Computing },
  Year                     = {2016},
  Note                     = {Special Issue on Parallel Programming Models and SystemsSoftware for High-End Computing },
  Pages                    = {1 - 2},
  Volume                   = {51},

  Abstract                 = {Abstract This special issue features a collection of papers that extend the literature in unique ways, improving the state of art of programming models and systems software for high-end computing systems. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2016.01.004},
  ISSN                     = {0167-8191},
  Keywords                 = {Programming Models},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819116000053}
}

@Article{Balzuweit201667,
  Title                    = {Local search to improve coordinate-based task mapping },
  Author                   = {Evan Balzuweit and David P. Bunde and Vitus J. Leung and Austin Finley and Alan C.S. Lee},
  Journal                  = {Parallel Computing },
  Year                     = {2016},
  Note                     = {Special Issue on Parallel Programming Models and SystemsSoftware for High-End Computing },
  Pages                    = {67 - 78},
  Volume                   = {51},

  Abstract                 = {Abstract We present a local search strategy to improve the coordinate-based mapping of a parallel job’s tasks to the \{MPI\} ranks of its parallel allocation in order to reduce network congestion and the job’s communication time. The goal is to reduce the number of network hops between communicating pairs of ranks. Our target is applications with a nearest-neighbor stencil communication pattern running on mesh systems with non-contiguous processor allocation, such as Cray \{XE\} and \{XK\} Systems. Using the miniGhost mini-app, which models the shock physics application CTH, we demonstrate that our strategy reduces application running time while also reducing the runtime variability. We further show that mapping quality can vary based on the selected allocation algorithm, even between allocation algorithms of similar apparent quality. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2015.10.012},
  ISSN                     = {0167-8191},
  Keywords                 = {Task mapping},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819115001441}
}

@InCollection{Bamiedakis2013377,
  Title                    = {Chapter 11 - Integrated and Hybrid Photonics for High-Performance Interconnects },
  Author                   = {Nikos Bamiedakis and Kevin A. Williams and Richard V. Penty and Ian H. White},
  Booktitle                = {Optical Fiber Telecommunications (Sixth Edition) },
  Publisher                = {Academic Press},
  Year                     = {2013},

  Address                  = {Boston},
  Edition                  = {Sixth Edition},
  Editor                   = {Kaminow, Ivan P. and Li, Tingye and Willner, Alan E. },
  Pages                    = {377 - 418},
  Series                   = {Optics and Photonics},

  Abstract                 = {Abstract Optical interconnection technologies are increasingly deployed in high-performance electronic systems to address challenges in connectivity, size, bandwidth, latency, and cost. Projected performance requirements are leading to formidable cost and energy efficiency challenges. Hybrid and integrated photonic technologies are currently being developed to reduce assembly complexity and to reduce the numbers of individually packaged parts. This chapter provides an overview of the important challenges that photonics currently face, identifies the various optical technologies that are being considered for use at the different interconnection levels, and presents examples of demonstrated state-of-the-art optical interconnection systems. Finally, the prospects and potential of these technologies in the near future are discussed. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-396958-3.00011-1},
  ISSN                     = {15575837},
  Keywords                 = {Integrated photonics},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780123969583000111}
}

@Article{Bandura20103485,
  Title                    = {An integrated high-performance beam optics-nuclear processes framework with hybrid transfer map-Monte Carlo particle transport and optimization },
  Author                   = {L. Bandura and B. Erdelyi and J. Nolen},
  Journal                  = {Nuclear Instruments and Methods in Physics Research Section B: Beam Interactions with Materials and Atoms },
  Year                     = {2010},
  Number                   = {23},
  Pages                    = {3485 - 3497},
  Volume                   = {268},

  Abstract                 = {An integrated beam optics-nuclear processes framework is essential for accurate simulation of fragment separator beam dynamics. The code \{COSY\} \{INFINITY\} provides powerful differential algebraic methods for modeling and beam dynamics simulations in absence of beam-material interactions. However, these interactions are key for accurately simulating the dynamics of heavy ion fragmentation and fission. We have developed an extended version of the code that includes these interactions, and a set of new tools that allow efficient and accurate particle transport: by transfer map in vacuum and by Monte Carlo methods in materials. The new framework is presented, along with several examples from a preliminary layout of a fragment separator for a facility for rare isotope beams. },
  Doi                      = {http://dx.doi.org/10.1016/j.nimb.2010.09.011},
  ISSN                     = {0168-583X},
  Keywords                 = {Fragment separator},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0168583X10007615}
}

@Article{Barrett2013131,
  Title                    = {Ab initio no core shell model },
  Author                   = {Bruce R. Barrett and Petr Navrátil and James P. Vary},
  Journal                  = {Progress in Particle and Nuclear Physics },
  Year                     = {2013},
  Pages                    = {131 - 181},
  Volume                   = {69},

  Abstract                 = {Motivated by limitations of the Bloch–Horowitz–Brandow perturbative approach to nuclear structure we have developed the non-perturbative ab initio no core shell model (NCSM) capable of solving the properties of nuclei exactly for arbitrary nucleon–nucleon ( N N ) and N N +  three-nucleon ( N N N ) interactions with exact preservation of all symmetries. We present the complete ab initio \{NCSM\} formalism and review highlights obtained with it since its inception. These highlights include the first ab initio nuclear-structure calculations utilizing chiral N N N interactions, which predict the correct low-lying spectrum for 10B and explain the anomalous long 14C β -decay lifetime. We also obtain the small quadrupole moment of 6Li. In addition to explaining long-standing nuclear structure anomalies, the ab initio \{NCSM\} provides a predictive framework for observables that are not yet measured or are not directly measurable. For example, reactions between short-lived systems and reaction rates near zero energy are relevant to fusion research but may not be known from experiment with sufficient precision. We, therefore, discuss, in detail, the extension of the ab initio \{NCSM\} to nuclear reactions and sketch a number of promising future directions for research emerging from the \{NCSM\} foundation, including a microscopic non-perturbative framework for the theory with a core. Having a parameter-free approach, we can construct systems with a core, which will provide an ab initio pathway to heavier nuclei. },
  Doi                      = {http://dx.doi.org/10.1016/j.ppnp.2012.10.003},
  ISSN                     = {0146-6410},
  Keywords                 = {Nuclei},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0146641012001184}
}

@Article{Barton2015224,
  Title                    = {The use of discrete harmonics in direct multi-scale embedding of polycrystal plasticity },
  Author                   = {Nathan R. Barton and Joel V. Bernier and Ricardo A. Lebensohn and Donald E. Boyce},
  Journal                  = {Computer Methods in Applied Mechanics and Engineering },
  Year                     = {2015},
  Pages                    = {224 - 242},
  Volume                   = {283},

  Abstract                 = {Abstract We describe an approach for directly embedding polycrystal plasticity models in component scale calculations, with an emphasis on computational tractability. Previously, we have employed adaptive sampling to mitigate the computational cost of direct embedding, achieving two or more orders of magnitude in wall-clock speedup compared to more traditional approaches. However, in our previous work the crystal orientation distribution function (crystallographic texture) was not allowed to evolve significantly. Here we discuss an approach that allows for evolving texture by employing discrete harmonics, effectively decoupling considerations related to accuracy of integrals in the homogenization from those related to adequate representation of the evolving texture. We discuss the basic behaviors and convergence of the new polycrystal plasticity framework. Specific applications focus on the deformation of titanium, including the effects of twinning. Overall, the discrete harmonic based framework offers an attractive path forward for computationally efficient multi-scale embedding of polycrystal plasticity. },
  Doi                      = {http://dx.doi.org/10.1016/j.cma.2014.09.017},
  ISSN                     = {0045-7825},
  Keywords                 = {Multi-scale},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045782514003326}
}

@Article{Bauge201432,
  Title                    = {Connecting the Dots, or Nuclear Data in the Age of Supercomputing },
  Author                   = {E. Bauge and M. Dupuis and S. Hilaire and S. Péru and A.J. Koning and D. Rochman and S. Goriely},
  Journal                  = {Nuclear Data Sheets },
  Year                     = {2014},
  Pages                    = {32 - 37},
  Volume                   = {118},

  Abstract                 = {Abstract Recent increases in computing power have allowed for much progress to be made in the field of nuclear data. The advances listed below are each significant, but together bring the potential to completely change our perspective on the nuclear data evaluation process. The use of modern nuclear modeling codes like \{TALYS\} and the Monte Carlo sampling of its model parameter space, together with a code system developed at \{NRG\} Petten, which automates the production of ENDF-6 formatted files, their processing, and their use in nuclear reactor calculations, constitutes the Total Monte Carlo approach, which directly links physical model parameters with calculated integral observables like k eff . Together with the Backward-Forward Monte Carlo method for weighting samples according their statistical likelihood, the Total Monte Carlo can be applied to complete isotopic chains in a consistent way, to simultaneously evaluate nuclear data and the associated uncertainties in the continuum region. Another improvement is found in the uses of microscopic models for nuclear reaction calculations. For example, making use of \{QRPA\} excited states calculated with the Gogny interaction to solve the long standing question of the origin of the ad hoc “pseudo-states” that are introduced in evaluated nuclear data files to account for the Livermore pulsed sphere experiments. A third advance consists of the recent optimization of the Gogny \{D1M\} effective nuclear interaction, including constraints from experimental nuclear masses at the “beyond the mean field” level. All these advances are only made possible by the availability of vast resources of computing power, and even greater resources will allow connecting them, going continuously from the parameters of the nuclear interaction to reactor calculations. However, such scheme will surely only be usable for applications if a few fine-tuning “knobs” are introduced in it. The values of these adjusted parameters will have to be calibrated versus differential and integral experimental constraints. },
  Doi                      = {http://dx.doi.org/10.1016/j.nds.2014.04.004},
  ISSN                     = {0090-3752},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0090375214000349}
}

@Article{Beane20111,
  Title                    = {Nuclear physics from lattice \{QCD\} },
  Author                   = {S.R. Beane and W. Detmold and K. Orginos and M.J. Savage},
  Journal                  = {Progress in Particle and Nuclear Physics },
  Year                     = {2011},
  Number                   = {1},
  Pages                    = {1 - 40},
  Volume                   = {66},

  Abstract                 = {We review recent progress toward establishing lattice Quantum Chromodynamics as a predictive calculational framework for nuclear physics. A survey of the current techniques that are used to extract low-energy hadronic scattering amplitudes and interactions is followed by a review of recent two-body and few-body calculations by the \{NPLQCD\} collaboration and others. An outline of the nuclear physics that is expected to be accomplished with Lattice \{QCD\} in the next decade, along with estimates of the required computational resources, is presented. },
  Doi                      = {http://dx.doi.org/10.1016/j.ppnp.2010.08.002},
  ISSN                     = {0146-6410},
  Keywords                 = {Nuclear physics},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0146641010000530}
}

@InCollection{Becquart2012393,
  Title                    = {1.14 - Kinetic Monte Carlo Simulations of Irradiation Effects },
  Author                   = {C.S. Becquart and B.D. Wirth},
  Booktitle                = {Comprehensive Nuclear Materials },
  Publisher                = {Elsevier},
  Year                     = {2012},

  Address                  = {Oxford},
  Editor                   = {Konings, Rudy J.M. },
  Pages                    = {393 - 410},

  Abstract                 = {Abstract This chapter describes a family of Monte Carlo methods currently in use to model radiation-induced microstructural evolution. After presenting the methods, the main components of the framework of radiation damage modeling are illustrated and two examples of such studies are provided to present sufficient details on the kind of information that can be obtained using these techniques and demonstrating the strength of the methods. The chapter concludes with a description of the limitations of these approaches and presents possible ways of improvement that could be useful for further development. Recent years have witnessed tremendous advances in the realistic multiscale simulation of complex physical phenomena, such as irradiation and aging effects of materials. These advances have been made possible by the enormous progress achieved in computational physics for calculating reliable, yet tractable interatomic potentials and the vast improvements in computational power and parallel computing. As a result, computational materials science has emerged as an important complement to theory and experiment to provide fundamental materials science insight into the kinetics of irradiation effects in materials. This chapter describes the kinetic Monte Carlo (KMC) modeling technique and provides select examples of atomistic-type \{KMC\} modeling. In particular, these studies provide important insight into the vacancy clustering behavior in the milliseconds to months timeframe following displacement cascades in ferritic alloys and provide understanding of the solute clustering and precipitation in irradiated materials. However, the intrinsic limitation of \{KMC\} methods is the inability to simulate very long times or irradiation doses in a routine fashion, and this chapter concludes with a brief description of the advanced \{KMC\} algorithms that seek to increase the applicability of \{KMC\} simulations to the study of irradiation effects on materials. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-08-056033-5.00030-6},
  ISBN                     = {978-0-08-056033-5},
  Keywords                 = {Computational modeling},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780080560335000306}
}

@Article{Belleville201338,
  Title                    = {Designing digital circuits with nano-scale devices: Challenges and opportunities },
  Author                   = {Marc Belleville and Olivier Thomas and Alexandre Valentian and Fabien Clermidy},
  Journal                  = {Solid-State Electronics },
  Year                     = {2013},
  Note                     = {Selected Papers from the \{ESSDERC\} 2012 Conference },
  Pages                    = {38 - 45},
  Volume                   = {84},

  Abstract                 = {This paper presents an overview of the challenges and opportunities when designing digital integrated circuits in nano-scale technologies. Major applications requirements and nano-technologies design limitations are introduced. Design solutions currently under development like adaptive techniques aiming to cope with variations and to track an optimal energy operating point are presented. },
  Doi                      = {http://dx.doi.org/10.1016/j.sse.2013.02.030},
  ISSN                     = {0038-1101},
  Keywords                 = {Nano-scale devices},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0038110113000919}
}

@Article{Belov2015619,
  Title                    = {Design and Operation of the BES-III Distributed Computing System },
  Author                   = {S. Belov and B. Suo and Z.Y. Deng and V. Korenkov and W.D. Li and T. Lin and Z.T. Ma and C. Nicholson and I. Pelevanyuk and V. Trofimov and A. Uzhinskiy and T. Yan and X.F. Yan and X.M. Zhang and A. Zhemchugov},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {4th International Young Scientist Conference on Computational Science },
  Pages                    = {619 - 624},
  Volume                   = {66},

  Abstract                 = {Abstract The paper summarizes general information, the latest results and development plans of the BES-III distributed computing system. The BES-III experiment at the Institute of High Energy Physics (Beijing, China) is aimed at the precision measurements in e+e- annihilation at the energy range from 2.0 to 4.6 GeV. The world's largest samples of J/psi and psi’ events and unique samples of \{XYZ\} data have been already collected. To process the BES-III experiment's data the distributed computing infrastructure based on \{DIRAC\} interware has been setup and became operational since 2013. The work was done in order to tune and enhance \{DIRAC\} itself for BES-III purposes: monitoring system and data transfer system were developed. Experience of the BES-III development team may be very useful for medium scale \{HEP\} experiments aiming to apply distributed data processing in their computing model. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.11.070},
  ISSN                     = {1877-0509},
  Keywords                 = {Distributed computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915034195}
}

@Article{DelBen2015120,
  Title                    = {Enabling simulation at the fifth rung of DFT: Large scale \{RPA\} calculations with excellent time to solution },
  Author                   = {Mauro Del Ben and Ole Schütt and Tim Wentz and Peter Messmer and Jürg Hutter and Joost VandeVondele},
  Journal                  = {Computer Physics Communications },
  Year                     = {2015},
  Pages                    = {120 - 129},
  Volume                   = {187},

  Abstract                 = {Abstract The Random Phase Approximation (RPA), which represents the fifth rung of accuracy in Density Functional Theory (DFT), is made practical for large systems. Energies of condensed phase systems containing thousands of explicitly correlated electrons and 1500 atoms can now be computed in minutes and less than 1 h, respectively. \{GPU\} acceleration is employed for dense and sparse linear algebra, while communication is minimized by a judicious data layout. The performance of the algorithms, implemented in the widely used \{CP2K\} simulation package, has been investigated on hybrid Cray \{XC30\} and \{XK7\} architectures, up to 16,384 nodes. Our results emphasize the importance of good network performance, in addition to the availability of \{GPUs\} and generous on node memory. A new level of predictivity has thus become available for routine application in Monte Carlo and molecular dynamics simulations. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2014.10.021},
  ISSN                     = {0010-4655},
  Keywords                 = {Random phase approximation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465514003671}
}

@Article{Bergmann2015176,
  Title                    = {Algorithmic choices in \{WARP\} – A framework for continuous energy Monte Carlo neutron transport in general 3D geometries on \{GPUs\} },
  Author                   = {Ryan M. Bergmann and Jasmina L. Vujić},
  Journal                  = {Annals of Nuclear Energy },
  Year                     = {2015},
  Pages                    = {176 - 193},
  Volume                   = {77},

  Abstract                 = {Abstract In recent supercomputers, general purpose graphics processing units (GPGPUs) are a significant faction of the supercomputer’s total computational power. \{GPGPUs\} have different architectures compared to central processing units (CPUs), and for Monte Carlo neutron transport codes used in nuclear engineering to take advantage of these coprocessor cards, transport algorithms must be changed to execute efficiently on them. \{WARP\} is a continuous energy Monte Carlo neutron transport code that has been written to do this. The main thrust of \{WARP\} is to adapt previous event-based transport algorithms to the new \{GPU\} hardware; the algorithmic choices for all parts of which are presented in this paper. It is found that remapping history data references increases the \{GPU\} processing rate when histories start to complete. The main reason for this is that completed data are eliminated from the address space, threads are kept busy, and memory bandwidth is not wasted on checking completed data. Remapping also allows the interaction kernels to be launched concurrently, improving efficiency. The OptiX ray tracing framework and \{CUDPP\} library are used for geometry representation and parallel dataset-side operations, ensuring high performance and reliability. },
  Doi                      = {http://dx.doi.org/10.1016/j.anucene.2014.10.039},
  ISSN                     = {0306-4549},
  Keywords                 = {Monte Carlo},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0306454914005787}
}

@Article{Betelin2015269,
  Title                    = {Supercomputer predictive modeling for ensuring space flight safety },
  Author                   = {V.B. Betelin and N.N. Smirnov and V.F. Nikitin},
  Journal                  = {Acta Astronautica },
  Year                     = {2015},
  Pages                    = {269 - 277},
  Volume                   = {109},

  Abstract                 = {Abstract Development of new types of rocket engines, as well as upgrading the existing engines needs computer aided design and mathematical tools for supercomputer modeling of all basic processes of mixing, ignition, combustion and outflow through the nozzle. Even small upgrades and changes introduced in existing rocket engines without proper simulations cause severe accidents at launch places witnessed recently. The paper presents the results of computer code developing, verification and validation, making it possible to simulate unsteady processes of ignition and combustion in rocket engines. },
  Doi                      = {http://dx.doi.org/10.1016/j.actaastro.2014.11.014},
  ISSN                     = {0094-5765},
  Keywords                 = {Combustion},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0094576514004469}
}

@Article{Bilal2014189,
  Title                    = {A taxonomy and survey on Green Data Center Networks },
  Author                   = {Kashif Bilal and Saif Ur Rehman Malik and Osman Khalid and Abdul Hameed and Enrique Alvarez and Vidura Wijaysekara and Rizwana Irfan and Sarjan Shrestha and Debjyoti Dwivedy and Mazhar Ali and Usman Shahid Khan and Assad Abbas and Nauman Jalil and Samee U. Khan},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2014},
  Note                     = {Special Section: Intelligent Big Data ProcessingSpecial Section: Behavior Data Security Issues in Network Information PropagationSpecial Section: Energy-efficiency in Large Distributed Computing ArchitecturesSpecial Section: eScience Infrastructure and Applications },
  Pages                    = {189 - 208},
  Volume                   = {36},

  Abstract                 = {Abstract Data centers are growing exponentially (in number and size) to accommodate the escalating user and application demands. Likewise, the concerns about the environmental impacts, energy needs, and electricity cost of data centers are also growing. Network infrastructure being the communication backbone of the data center plays a pivotal role in the data center’s scalability, performance, energy consumption, and cost. Research community is endeavoring hard to overcome the challenges faced by the legacy Data Center Networks (DCNs). Serious efforts have been made to handle the problems in various \{DCN\} areas. This survey presents significant insights to the state-of-the-art research conducted pertaining to the \{DCN\} domain along with a detailed discussion of the energy efficiency aspects of the DCNs. The authors explored: (a) \{DCN\} architectures (electrical, optical, and hybrid), (b) network traffic management and characterization, (c) \{DCN\} performance monitoring, (d) network-aware resource allocation, (e) \{DCN\} experimentation techniques, and (f) energy efficiency. The survey presents an overview of the ongoing research in the broad domain of \{DCNs\} and highlights the challenges faced by the \{DCN\} research community. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2013.07.006},
  ISSN                     = {0167-739X},
  Keywords                 = {Data center},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X13001519}
}

@Article{Bishop2015262,
  Title                    = {Direct numerical simulations in solid mechanics for understanding the macroscale effects of microscale material variability },
  Author                   = {Joseph E. Bishop and John M. Emery and Richard V. Field and Christopher R. Weinberger and David J. Littlewood},
  Journal                  = {Computer Methods in Applied Mechanics and Engineering },
  Year                     = {2015},
  Pages                    = {262 - 289},
  Volume                   = {287},

  Abstract                 = {Abstract A fundamental challenge for the quantification of uncertainty in solid mechanics is understanding how microscale material variability is manifested at the macroscale. In an era of petascale computing and future exascale computing, it is now possible to perform direct numerical simulations (DNS) in solid mechanics where the microstructure is modeled directly in a macroscale structure. Using this \{DNS\} capability, we investigate the macroscale response of polycrystalline microstructures and the accuracy of homogenization theory for upscaling the microscale response. Using a massively parallel finite-element code, we perform an ensemble of direct numerical simulations in which polycrystalline microstructures are embedded throughout a macroscale structure. The largest simulations model approximately 420 thousand grains within an I-beam. The inherently random \{DNS\} results are compared with corresponding simulations based on the deterministic governing equations and material properties obtained from homogenization theory. Evidence is sought for both surface effects and other higher-order effects as predicted by homogenization theory for macroscale structures containing finite microstructures. },
  Doi                      = {http://dx.doi.org/10.1016/j.cma.2015.01.017},
  ISSN                     = {0045-7825},
  Keywords                 = {Polycrystal},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045782515000377}
}

@Article{Blau20132856,
  Title                    = {g_contacts: Fast contact search in bio-molecular ensemble data },
  Author                   = {Christian Blau and Helmut Grubmuller},
  Journal                  = {Computer Physics Communications },
  Year                     = {2013},
  Number                   = {12},
  Pages                    = {2856 - 2859},
  Volume                   = {184},

  Abstract                 = {Abstract Short-range interatomic interactions govern many bio-molecular processes. Therefore, identifying close interaction partners in ensemble data is an essential task in structural biology and computational biophysics. A contact search can be cast as a typical range search problem for which efficient algorithms have been developed. However, none of those has yet been adapted to the context of macromolecular ensembles, particularly in a molecular dynamics (MD) framework. Here a set-decomposition algorithm is implemented which detects all contacting atoms or residues in maximum O ( N log ( N ) ) run-time, in contrast to the O ( N 2 ) complexity of a brute-force approach. Program summary Program title: g_contacts Catalogue identifier: AEQA_v1_0 Program summary URL:http://cpc.cs.qub.ac.uk/summaries/AEQA_v1_0.html Program obtainable from: \{CPC\} Program Library, Queen’s University, Belfast, N. Ireland Licensing provisions: Standard \{CPC\} licence, http://cpc.cs.qub.ac.uk/licence/licence.html No. of lines in distributed program, including test data, etc.: 8945 No. of bytes in distributed program, including test data, etc.: 981604 Distribution format: tar.gz Programming language: C99. Computer: PC. Operating system: Linux. RAM: ≈Size of input frame Classification: 3, 4.14. External routines: Gromacs 4.6[1] Nature of problem: Finding atoms or residues that are closer to one another than a given cut-off. Solution method: Excluding distant atoms from distance calculations by decomposing the given set of atoms into disjoint subsets. Running time: ≤ O ( N log ( N ) ) References: [1] S. Pronk, S. Pall, R. Schulz, P. Larsson, P. Bjelkmar, R. Apostolov, M. R. Shirts, J.C. Smith, P. M. Kasson, D. van der Spoel, B. Hess and Erik Lindahl, Gromacs 4.5: a high-throughput and highly parallel open source molecular simulation toolkit, Bioinformatics 29 (7) (2013). },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2013.07.018},
  ISSN                     = {0010-4655},
  Keywords                 = {Range search},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465513002464}
}

@Article{Blom2015211,
  Title                    = {Multi-level acceleration with manifold mapping of strongly coupled partitioned fluid–structure interaction },
  Author                   = {D.S. Blom and A.H. van Zuijlen and H. Bijl},
  Journal                  = {Computer Methods in Applied Mechanics and Engineering },
  Year                     = {2015},
  Pages                    = {211 - 231},
  Volume                   = {296},

  Abstract                 = {Abstract To accelerate the convergence of strongly coupled partitioned fluid–structure interaction simulations, the manifold mapping algorithm is used which combines a high-fidelity model with a low-fidelity model. A computationally inexpensive low-fidelity fluid–structure interaction (FSI) model is combined with a high-fidelity \{FSI\} model in order to accelerate the convergence of the coupling iterations of the high-fidelity \{FSI\} model. The manifold mapping algorithm is applied to the fluid–structure interaction problem in order to minimize the fluid–structure interface residual. Originating from multi-fidelity optimization, the manifold mapping algorithm is applied for the first time in a simulation context, instead of an optimization context. The manifold mapping algorithm is applied to an unsteady flow in a one-dimensional tube, incompressible laminar flow over a fixed cylinder with an attached flexible flap, and a wave propagation in a three-dimensional elastic tube problem. A reduction of approximately 50% in terms of high-fidelity iterations is achieved compared to the state-of-the-art Interface Quasi-Newton Inverse Least Squares algorithm. The convergence of the high-fidelity model is accelerated even further when information from previous time steps is reused. },
  Doi                      = {http://dx.doi.org/10.1016/j.cma.2015.08.004},
  ISSN                     = {0045-7825},
  Keywords                 = {Fluid–structure interaction},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045782515002509}
}

@Article{Bobkov2015224,
  Title                    = {The Unification of Space Qualified Integrated Circuits by Example of International Space Project GAMMA-400 },
  Author                   = {S.G. Bobkov and O.V. Serdin and A.I. Arkhangelskiy and I.V. Arkhangelskaja and S.I. Suchkov and N.P. Topchiev},
  Journal                  = {Physics Procedia },
  Year                     = {2015},
  Note                     = {Fundamental Research in Particle Physics and Cosmophysics },
  Pages                    = {224 - 231},
  Volume                   = {74},

  Abstract                 = {Abstract The problem of electronic component unification at the different levels (circuits, interfaces, hardware and software) used in space industry is considered. The task of computer systems for space purposes developing is discussed by example of scientific data acquisition system for space project GAMMA-400. The basic characteristics of high reliable and fault tolerant chips developed by \{SRISA\} \{RAS\} for space applicable computational systems are given. To reduce power consumption and enhance data reliability, embedded system interconnect made hierarchical: upper level is Serial RapidIO 1x or 4x with rate transfer 1.25 Gbaud; next level - SpaceWire with rate transfer up to 400 Mbaud and lower level - MIL-STD-1553B and RS232/RS485. The Ethernet 10/100 is technology interface and provided connection with the previously released modules too. Systems interconnection allows creating different redundancy systems. Designers can develop heterogeneous systems that employ the peer-to-peer networking performance of Serial RapidIO using multiprocessor clusters interconnected by SpaceWire. },
  Doi                      = {http://dx.doi.org/10.1016/j.phpro.2015.09.208},
  ISSN                     = {1875-3892},
  Keywords                 = {\{SOI\} technology},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1875389215014078}
}

@Article{Bouguerra20142411,
  Title                    = {Fault-tolerant scheduling on parallel systems with non-memoryless failure distributions },
  Author                   = {Mohamed Slim Bouguerra and Derrick Kondo and Fernando Mendonca and Denis Trystram},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2014},
  Number                   = {5},
  Pages                    = {2411 - 2422},
  Volume                   = {74},

  Abstract                 = {Abstract As large parallel systems increase in size and complexity, failures are inevitable and exhibit complex space and time dynamics. Most often, in real systems, failure rates are increasing or decreasing over time. Considering non-memoryless failure distributions, we study a bi-objective scheduling problem of optimizing application makespan and reliability. In particular, we determine whether one can optimize both makespan and reliability simultaneously, or whether one metric must be degraded in order to improve the other. We also devise scheduling algorithms for achieving (approximately) optimal makespan or reliability. When failure rates decrease, we prove that makespan and reliability are opposing metrics. In contrast, when failure rates increase, we prove that one can optimize both makespan and reliability simultaneously. Moreover, we show that the largest processing time (LPT) list scheduling algorithm achieves good performance when processors are of uniform speed. The implications of our findings are the accelerated completion and improved reliability of parallel jobs executed across large distributed systems. Finally, we conduct simulations to investigate the impact of failures on the performance, which is done using an actual application of biological sequence comparison. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2014.01.005},
  ISSN                     = {0743-7315},
  Keywords                 = {Fault tolerance},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S074373151400015X}
}

@Article{Boyd201443,
  Title                    = {The OpenMOC method of characteristics neutral particle transport code },
  Author                   = {William Boyd and Samuel Shaner and Lulu Li and Benoit Forget and Kord Smith},
  Journal                  = {Annals of Nuclear Energy },
  Year                     = {2014},
  Pages                    = {43 - 52},
  Volume                   = {68},

  Abstract                 = {Abstract The method of characteristics (MOC) is a numerical integration technique for partial differential equations, and has seen widespread use for reactor physics lattice calculations. The exponential growth in computing power has finally brought the possibility for high-fidelity full core \{MOC\} calculations within reach. The OpenMOC code is being developed at the Massachusetts Institute of Technology to investigate algorithmic acceleration techniques and parallel algorithms for MOC. OpenMOC is a free, open source code written using modern software languages such as C/C++ and \{CUDA\} with an emphasis on extensible design principles for code developers and an easy to use Python interface for code users. The present work describes the OpenMOC code and illustrates its ability to model large problems accurately and efficiently. },
  Doi                      = {http://dx.doi.org/10.1016/j.anucene.2013.12.012},
  ISSN                     = {0306-4549},
  Keywords                 = {Method of characteristics},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0306454913006634}
}

@Article{burau2010picongpu,
  Title                    = {PIConGPU: A fully relativistic particle-in-cell code for a GPU cluster},
  Author                   = {Burau, Heiko and Widera, Ren{\'e}e and H{\"o}nig, Wolfgang and Juckeland, Guido and Debus, Alexander and Kluge, Thomas and Schramm, Ulrich and Cowan, Tomas E and Sauerbrey, Roland and Bussmann, Michael},
  Journal                  = {Plasma Science, IEEE Transactions on},
  Year                     = {2010},
  Number                   = {10},
  Pages                    = {2831--2839},
  Volume                   = {38},

  Publisher                = {IEEE}
}

@Article{CaínoLores201546,
  Title                    = {A cloudification methodology for multidimensional analysis: Implementation and application to a railway power simulator },
  Author                   = {Silvina Caíno-Lores and Alberto García Fernández and Félix García-Carballeira and Jesús Carretero Pérez},
  Journal                  = {Simulation Modelling Practice and Theory },
  Year                     = {2015},
  Pages                    = {46 - 62},
  Volume                   = {55},

  Abstract                 = {Abstract Many scientific areas make extensive use of computer simulations to study complex real-world processes. These computations are typically very resource-intensive and present scalability issues as experiments get larger even in dedicated clusters, since these are limited by their own hardware resources. Cloud computing raises as an option to move forward into the ideal unlimited scalability by providing virtually infinite resources, yet applications must be adapted to this new paradigm. This process of converting and/or migrating an application and its data in order to make use of cloud computing is sometimes known as cloudifying the application. We propose a generalist cloudification method based in the MapReduce paradigm to migrate scientific simulations into the cloud to provide greater scalability. We analysed its viability by applying it to a real-world railway power consumption simulatior and running the resulting implementation on Hadoop \{YARN\} over Amazon EC2. Our tests show that the cloudified application is highly scalable and there is still a large margin to improve the theoretical model and its implementations, and also to extend it to a wider range of simulations. We also propose and evaluate a multidimensional analysis tool based on the cloudified application. It generates, executes and evaluates several experiments in parallel, for the same simulation kernel. The results we obtained indicate that out methodology is suitable for resource intensive simulations and multidimensional analysis, as it improves infrastructure’s utilization, efficiency and scalability when running many complex experiments. },
  Doi                      = {http://dx.doi.org/10.1016/j.simpat.2015.04.002},
  ISSN                     = {1569-190X},
  Keywords                 = {Railway simulator},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1569190X15000611}
}

@Article{Carretero201578,
  Title                    = {Introduction to the special section on “Optimization of parallel scientific applications with accelerated high-performance computers” },
  Author                   = {Jesus Carretero and Javier Garcia-Blas and Maya G. Neytcheva},
  Journal                  = {Computers \& Electrical Engineering },
  Year                     = {2015},
  Pages                    = {78 - 80},
  Volume                   = {46},

  Doi                      = {http://dx.doi.org/10.1016/j.compeleceng.2015.09.017},
  ISSN                     = {0045-7906},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045790615003249}
}

@Article{Carrillo201242,
  Title                    = {Advancing interconnect density for spiking neural network hardware implementations using traffic-aware adaptive network-on-chip routers },
  Author                   = {Snaider Carrillo and Jim Harkin and Liam McDaid and Sandeep Pande and Seamus Cawley and Brian McGinley and Fearghal Morgan},
  Journal                  = {Neural Networks },
  Year                     = {2012},
  Pages                    = {42 - 57},
  Volume                   = {33},

  Abstract                 = {The brain is highly efficient in how it processes information and tolerates faults. Arguably, the basic processing units are neurons and synapses that are interconnected in a complex pattern. Computer scientists and engineers aim to harness this efficiency and build artificial neural systems that can emulate the key information processing principles of the brain. However, existing approaches cannot provide the dense interconnect for the billions of neurons and synapses that are required. Recently a reconfigurable and biologically inspired paradigm based on network-on-chip (NoC) and spiking neural networks (SNNs) has been proposed as a new method of realising an efficient, robust computing platform. However, the use of the NoC as an interconnection fabric for large-scale \{SNNs\} demands a good trade-off between scalability, throughput, neuron/synapse ratio and power consumption. This paper presents a novel traffic-aware, adaptive NoC router, which forms part of a proposed embedded mixed-signal \{SNN\} architecture called \{EMBRACE\} (EMulating Biologically-inspiRed ArChitectures in hardwarE). The proposed adaptive NoC router provides the inter-neuron connectivity for EMBRACE, maintaining router communication and avoiding dropped router packets by adapting to router traffic congestion. Results are presented on throughput, power and area performance analysis of the adaptive router using a 90 nm \{CMOS\} technology which outperforms existing NoCs in this domain. The adaptive behaviour of the router is also verified on a Stratix \{II\} \{FPGA\} implementation of a 4 × 2 router array with real-time traffic congestion. The presented results demonstrate the feasibility of using the proposed adaptive NoC router within the \{EMBRACE\} architecture to realise large-scale \{SNNs\} on embedded hardware. },
  Doi                      = {http://dx.doi.org/10.1016/j.neunet.2012.04.004},
  ISSN                     = {0893-6080},
  Keywords                 = {Adaptive router},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0893608012001104}
}

@Article{Cartwright,
  Title                    = {Loading and Injection of Maxwellian Distributions in Particle Simulations },
  Author                   = {K.L. Cartwright and J.P. Verboncoeur and C.K. Birdsall},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2000},
  Number                   = {2},
  Pages                    = {483 - 513},
  Volume                   = {162},

  Abstract                 = {Existing and new particle loading and injection algorithms for particle simulations are analyzed to determine numerical accuracy and computational efficiency. Emphasis has been placed on loading and emission of Maxwellian, drifting Maxwellian, and cutoff Maxwellian velocity distributions. Once a velocity distribution has been inverted for loading or injection, time-centering of the position and velocity is necessary in order to maintain second-order accuracy. Here, the accuracy of these methods is determined and compared to three analytic test cases with spatially varying, time-dependent, and time-independent electric fields in a homogeneous magnetic field and a self-consistent crossed-field diode. The initial push is shown to be important in calculating the correct electric field at the boundary where particles are injected, in relaxing constraints on the time step, and in providing reliable field fluctuations due to particle statistics. },
  Doi                      = {http://dx.doi.org/10.1006/jcph.2000.6549},
  ISSN                     = {0021-9991},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999100965495}
}

@Article{Casanova20142899,
  Title                    = {Versatile, scalable, and accurate simulation of distributed applications and platforms },
  Author                   = {Henri Casanova and Arnaud Giersch and Arnaud Legrand and Martin Quinson and Frédéric Suter},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2014},
  Number                   = {10},
  Pages                    = {2899 - 2917},
  Volume                   = {74},

  Abstract                 = {Abstract The study of parallel and distributed applications and platforms, whether in the cluster, grid, peer-to-peer, volunteer, or cloud computing domain, often mandates empirical evaluation of proposed algorithmic and system solutions via simulation. Unlike direct experimentation via an application deployment on a real-world testbed, simulation enables fully repeatable and configurable experiments for arbitrary hypothetical scenarios. Two key concerns are accuracy (so that simulation results are scientifically sound) and scalability (so that simulation experiments can be fast and memory-efficient). While the scalability of a simulator is easily measured, the accuracy of many state-of-the-art simulators is largely unknown because they have not been sufficiently validated. In this work we describe recent accuracy and scalability advances made in the context of the SimGrid simulation framework. A design goal of SimGrid is that it should be versatile, i.e., applicable across all aforementioned domains. We present quantitative results that show that SimGrid compares favorably with state-of-the-art domain-specific simulators in terms of scalability, accuracy, or the trade-off between the two. An important implication is that, contrary to popular wisdom, striving for versatility in a simulator is not an impediment but instead is conducive to improving both accuracy and scalability. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2014.06.008},
  ISSN                     = {0743-7315},
  Keywords                 = {Simulation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731514001105}
}

@Article{Casanova20157,
  Title                    = {On the impact of process replication on executions of large-scale parallel applications with coordinated checkpointing },
  Author                   = {Henri Casanova and Yves Robert and Frédéric Vivien and Dounia Zaidouni},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2015},
  Note                     = {Special Section: A Note on New Trends in Data-Aware Scheduling and Resource Provisioning in Modern \{HPC\} Systems },
  Pages                    = {7 - 19},
  Volume                   = {51},

  Abstract                 = {Abstract Processor failures in post-petascale parallel computing platforms are common occurrences. The traditional fault-tolerance solution, checkpoint–rollback–recovery, severely limits parallel efficiency. One solution is to replicate application processes so that a processor failure does not necessarily imply an application failure. Process replication, combined with checkpoint–rollback–recovery, has been recently advocated. We first derive novel theoretical results for Exponential failure distributions, namely exact values for the Mean Number of Failures To Interruption and the Mean Time To Interruption. We then extend these results to arbitrary failure distributions, obtaining closed-form solutions for Weibull distributions. Finally, we evaluate process replication in simulation using both synthetic and real-world failure traces so as to quantify average application makespan. One interesting result from these experiments is that, when process replication is used, application performance is not sensitive to the checkpointing period, provided that period is within a large neighborhood of the optimal period. More generally, our empirical results make it possible to identify regimes in which process replication is beneficial. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2015.04.003},
  ISSN                     = {0167-739X},
  Keywords                 = {Fault-tolerance},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X15000953}
}

@Article{Castro20142845,
  Title                    = {Adaptive thread mapping strategies for transactional memory applications },
  Author                   = {Márcio Castro and Luís Fabrício W. Góes and Jean-François Méhaut},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2014},
  Number                   = {9},
  Pages                    = {2845 - 2859},
  Volume                   = {74},

  Abstract                 = {Abstract Transactional Memory (TM) is a programmer friendly alternative to traditional lock-based concurrency. Although it intends to simplify concurrent programming, the performance of the applications still relies on how frequent they synchronize and the way they access shared data. These aspects must be taken into consideration if one intends to exploit the full potential of modern multicore platforms. Since these platforms feature complex memory hierarchies composed of different levels of cache, applications may suffer from memory latencies and bandwidth problems if threads are not properly placed on cores. An interesting approach to efficiently exploit the memory hierarchy is called thread mapping. However, a single fixed thread mapping cannot deliver the best performance when dealing with a large range of transactional workloads, \{TM\} systems and platforms. In this article, we propose and implement in a \{TM\} system a set of adaptive thread mapping strategies for \{TM\} applications to tackle this problem. They range from simple strategies that do not require any prior knowledge to strategies based on Machine Learning techniques. Taking the Linux default strategy as baseline, we achieved performance improvements of up to 64.4% on a set of synthetic applications and an overall performance improvement of up to 16.5% on the standard \{STAMP\} benchmark suite. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2014.05.008},
  ISSN                     = {0743-7315},
  Keywords                 = {Transactional memory},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731514001026}
}

@Article{Catasta201419,
  Title                    = {B-hist: Entity-centric search over personal web browsing history },
  Author                   = {Michele Catasta and Alberto Tonon and Gianluca Demartini and Jean-Eudes Ranvier and Karl Aberer and Philippe Cudré-Mauroux},
  Journal                  = {Web Semantics: Science, Services and Agents on the World Wide Web },
  Year                     = {2014},
  Note                     = {Semantic Web Challenge 2013 },
  Pages                    = {19 - 25},
  Volume                   = {27–28},

  Abstract                 = {Abstract Web Search is increasingly entity centric; as a large fraction of common queries target specific entities, search results get progressively augmented with semi-structured and multimedia information about those entities. However, search over personal web browsing history still revolves around keyword-search mostly. In this paper, we present a novel approach to answer queries over web browsing logs that takes into account entities appearing in the web pages, user activities, as well as temporal information. Our system, B-hist, aims at providing web users with an effective tool for searching and accessing information they previously looked up on the web by supporting multiple ways of filtering results using clustering and entity-centric search. In the following, we present our system and motivate our User Interface (UI) design choices by detailing the results of a survey on web browsing and history search. In addition, we present an empirical evaluation of our entity-based approach used to cluster web pages. },
  Doi                      = {http://dx.doi.org/10.1016/j.websem.2014.07.003},
  ISSN                     = {1570-8268},
  Keywords                 = {Browsing history},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1570826814000511}
}

@Article{Celaya201528,
  Title                    = {Fair scheduling of bag-of-tasks applications on large-scale platforms },
  Author                   = {Javier Celaya and Unai Arronategui},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2015},
  Pages                    = {28 - 44},
  Volume                   = {49},

  Abstract                 = {Abstract Users of distributed computing platforms want to obtain a fair share of the resources they use. With respect to the amount of computation, the most suitable measure of fairness is the stretch. It describes the slowdown that the applications suffer for being executed in a shared platform, in contrast to being executed alone. In this paper, we present a decentralized scheduling policy that minimizes the maximum stretch among user-submitted applications. With two reasonable assumptions, that can be deduced from existing system traces, we are able to minimize the stretch using only local information. In this way, we avoid a centralized design and provide scalability and fault tolerance. As a result, our policy performs just 11% worse than a centralized implementation, and largely outperforms other common policies. Additionally, it easily scales to hundreds of thousands of nodes. We presume that it can scale to millions with a minimal overhead. Finally, we also show that preemption is crucial to provide fairness in any case. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2015.03.002},
  ISSN                     = {0167-739X},
  Keywords                 = {Fairness},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X15000552}
}

@Article{Chakroun20131563,
  Title                    = {Combining multi-core and \{GPU\} computing for solving combinatorial optimization problems },
  Author                   = {I. Chakroun and N. Melab and M. Mezmaz and D. Tuyttens},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2013},
  Note                     = {Heterogeneity in Parallel and Distributed Computing },
  Number                   = {12},
  Pages                    = {1563 - 1577},
  Volume                   = {73},

  Abstract                 = {Abstract In this paper, we revisit the design and implementation of Branch-and-Bound (B&amp;B) algorithms for solving large combinatorial optimization problems on GPU-enhanced multi-core machines. B&amp;B is a tree-based optimization method that uses four operators (selection, branching, bounding and pruning) to build and explore a highly irregular tree representing the solution space. In our previous works, we have proposed a GPU-accelerated approach in which only a single \{CPU\} core is used and only the bounding operator is performed on the \{GPU\} device. Here, we extend the approach (LL-GB&amp;B) in order to minimize the CPU–GPU communication latency and thread divergence. Such an objective is achieved through a GPU-based fine-grained parallelization of the branching and pruning operators in addition to the bounding one. The second contribution consists in investigating the combination of a \{GPU\} with multi-core processing. Two scenarios have been explored leading to two approaches: a concurrent (RLL-GB&amp;B) and a cooperative one (PLL-GB&amp;B). In the first one, the exploration process is performed concurrently by the \{GPU\} and the \{CPU\} cores. In the cooperative approach, the \{CPU\} cores prepare and off-load to \{GPU\} pools of tree nodes using data streaming while the \{GPU\} performs the exploration. The different approaches have been extensively experimented on the Flowshop scheduling problem. Compared to a single CPU-based execution, LL-GB&amp;B allows accelerations up to ( × 160) for large problem instances. Moreover, when combining multi-core and GPU, we figure out that using RLL-GB&amp;B is not beneficial while PLL-GB&amp;B enables an improvement up to 36% compared to LL-GB&amp;B. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2013.07.023},
  ISSN                     = {0743-7315},
  Keywords                 = {Multi-core computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731513001615}
}

@Article{Chang2011370,
  Title                    = {Special Section: Future Generation Information Technology },
  Author                   = {Ruay-Shiung Chang and Tai-hoon Kim},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2011},
  Number                   = {4},
  Pages                    = {370 - 371},
  Volume                   = {27},

  Doi                      = {http://dx.doi.org/10.1016/j.future.2010.10.017},
  ISSN                     = {0167-739X},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X10002104}
}

@Article{Chen201199,
  Title                    = {Petascale direct numerical simulation of turbulent combustion—fundamental insights towards predictive models },
  Author                   = {Jacqueline H. Chen},
  Journal                  = {Proceedings of the Combustion Institute },
  Year                     = {2011},
  Number                   = {1},
  Pages                    = {99 - 123},
  Volume                   = {33},

  Abstract                 = {The advent of petascale computing applied to direct numerical simulation (DNS) of turbulent combustion has transformed our ability to interrogate fine-grained ‘turbulence-chemistry’ interactions in canonical and laboratory configurations. In particular, three-dimensional DNS, at moderate Reynolds numbers and with complex chemistry, is providing unprecedented levels of detail to isolate and reveal fundamental causal relationships between turbulence, mixing and reaction. This information is leading to new physical insight, providing benchmark data for assessing model assumptions, suggesting new closure hypotheses, and providing interpretation of statistics obtained from lower-dimensional measurements. In this paper the various roles of petascale \{DNS\} are illustrated through selected examples related to lifted flame stabilization, premixed and stratified flame propagation in intense turbulence, and extinction and reignition in turbulent non-premixed jet flames. Extending the \{DNS\} envelope to higher Reynolds numbers, higher pressures, and greater chemical complexity will require exascale computing in the next decade. The future outlook of \{DNS\} in terms of challenges and opportunities in this regard are addressed. },
  Doi                      = {http://dx.doi.org/10.1016/j.proci.2010.09.012},
  ISSN                     = {1540-7489},
  Keywords                 = {Direct Numerical Simulation (DNS)},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1540748910003962}
}

@Article{Chien20111987,
  Title                    = {10x10: A General-purpose Architectural Approach to Heterogeneity and Energy Efficiency },
  Author                   = {Andrew A. Chien and Allan Snavely and Mark Gahagan},
  Journal                  = {Procedia Computer Science },
  Year                     = {2011},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2011 },
  Pages                    = {1987 - 1996},
  Volume                   = {4},

  Abstract                 = {Two decades of microprocessor architecture driven by quantitative 90/10 optimization has delivered an extraordinary 1000-fold improvement in microprocessor performance, enabled by transistor scaling which improved density, speed, and energy. Recent generations of technology have produced limited benefits in transistor speed and power, so as a result the industry has turned to multicore parallelism for performance scaling. Long-range studies [1,2] indicate that radical approaches are needed in the coming decade – extreme parallelism, near-threshold voltage scaling (and resulting poor single-thread performance), and tolerance of extreme variability – are required to maximize energy efficiency and compute density. These changes create major new challenges in architecture and software. As a result, the performance and energy-efficiency advantages of heterogeneous architectures are increasingly attractive. However, computing has lacked an optimization paradigm in which to systematically analyze, assess, and implement heterogeneous computing. We propose a new paradigm, “10x10”, which clusters applications into a set of less frequent cases (ie. 10% cases), and creates customized architecture, implementation, and software solutions for each of these clusters, achieving significantly better energy efficiency and performance. We call this approach “10x10” because the approach is exemplified by optimizing ten different 10% cases, reflecting a shift away from the 90/10 optimization paradigm framed by Amdahl's law [3]. We describe the 10x10 approach, explain how it solves the major obstacles to widespread adoption of heterogeneous architectures, and present a preliminary 10x10 clustering, strawman architecture, and software tool chain approach. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2011.04.217},
  ISSN                     = {1877-0509},
  Keywords                 = {Computer architecture},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050911002754}
}

@Article{Chien201529,
  Title                    = {Versioned Distributed Arrays for Resilience in Scientific Applications: Global View Resilience },
  Author                   = {A. Chien and P. Balaji and P. Beckman and N. Dun and A. Fang and H. Fujita and K. Iskra and Z. Rubenstein and Z. Zheng and R. Schreiber and J. Hammond and J. Dinan and I. Laguna and D. Richards and A. Dubey and B. van Straalen and M. Hoemmen and M. Heroux and K. Teranishi and A. Siegel},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {29 - 38},
  Volume                   = {51},

  Abstract                 = {Abstract Exascale studies project reliability challenges for future high-performance computing (HPC) systems. We propose the Global View Resilience (GVR) system, a library that enables applications to add resilience in a portable, application-controlled fashion using versioned distributed arrays. We describe GVR's interfaces to distributed arrays, versioning, and cross-layer error recovery. Using several large applications (OpenMC, the preconditioned conjugate gradient solver PCG, ddcMD, and Chombo), we evaluate the programmer effort to add resilience. The required changes are small (&lt;2% LOC), localized, and machine-independent, requiring no software architecture changes. We also measure the overhead of adding \{GVR\} versioning and show that generally overheads &lt;2% are achieved. We conclude that GVR's interfaces and implementation are flexible and portable and create a gentle-slope path to tolerate growing error rates in future systems. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.187},
  ISSN                     = {1877-0509},
  Keywords                 = {Resilience},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915009953}
}

@Article{Christen2012956,
  Title                    = {A Performance Study of an Anelastic Wave Propagation Code Using Auto-tuned Stencil Computations },
  Author                   = {Matthias Christen and Olaf Schenk},
  Journal                  = {Procedia Computer Science },
  Year                     = {2012},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2012 },
  Pages                    = {956 - 965},
  Volume                   = {9},

  Abstract                 = {In this paper, we use our stencil code generation and auto-tuning framework Patus to optimize and parallelize the most compute intensive stencil calculations of an anelastic wave propagation code, which was used to conduct numerous significant simulations at the Southern California Earthquake Center. From a straight-forward specification of the stencil calculation, Patus automatically creates an implementation targeted at the chosen hardware platform and applies hardware-specific optimizations including cache blocking, loop unrolling, and explicit vectorization. We show that, using this approach, we are able to speed up individual compute kernels by a factor of 2.4× on average, and reduce the time required to compute one time step of the entire simulation by 47% in a weak and up to 129% in a strong thread scaling setting. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2012.04.102},
  ISSN                     = {1877-0509},
  Keywords                 = {wave propagation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050912002232}
}

@Article{Collange201583,
  Title                    = {Numerical reproducibility for the parallel reduction on multi- and many-core architectures },
  Author                   = {Sylvain Collange and David Defour and Stef Graillat and Roman Iakymchuk},
  Journal                  = {Parallel Computing },
  Year                     = {2015},
  Pages                    = {83 - 97},
  Volume                   = {49},

  Abstract                 = {Abstract On modern multi-core, many-core, and heterogeneous architectures, floating-point computations, especially reductions, may become non-deterministic and, therefore, non-reproducible mainly due to the non-associativity of floating-point operations. We introduce an approach to compute the correctly rounded sums of large floating-point vectors accurately and efficiently, achieving deterministic results by construction. Our multi-level algorithm consists of two main stages: first, a filtering stage that relies on fast vectorized floating-point expansion; second, an accumulation stage based on superaccumulators in a high-radix carry-save representation. We present implementations on recent Intel desktop and server processors, Intel Xeon Phi co-processors, and both \{AMD\} and \{NVIDIA\} GPUs. We show that numerical reproducibility and bit-perfect accuracy can be achieved at no additional cost for large sums that have dynamic ranges of up to 90 orders of magnitude by leveraging arithmetic units that are left underused by standard reduction algorithms. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2015.09.001},
  ISSN                     = {0167-8191},
  Keywords                 = {Parallel floating-point summation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819115001155}
}

@Article{Collins2015,
  Title                    = {Progress in Fast, Accurate Multi-scale Climate Simulations },
  Author                   = {W.D. Collins and H. Johansen and K.J. Evans and C.S. Woodward and P.M. Caldwell},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {2006 - 2015},
  Volume                   = {51},

  Abstract                 = {Abstract We present a survey of physical and computational techniques that have the potential to contribute to the next generation of high-fidelity, multi-scale climate simulations. Examples of the climate science problems that can be investigated with more depth with these computational improvements include the capture of remote forcings of localized hydrological extreme events, an accurate representation of cloud features over a range of spatial and temporal scales, and parallel, large ensembles of simulations to more effectively explore model sensitivities and un- certainties. Numerical techniques, such as adaptive mesh refinement, implicit time integration, and separate treatment of fast physical time scales are enabling improved accuracy and fidelity in simulation of dynamics and allowing more complete representations of climate features at the global scale. At the same time, partnerships with computer science teams have focused on taking advantage of evolving computer architectures such as many-core processors and GPUs. As a result, approaches which were previously considered prohibitively costly have become both more efficient and scalable. In combination, progress in these three critical areas is poised to transform climate modeling in the coming decades. These topics have been presented within a workshop titled, “Numerical and Computational Developments to Advance Multiscale Earth System Models (MSESM ‘15),” as part of the International Conference on Computational Sciences, Reykjavik, Iceland, June 1-3, 2015. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.465},
  ISSN                     = {1877-0509},
  Keywords                 = {Earth system models},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915012739}
}

@Article{Collins20152006,
  Title                    = {Progress in Fast, Accurate Multi-scale Climate Simulations },
  Author                   = {W.D. Collins and H. Johansen and K.J. Evans and C.S. Woodward and P.M. Caldwell},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {2006 - 2015},
  Volume                   = {51},

  Abstract                 = {Abstract We present a survey of physical and computational techniques that have the potential to contribute to the next generation of high-fidelity, multi-scale climate simulations. Examples of the climate science problems that can be investigated with more depth with these computational improvements include the capture of remote forcings of localized hydrological extreme events, an accurate representation of cloud features over a range of spatial and temporal scales, and parallel, large ensembles of simulations to more effectively explore model sensitivities and un- certainties. Numerical techniques, such as adaptive mesh refinement, implicit time integration, and separate treatment of fast physical time scales are enabling improved accuracy and fidelity in simulation of dynamics and allowing more complete representations of climate features at the global scale. At the same time, partnerships with computer science teams have focused on taking advantage of evolving computer architectures such as many-core processors and GPUs. As a result, approaches which were previously considered prohibitively costly have become both more efficient and scalable. In combination, progress in these three critical areas is poised to transform climate modeling in the coming decades. These topics have been presented within a workshop titled, “Numerical and Computational Developments to Advance Multiscale Earth System Models (MSESM ‘15),” as part of the International Conference on Computational Sciences, Reykjavik, Iceland, June 1-3, 2015. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.465},
  ISSN                     = {1877-0509},
  Keywords                 = {Earth system models},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915012739}
}

@InCollection{Coombs2011383,
  Title                    = {1.27 - Viruses Produced from Cells },
  Author                   = {K.M. Coombs},
  Booktitle                = {Comprehensive Biotechnology (Second Edition) },
  Publisher                = {Academic Press},
  Year                     = {2011},

  Address                  = {Burlington},
  Edition                  = {Second Edition},
  Editor                   = {Moo-Young, Murray },
  Pages                    = {383 - 393},

  Abstract                 = {Abstract Viruses are among the smallest and simplest of living organisms. They are obligate parasites and, thus, can only replicate in living cells. Therefore, endeavors to produce large amounts of virus, such as, those needed for scientific investigation, including virus characterization and high-resolution structural analysis, or for human therapy, require the capacity to grow large numbers of host cells, produce large amounts of virus, and, in many cases, purify the virus away from culture contaminants. This article reviews the types of systems available for growing mammalian cells, including static cultures, such as T-flasks, multilayered flasks, cell factories, and agitated cultures, such as microcarriers, wave bags, packed bed reactors, and bellows mechanisms. In addition, other parameters that are crucial for optimal cell and virus growth, including cell type, initial multiplicity of infection, cell density, media pH, incubation temperature, whether media is replenished during infection, and flask size are discussed. Finally, virion purification by isopycnic density ultracentrifugation, ultra-filtration, and chromatography is described. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-08-088504-9.00041-6},
  ISBN                     = {978-0-08-088504-9},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780080885049000416}
}

@Article{Cruz2015,
  Title                    = {LAPT: A Locality-Aware Page Table for thread and data mapping },
  Author                   = {Eduardo H.M. Cruz and Matthias Diener and Marco A.Z. Alves and Laércio L. Pilla and Philippe O.A. Navaux},
  Journal                  = {Parallel Computing },
  Year                     = {2015},
  Pages                    = { - },

  Abstract                 = {Abstract The performance and energy efficiency of current systems is influenced by accesses to the memory hierarchy. One important aspect of memory hierarchies is the introduction of different memory access times, depending on the core that requested the transaction, and which cache or main memory bank responded to it. In this context, the locality of the memory accesses plays a key role for the performance and energy efficiency of parallel applications. Accesses to remote caches and \{NUMA\} nodes are more expensive than accesses to local ones. With information about the memory access pattern, pages can be migrated to the \{NUMA\} nodes that access them (data mapping), and threads that communicate can be migrated to the same node (thread mapping). In this paper, we present LAPT, a hardware-based mechanism to store the memory access pattern of parallel applications in the page table. The operating system uses the detected memory access pattern to perform an optimized thread and data mapping during the execution of the parallel application. Experiments with a wide range of parallel applications (from the \{NAS\} and \{PARSEC\} Benchmark Suites) on a \{NUMA\} machine showed significant performance and energy efficiency improvements of up to 19.2% and 15.7%, respectively, (6.7% and 5.3% on average). },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2015.12.001},
  ISSN                     = {0167-8191},
  Keywords                 = {Communication},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819115001556}
}

@Article{Cupertino2015535,
  Title                    = {Energy-efficient, thermal-aware modeling and simulation of data centers: The CoolEmAll approach and evaluation results },
  Author                   = {Leandro Cupertino and Georges Da Costa and Ariel Oleksiak and Wojciech Pia¸tek and Jean-Marc Pierson and Jaume Salom and Laura Sisó and Patricia Stolf and Hongyang Sun and Thomas Zilio},
  Journal                  = {Ad Hoc Networks },
  Year                     = {2015},
  Note                     = {New Research Challenges in Mobile, Opportunistic and Delay-Tolerant NetworksEnergy-Aware Data Centers: Architecture, Infrastructure, and Communication },
  Pages                    = {535 - 553},
  Volume                   = {25, Part B},

  Abstract                 = {Abstract This paper describes the CoolEmAll project and its approach for modeling and simulating energy-efficient and thermal-aware data centers. The aim of the project was to address energy-thermal efficiency of data centers by combining the optimization of IT, cooling and workload management. This paper provides a complete data center model considering the workload profiles, the applications profiling, the power model and a cooling model. Different energy efficiency metrics are proposed and various resource management and scheduling policies are presented. The proposed strategies are validated through simulation at different levels of a data center. },
  Doi                      = {http://dx.doi.org/10.1016/j.adhoc.2014.11.002},
  ISSN                     = {1570-8705},
  Keywords                 = {Data centers},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1570870514002364}
}

@Article{Darema20101287,
  Title                    = {CyberInfrastructures of cyber-applications-systems },
  Author                   = {Frederica Darema},
  Journal                  = {Procedia Computer Science },
  Year                     = {2010},
  Note                     = {\{ICCS\} 2010 },
  Number                   = {1},
  Pages                    = {1287 - 1296},
  Volume                   = {1},

  Abstract                 = {The paper discusses foundational notions and conditions in complex applications modeling and in software frameworks to support advanced CyberInfrastructure environments such as those implied and required for Dynamic Data Driven Applications Systems, as well as other classes of applications, collectively referred to here as Cyber-Applications-Systems. The paper discusses considerations of dynamic invocation of multi-scale models, uncertainty quantification, uncertainty propagation, and dynamic runtime systems support on heterogeneous, distributed, end-to-end dynamically integrated high-end, real-time and instrumentation and control systems. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2010.04.143},
  ISSN                     = {1877-0509},
  Keywords                 = {Dynamic data driven applications systems},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050910001444}
}

@InCollection{DeCusatis2013167,
  Title                    = {Case Study - Energy Efficient Networking for Data Centers },
  Author                   = {Casimer DeCusatis},
  Booktitle                = {Handbook of Fiber Optic Data Communication (Fourth Edition) },
  Publisher                = {Academic Press},
  Year                     = {2013},

  Address                  = {Oxford},
  Edition                  = {Fourth Edition},
  Editor                   = {DeCusatis, Casimer },
  Pages                    = {167 - 168},

  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-401673-6.00039-8},
  ISBN                     = {978-0-12-401673-6},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780124016736000398}
}

@Article{Decyk2014,
  Title                    = {Particle-in-Cell algorithms for emerging computer architectures },
  Author                   = {Viktor K. Decyk and Tajendra V. Singh},
  Journal                  = {Computer Physics Communications },
  Year                     = {2014},
  Number                   = {3},
  Pages                    = {708 - 719},
  Volume                   = {185},

  Abstract                 = {Abstract We have designed Particle-in-Cell algorithms for emerging architectures. These algorithms share a common approach, using fine-grained tiles, but different implementations depending on the architecture. On the GPU, there were two different implementations, one with atomic operations and one with no data collisions, using \{CUDA\} C and Fortran. Speedups up to about 50 compared to a single core of the Intel i7 processor have been achieved. There was also an implementation for traditional multi-core processors using OpenMP which achieved high parallel efficiency. We believe that this approach should work for other emerging designs such as Intel Phi coprocessor from the Intel \{MIC\} architecture. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2013.10.013},
  ISSN                     = {0010-4655},
  Keywords                 = {Parallel algorithms},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S001046551300341X}
}

@Article{Decyk2011,
  Title                    = {Adaptable Particle-in-Cell algorithms for graphical processing units },
  Author                   = {Viktor K. Decyk and Tajendra V. Singh},
  Journal                  = {Computer Physics Communications },
  Year                     = {2011},
  Number                   = {3},
  Pages                    = {641 - 648},
  Volume                   = {182},

  Abstract                 = {We developed new parameterized Particle-in-Cell algorithms and data structures for emerging multi-core and many-core architectures. Four parameters allow tuning of this \{PIC\} code to different hardware configurations. Particles are kept ordered at each time step. The first application of these algorithms is to \{NVIDIA\} graphical processing units, where speedups of about 15–25 compared to an Intel Nehalem processor were obtained for a simple 2D electrostatic code. Electromagnetic codes are expected to get higher speedups due to their greater computational intensity. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2010.11.009},
  ISSN                     = {0010-4655},
  Keywords                 = {Particle-in-Cell},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465510004558}
}

@Article{Deelman201517,
  Title                    = {Pegasus, a workflow management system for science automation },
  Author                   = {Ewa Deelman and Karan Vahi and Gideon Juve and Mats Rynge and Scott Callaghan and Philip J. Maechling and Rajiv Mayani and Weiwei Chen and Rafael Ferreira da Silva and Miron Livny and Kent Wenger},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2015},
  Pages                    = {17 - 35},
  Volume                   = {46},

  Abstract                 = {Abstract Modern science often requires the execution of large-scale, multi-stage simulation and data analysis pipelines to enable the study of complex systems. The amount of computation and data involved in these pipelines requires scalable workflow management systems that are able to reliably and efficiently coordinate and automate data movement and task execution on distributed computational resources: campus clusters, national cyberinfrastructures, and commercial and academic clouds. This paper describes the design, development and evolution of the Pegasus Workflow Management System, which maps abstract workflow descriptions onto distributed computing infrastructures. Pegasus has been used for more than twelve years by scientists in a wide variety of domains, including astronomy, seismology, bioinformatics, physics and others. This paper provides an integrated view of the Pegasus system, showing its capabilities that have been developed over time in response to application needs and to the evolution of the scientific computing platforms. The paper describes how Pegasus achieves reliable, scalable workflow execution across a wide variety of computing infrastructures. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2014.10.008},
  ISSN                     = {0167-739X},
  Keywords                 = {Scientific workflows},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X14002015}
}

@Article{Defour20161,
  Title                    = {A software scheduling solution to avoid corrupted units on \{GPUs\} },
  Author                   = {David Defour and Eric Petit},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2016},
  Pages                    = {1 - 8},
  Volume                   = {90–91},

  Abstract                 = {Abstract Massively parallel processors provide high computing performance by increasing the number of concurrent execution units. Moreover, the transistor technology evolves to higher density, higher frequency and lower voltage. The combination of these factors increases significantly the probability of hardware failures. In this paper, we present a methodology to locate and mitigate hardware failures of Nvidia GPUs. Results show that intermittent errors can be precisely localized and have a limited impact to a well defined architecture tile. Therefore, we propose, and demonstrate on a software prototype, a rescheduling strategy to quarantine the defective hardware and ensure correct execution. Our approach significantly improves the \{GPU\} fault-tolerance capability and GPU’s lifespan, at a reasonable overhead. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2016.01.001},
  ISSN                     = {0743-7315},
  Keywords                 = {Reliability},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731516000022}
}

@Article{Demartini20155,
  Title                    = {Hybrid human–machine information systems: Challenges and opportunities },
  Author                   = {Gianluca Demartini},
  Journal                  = {Computer Networks },
  Year                     = {2015},
  Note                     = {Crowdsourcing },
  Pages                    = {5 - 13},
  Volume                   = {90},

  Abstract                 = {Abstract Micro-task Crowdsourcing has been used for different purposes: creating training data for machine learning algorithms, relevance judgments for evaluation of information systems, sentiment analysis, language translation, etc. In this paper we focus on the use of crowdsourcing as core component of data-driven systems. The creation of hybrid human–machine systems is a highly promising direction as it allows leveraging both the scalability of machines over large amounts of data as well as keeping the quality of human intelligence in the loop to finally obtain both efficiency and effectiveness in data processing applications. Such a hybrid approach is a great opportunity to develop systems that are more powerful than purely machine-based ones. For example, it is possible to build systems that can understand sarcasm in text at scale. However, when designing such systems it is critical to take into account a number of dimensions related to human behavior as humans become a component of the overall process. In this paper, we overview existing hybrid human–machine systems presenting commonalities in the approaches taken by different research communities. We summarize the key challenges that one has to face in developing such systems as well the opportunities and the open research directions to make such approaches the best way to process data in the future. },
  Doi                      = {http://dx.doi.org/10.1016/j.comnet.2015.05.018},
  ISSN                     = {1389-1286},
  Keywords                 = {Human computation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1389128615002194}
}

@Article{Diouri201468,
  Title                    = {Assessing Power Monitoring Approaches for Energy and Power Analysis of Computers },
  Author                   = {Mohammed El Mehdi Diouri and Manuel F. Dolz and Olivier Glück and Laurent Lefèvre and Pedro Alonso and Sandra Catalán and Rafael Mayo and Enrique S. Quintana-Ortí},
  Journal                  = {Sustainable Computing: Informatics and Systems },
  Year                     = {2014},
  Note                     = {Special Issue on Selected papers from EE-LSDS2013 Conference },
  Number                   = {2},
  Pages                    = {68 - 82},
  Volume                   = {4},

  Abstract                 = {Abstract Large-scale distributed systems (e.g., datacenters, \{HPC\} systems, clouds, large-scale networks, etc.) consume and will consume enormous amounts of energy. Therefore, accurately monitoring the power dissipation and energy consumption of these systems is more unavoidable. The main novelty of this contribution is the analysis and evaluation of different external and internal power monitoring devices tested using two different computing systems, a server and a desktop machine. Furthermore, we provide experimental results for a variety of benchmarks which intensively exercise the main components (CPU, Memory, HDDs, and NICs) of the target platforms to validate the accuracy of the equipment in terms of power dissipation and energy consumption. On the other hand, we also evaluate three different power measurement interfaces available on current architecture generations. Thanks to the high sampling rate and to the different measured lines, the internal wattmeters allow an improved visualization of some power fluctuations. However, a high sampling rate is not always necessary to understand the evolution of the power consumption during the execution of a benchmark. },
  Doi                      = {http://dx.doi.org/10.1016/j.suscom.2014.03.006},
  ISSN                     = {2210-5379},
  Keywords                 = {Wattmeters},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S2210537914000171}
}

@Article{Djorgovski2016,
  Title                    = {Real-time data mining of massive data streams from synoptic sky surveys },
  Author                   = {S.G. Djorgovski and M.J. Graham and C. Donalek and A.A. Mahabal and A.J. Drake and M. Turmon and T. Fuchs},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2016},
  Pages                    = { - },

  Abstract                 = {Abstract The nature of scientific and technological data collection is evolving rapidly: data volumes and rates grow exponentially, with increasing complexity and information content, and there has been a transition from static data sets to data streams that must be analyzed in real time. Interesting or anomalous phenomena must be quickly characterized and followed up with additional measurements via optimal deployment of limited assets. Modern astronomy presents a variety of such phenomena in the form of transient events in digital synoptic sky surveys, including cosmic explosions (supernovae, gamma ray bursts), relativistic phenomena (black hole formation, jets), potentially hazardous asteroids, etc. We have been developing a set of machine learning tools to detect, classify and plan a response to transient events for astronomy applications, using the Catalina Real-time Transient Survey (CRTS) as a scientific and methodological testbed. The ability to respond rapidly to the potentially most interesting events is a key bottleneck that limits the scientific returns from the current and anticipated synoptic sky surveys. Similar challenge arises in other contexts, from environmental monitoring using sensor networks to autonomous spacecraft systems. Given the exponential growth of data rates, and the time-critical response, we need a fully automated and robust approach. We describe the results obtained to date, and the possible future developments. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2015.10.013},
  ISSN                     = {0167-739X},
  Keywords                 = {Sky surveys},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X1500326X}
}

@Article{Dokulil20151453,
  Title                    = {Retargeting of the Open Community Runtime to Intel Xeon Phi },
  Author                   = {Jiri Dokulil and Siegfried Benkner},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {1453 - 1462},
  Volume                   = {51},

  Abstract                 = {Abstract The Open Community Runtime (OCR) is a recent effort in the search for a runtime for extreme scale parallel systems. \{OCR\} relies on the concept of a dynamically generated task graph to ex- press the parallelism of a program. Rather than being directly used for application development, the main purpose of \{OCR\} is to become a low-level runtime for higher-level programming models and tools. Since manycore architectures like the Intel Xeon Phi are likely to play a major role in future high performance systems, we have implemented the \{OCR\} \{API\} for shared-memory machines, including the Xeon Phi. We have also implemented two benchmark applications and performed experiments to investigate the viability of the \{OCR\} as a runtime for manycores. Our initial experiments and a comparison with OpenMP indicate that \{OCR\} can be an efficient runtime system for current and emerging manycore systems. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.335},
  ISSN                     = {1877-0509},
  Keywords                 = {Open Community Runtime},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915011436}
}

@Article{Dong20121254,
  Title                    = {A dynamic and adaptive load balancing strategy for parallel file system with large-scale I/O servers },
  Author                   = {Bin Dong and Xiuqiao Li and Qimeng Wu and Limin Xiao and Li Ruan},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2012},
  Number                   = {10},
  Pages                    = {1254 - 1268},
  Volume                   = {72},

  Abstract                 = {Many solutions have been proposed to tackle the load imbalance issue of parallel file systems. However, all these solutions either adopt centralized algorithms, or lack considerations for both the network transmission and the tradeoff between benefits and side-effects of each dynamic file migration. Therefore, existing solutions will be prohibitively inefficient in large-scale parallel file systems. To address this problem, this paper presents SALB, a dynamic and adaptive load balancing algorithm which is totally based on a distributed architecture. To be also aware of the network transmission, \{SALB\} on the one hand adopts an adaptively adjusted load collection threshold in order to reduce the message exchanges for load collection, and on the other hand it employs an on-line load prediction model with a view to reducing the decision delay caused by the network transmission latency. Moreover, \{SALB\} employs an optimization model for selecting the migration candidates so as to balance the benefits and the side-effects of each dynamic file migration. Extensive experiments are conducted to prove the effectiveness of SALB. The results show that \{SALB\} achieves an optimal performance not only on the mean response time but also on the resource utilization among the schemes for comparison. The simulation results also indicate that \{SALB\} is able to deliver high scalability. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2012.05.006},
  ISSN                     = {0743-7315},
  Keywords                 = {Distributed load balancing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731512001244}
}

@Article{Dongarra2013212,
  Title                    = {Hierarchical \{QR\} factorization algorithms for multi-core clusters },
  Author                   = {Jack Dongarra and Mathieu Faverge and Thomas Hérault and Mathias Jacquelin and Julien Langou and Yves Robert},
  Journal                  = {Parallel Computing },
  Year                     = {2013},
  Number                   = {4–5},
  Pages                    = {212 - 232},
  Volume                   = {39},

  Abstract                 = {Abstract This paper describes a new \{QR\} factorization algorithm which is especially designed for massively parallel platforms combining parallel distributed nodes, where a node is a multi-core processor. These platforms represent the present and the foreseeable future of high-performance computing. Our new \{QR\} factorization algorithm falls in the category of the tile algorithms which naturally enables good data locality for the sequential kernels executed by the cores (high sequential performance), low number of messages in a parallel distributed setting (small latency term), and fine granularity (high parallelism). Each tile algorithm is uniquely characterized by its sequence of reduction trees. In the context of a cluster of nodes, in order to minimize the number of inter-processor communications (aka, “communication-avoiding”), it is natural to consider hierarchical trees composed of an “inter-node” tree which acts on top of “intra-node” trees. At the intra-node level, we propose a hierarchical tree made of three levels: (0) “TS level” for cache-friendliness, (1) “low-level” for decoupled highly parallel inter-node reductions, (2) “domino level” to efficiently resolve interactions between local reductions and global reductions. Our hierarchical algorithm and its implementation are flexible and modular, and can accommodate several kernel types, different distribution layouts, and a variety of reduction trees at all levels, both inter-node and intra-node. Numerical experiments on a cluster of multi-core nodes (i) confirm that each of the four levels of our hierarchical tree contributes to build up performance and (ii) build insights on how these levels influence performance and interact within each other. Our implementation of the new algorithm with the \{DAGuE\} scheduling tool significantly outperforms currently available \{QR\} factorization software for all matrix shapes, thereby bringing a new advance in numerical linear algebra for petascale and exascale platforms. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2013.01.003},
  ISSN                     = {0167-8191},
  Keywords                 = {\{QR\} factorization},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819113000100}
}

@Article{Donzis2014370,
  Title                    = {Asynchronous finite-difference schemes for partial differential equations },
  Author                   = {Diego A. Donzis and Konduri Aditya},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2014},
  Pages                    = {370 - 392},
  Volume                   = {274},

  Abstract                 = {Abstract Current trends in massively parallel computing systems suggest that the number of processing elements (PEs) used in simulations will continue to grow over time. A known problem in this context is the overhead associated with communication and/or synchronization between \{PEs\} as well as idling due to load imbalances. Simulation at extreme levels of parallelism will then require an elimination, or at least a tight control of these overheads. In this work, we present an analysis of common finite difference schemes for partial differential equations (PDEs) when no synchronization between \{PEs\} is enforced. \{PEs\} are allowed to continue computations regardless of messages status and are thus asynchronous. We show that while stability is conserved when these schemes are used asynchronously, accuracy is greatly degraded. Since message arrivals at \{PEs\} are essentially random processes, so is the behavior of the error. Within a statistical framework we show that average errors drop always to first-order regardless of the original scheme. The value of the error is found to depend on both grid spacing as well as characteristics of the computing system including number of processors and statistics of the delays. We propose new schemes that are robust to asynchrony. The analytical results are compared against numerical simulations. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2014.06.017},
  ISSN                     = {0021-9991},
  Keywords                 = {Asynchronous schemes},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999114004240}
}

@Article{Dosanjh2014,
  Title                    = {Exascale design space exploration and co-design },
  Author                   = {S.S. Dosanjh and R.F. Barrett and D.W. Doerfler and S.D. Hammond and K.S. Hemmert and M.A. Heroux and P.T. Lin and K.T. Pedretti and A.F. Rodrigues and T.G. Trucano and J.P. Luitjens},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2014},
  Note                     = {Special Issue on Extreme Scale Parallel Architectures and Systems, Cryptography in Cloud Computing and Recent Advances in Parallel and Distributed Systems, \{ICPADS\} 2012 Selected Papers },
  Pages                    = {46 - 58},
  Volume                   = {30},

  Abstract                 = {Abstract The co-design of architectures and algorithms has been postulated as a strategy for achieving Exascale computing in this decade. Exascale design space exploration is prohibitively expensive, at least partially due to the size and complexity of scientific applications of interest. Application codes can contain millions of lines and involve many libraries. Mini-applications, which attempt to capture some key performance issues, can potentially reduce the order of the exploration by a factor of a thousand. However, we need to carefully understand how representative mini-applications are of the full application code. This paper describes a methodology for this comparison and applies it to a particularly challenging mini-application. A multi-faceted methodology for design space exploration is also described that includes measurements on advanced architecture testbeds, experiments that use supercomputers and system software to emulate future hardware, and hardware/software co-simulation tools to predict the behavior of applications on hardware that does not yet exist. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2013.04.018},
  ISSN                     = {0167-739X},
  Keywords                 = {High performance computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X13000782}
}

@Article{Dosanjh201446,
  Title                    = {Exascale design space exploration and co-design },
  Author                   = {S.S. Dosanjh and R.F. Barrett and D.W. Doerfler and S.D. Hammond and K.S. Hemmert and M.A. Heroux and P.T. Lin and K.T. Pedretti and A.F. Rodrigues and T.G. Trucano and J.P. Luitjens},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2014},
  Note                     = {Special Issue on Extreme Scale Parallel Architectures and Systems, Cryptography in Cloud Computing and Recent Advances in Parallel and Distributed Systems, \{ICPADS\} 2012 Selected Papers },
  Pages                    = {46 - 58},
  Volume                   = {30},

  Abstract                 = {Abstract The co-design of architectures and algorithms has been postulated as a strategy for achieving Exascale computing in this decade. Exascale design space exploration is prohibitively expensive, at least partially due to the size and complexity of scientific applications of interest. Application codes can contain millions of lines and involve many libraries. Mini-applications, which attempt to capture some key performance issues, can potentially reduce the order of the exploration by a factor of a thousand. However, we need to carefully understand how representative mini-applications are of the full application code. This paper describes a methodology for this comparison and applies it to a particularly challenging mini-application. A multi-faceted methodology for design space exploration is also described that includes measurements on advanced architecture testbeds, experiments that use supercomputers and system software to emulate future hardware, and hardware/software co-simulation tools to predict the behavior of applications on hardware that does not yet exist. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2013.04.018},
  ISSN                     = {0167-739X},
  Keywords                 = {High performance computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X13000782}
}

@Article{Düben20142,
  Title                    = {The use of imprecise processing to improve accuracy in weather \&amp; climate prediction },
  Author                   = {Peter D. Düben and Hugh McNamara and T.N. Palmer},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2014},
  Note                     = {Frontiers in Computational PhysicsModeling the Earth System },
  Pages                    = {2 - 18},
  Volume                   = {271},

  Abstract                 = {Abstract The use of stochastic processing hardware and low precision arithmetic in atmospheric models is investigated. Stochastic processors allow hardware-induced faults in calculations, sacrificing bit-reproducibility and precision in exchange for improvements in performance and potentially accuracy of forecasts, due to a reduction in power consumption that could allow higher resolution. A similar trade-off is achieved using low precision arithmetic, with improvements in computation and communication speed and savings in storage and memory requirements. As high-performance computing becomes more massively parallel and power intensive, these two approaches may be important stepping stones in the pursuit of global cloud-resolving atmospheric modelling. The impact of both hardware induced faults and low precision arithmetic is tested using the Lorenz '96 model and the dynamical core of a global atmosphere model. In the Lorenz '96 model there is a natural scale separation; the spectral discretisation used in the dynamical core also allows large and small scale dynamics to be treated separately within the code. Such scale separation allows the impact of lower-accuracy arithmetic to be restricted to components close to the truncation scales and hence close to the necessarily inexact parametrised representations of unresolved processes. By contrast, the larger scales are calculated using high precision deterministic arithmetic. Hardware faults from stochastic processors are emulated using a bit-flip model with different fault rates. Our simulations show that both approaches to inexact calculations do not substantially affect the large scale behaviour, provided they are restricted to act only on smaller scales. By contrast, results from the Lorenz '96 simulations are superior when small scales are calculated on an emulated stochastic processor than when those small scales are parametrised. This suggests that inexact calculations at the small scale could reduce computation and power costs without adversely affecting the quality of the simulations. This would allow higher resolution models to be run at the same computational cost. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2013.10.042},
  ISSN                     = {0021-9991},
  Keywords                 = {Stochastic processor},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999113007183}
}

@Article{Dubois2011222,
  Title                    = {Improving Scalability Using Hybrid Asynchronous Methods For Non-Hermitian Eigenproblems },
  Author                   = {Jérôme Dubois and Christophe Calvin and Serge Petiton},
  Journal                  = {Procedia Computer Science },
  Year                     = {2011},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2011 },
  Pages                    = {222 - 230},
  Volume                   = {4},

  Abstract                 = {We propose an optimized implementation of the \{MERAM\} method and preliminary experiments to solve non-Hermitian eigenproblems faster using this asynchronous hybrid method. We focus on improving the communication pattern by providing an entity called the collector as well as an optimized communication scheme using MPI-2 one-sided communications. The scalability of the parallelization is discussed and experiments are done to show how well our implementation scales to a large number of nodes. The one 8 cores node computing time of 3800 seconds is reduced to 4 seconds using 1200 Nehalem cores, and we achieve linear to superlinear speed-ups thanks to our efficient communication pattern and the coarse-grained parallel nature of MERAM. Our approach achieved an optimal performance on more than a thousand cores for the first time with MERAM. We conclude that hybrid asynchronous methods like \{MERAM\} with a good communication patter offer tremendous possibilities for high performance computing. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2011.04.024},
  ISSN                     = {1877-0509},
  Keywords                 = {HPC},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050911000822}
}

@Article{Dudai2014254,
  Title                    = {To Simulate or Not to Simulate: What Are the Questions? },
  Author                   = {Yadin Dudai and Kathinka Evers},
  Journal                  = {Neuron },
  Year                     = {2014},
  Number                   = {2},
  Pages                    = {254 - 261},
  Volume                   = {84},

  Abstract                 = {Simulation is a powerful method in science and engineering. However, simulation is an umbrella term, and its meaning and goals differ among disciplines. Rapid advances in neuroscience and computing draw increasing attention to large-scale brain simulations. What is the meaning of simulation, and what should the method expect to achieve? We discuss the concept of simulation from an integrated scientific and philosophical vantage point and pinpoint selected issues that are specific to brain simulation. },
  Doi                      = {http://dx.doi.org/10.1016/j.neuron.2014.09.031},
  ISSN                     = {0896-6273},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0896627314008514}
}

@Article{Dwyer20101051,
  Title                    = {Oscillation in a network model of neocortex },
  Author                   = {Jennifer Dwyer and Hyong Lee and Amber Martell and Rick Stevens and Mark Hereld and Wim van Drongelen},
  Journal                  = {Neurocomputing },
  Year                     = {2010},
  Note                     = {Advances in Computational Intelligence and Learning17th European Symposium on Artificial Neural Networks 200917th European Symposium on Artificial Neural Networks 2009 },
  Number                   = {7–9},
  Pages                    = {1051 - 1056},
  Volume                   = {73},

  Abstract                 = {A basic understanding of the relationship between activity of individual neurons and macroscopic electrical activity of local field potentials, or electroencephalogram (EEG), may provide guidance for experimental design in neuroscience, improve development of therapeutic approaches in neurology, and offer opportunities for computer-aided design of brain–computer interfaces. We study the relationship between resonant properties of neurons and network oscillations in a computational model of neocortex. Our findings suggest that resonance is associated with subthreshold oscillation of neurons. This subthreshold behavior affects spike timing and plays a significant role in the generation of the network's extracellular currents reflected in the EEG. },
  Doi                      = {http://dx.doi.org/10.1016/j.neucom.2009.12.021},
  ISSN                     = {0925-2312},
  Keywords                 = {Neuronal resonance},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0925231210000147}
}

@Article{Edgar20101707,
  Title                    = {Enabling a high throughput real time data pipeline for a large radio telescope array with \{GPUs\} },
  Author                   = {R.G. Edgar and M.A. Clark and K. Dale and D.A. Mitchell and S.M. Ord and R.B. Wayth and H. Pfister and L.J. Greenhill},
  Journal                  = {Computer Physics Communications },
  Year                     = {2010},
  Number                   = {10},
  Pages                    = {1707 - 1714},
  Volume                   = {181},

  Abstract                 = {The Murchison Widefield Array (MWA) is a next-generation radio telescope currently under construction in the remote Western Australia Outback. Raw data will be generated continuously at 5 GiB s−1, grouped into 8 s cadences. This high throughput motivates the development of on-site, real time processing and reduction in preference to archiving, transport and off-line processing. Each batch of 8 s data must be completely reduced before the next batch arrives. Maintaining real time operation will require a sustained performance of around 2.5 TFLOP s−1 (including convolutions, FFTs, interpolations and matrix multiplications). We describe a scalable heterogeneous computing pipeline implementation, exploiting both the high computing density and FLOP-per-Watt ratio of modern GPUs. The architecture is highly parallel within and across nodes, with all major processing elements performed by GPUs. Necessary scatter-gather operations along the pipeline are loosely synchronized between the nodes hosting the GPUs. The \{MWA\} will be a frontier scientific instrument and a pathfinder for planned peta- and exa-scale facilities. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2010.06.019},
  ISSN                     = {0010-4655},
  Keywords                 = {Radio telescopes and instrumentation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465510001967}
}

@Article{Eisenlohr201337,
  Title                    = {A spectral method solution to crystal elasto-viscoplasticity at finite strains },
  Author                   = {P. Eisenlohr and M. Diehl and R.A. Lebensohn and F. Roters},
  Journal                  = {International Journal of Plasticity },
  Year                     = {2013},
  Note                     = {Microstructure-based Models of Plastic Deformation },
  Pages                    = {37 - 53},
  Volume                   = {46},

  Abstract                 = {Abstract A significant improvement over existing models for the prediction of the macromechanical response of structural materials can be achieved by means of a more refined treatment of the underlying micromechanics. For this, achieving the highest possible spatial resolution is advantageous, in order to capture the intricate details of complex microstructures. Spectral methods, as an efficient alternative to the widely used finite element method (FEM), have been established during the last decade and their applicability to the case of polycrystalline materials has already been demonstrated. However, until now, the existing implementations were limited to infinitesimal strain and phenomenological crystal elasto-viscoplasticity. This work presents the extension of the existing spectral formulation for polycrystals to the case of finite strains, not limited to a particular constitutive law, by considering a general material model implementation. By interfacing the exact same material model to both, the new spectral implementation as well as a FEM-based solver, a direct comparison of both numerical strategies is possible. Carrying out this comparison, and using a phenomenological constitutive law as example, we demonstrate that the spectral method solution converges much faster with mesh/grid resolution, fulfills stress equilibrium and strain compatibility much better, and is able to solve the micromechanical problem for, e.g., a 2563 grid in comparable times as required by a 643 mesh of linear finite elements. },
  Doi                      = {http://dx.doi.org/10.1016/j.ijplas.2012.09.012},
  ISSN                     = {0749-6419},
  Keywords                 = {A. Microstructures},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0749641912001428}
}

@Article{Elliott2016,
  Title                    = {Exploiting data representation for fault tolerance },
  Author                   = {J. Elliott and M. Hoemmen and F. Mueller},
  Journal                  = {Journal of Computational Science },
  Year                     = {2016},
  Pages                    = { - },

  Abstract                 = {Abstract Incorrect computer hardware behavior may corrupt intermediate computations in numerical algorithms, possibly resulting in incorrect answers. Prior work models misbehaving hardware by randomly flipping bits in memory. We start by accepting this premise, and present an analytic model for the error introduced by a bit flip in an \{IEEE\} 754 floating-point number. We then relate this finding to the linear algebra concepts of normalization and matrix equilibration. In particular, we present a case study illustrating that normalizing both vector inputs of a dot product minimizes the probability of a single bit flip causing a large error in the dot product's result. Furthermore, the absolute error is either less than one or very large, which allows detection of large errors. Then, we apply this to the \{GMRES\} iterative solver. We count all possible errors that can be introduced through faults in arithmetic in the computationally intensive orthogonalization phase of GMRES, and show that when the matrix is equilibrated, the absolute error is bounded above by one. },
  Doi                      = {http://dx.doi.org/10.1016/j.jocs.2015.12.002},
  ISSN                     = {1877-7503},
  Keywords                 = {Algorithm-based fault tolerance},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877750315300491}
}

@Article{Emad2016,
  Title                    = {Unite and Conquer Approach for High Scale Numerical Computing },
  Author                   = {Nahid Emad and Serge Petiton},
  Journal                  = {Journal of Computational Science },
  Year                     = {2016},
  Pages                    = { - },

  Abstract                 = {Abstract The ability to exploit emerging exascale computational systems will require a careful review and redesign of core numerical algorithms and their implementations to fully exploit multiple levels of concurrency, hierarchical memory structures and heterogeneous processing units that will become available in these computational platforms. This paper presents the ”unite and conquer” approach to solve linear systems of equations and eigenvalue problems for extreme scale computing. Indeed, there are two ways to optimize the execution of a restarted method on a large-scale distributed system. The first one is to optimize the number of floating point operations per restart cycle through maximizing the concurrency inside a restart cycle while minimizing latencies. The second way is to accelerate/improve the rate of convergence for a given computational scheme. The unite and conquer restarted approach focuses on decreasing the number of restart cycles by coupling either synchronously or asynchronously several restarted methods called also co-methods. In the end of a restart cycle, each co-method locally gathers available results of all collaborating co-methods and selects the best one in order to create its restarting information. Consequently this permits the global reduction of the number of cycles to convergence. The unite and conquer restarted methods are heterogeneous, fault tolerant, support asynchronous communications and present a big potential of load balancing. Due to these properties, they are well adapted to large-scale multi-level parallel architectures. We show the relevant programming paradigms that allow multi-level parallel expression of these methods and how the software engineering technology can contribute significantly in achieving high scalability. We present some experiments validating the approach for unite and conquer restarted Krylov methods on several parallel and distributed platforms. },
  Doi                      = {http://dx.doi.org/10.1016/j.jocs.2016.01.007},
  ISSN                     = {1877-7503},
  Keywords                 = {Restarted hybrid methods},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877750316300084}
}

@Article{Engelmann2014,
  Title                    = {Scaling to a million cores and beyond: Using light-weight simulation to understand the challenges ahead on the road to exascale },
  Author                   = {Christian Engelmann},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2014},
  Note                     = {Special Issue on Extreme Scale Parallel Architectures and Systems, Cryptography in Cloud Computing and Recent Advances in Parallel and Distributed Systems, \{ICPADS\} 2012 Selected Papers },
  Pages                    = {59 - 65},
  Volume                   = {30},

  Abstract                 = {Abstract As supercomputers scale to 1000 PFlop/s over the next decade, investigating the performance of parallel applications at scale on future architectures and the performance impact of different architecture choices for high-performance computing (HPC) hardware/software co-design is crucial. This paper summarizes recent efforts in designing and implementing a novel \{HPC\} hardware/software co-design toolkit. The presented Extreme-scale Simulator (xSim) permits running an \{HPC\} application in a controlled environment with millions of concurrent execution threads while observing its performance in a simulated extreme-scale \{HPC\} system using architectural models and virtual timing. This paper demonstrates the capabilities and usefulness of the xSim performance investigation toolkit, such as its scalability to 227 simulated Message Passing Interface (MPI) ranks on 960 real processor cores, the capability to evaluate the performance of different \{MPI\} collective communication algorithms, and the ability to evaluate the performance of a basic Monte Carlo application with different architectural parameters. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2013.04.014},
  ISSN                     = {0167-739X},
  Keywords                 = {Parallel discrete event simulation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X13000745}
}

@Article{Engelmann201459,
  Title                    = {Scaling to a million cores and beyond: Using light-weight simulation to understand the challenges ahead on the road to exascale },
  Author                   = {Christian Engelmann},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2014},
  Note                     = {Special Issue on Extreme Scale Parallel Architectures and Systems, Cryptography in Cloud Computing and Recent Advances in Parallel and Distributed Systems, \{ICPADS\} 2012 Selected Papers },
  Pages                    = {59 - 65},
  Volume                   = {30},

  Abstract                 = {Abstract As supercomputers scale to 1000 PFlop/s over the next decade, investigating the performance of parallel applications at scale on future architectures and the performance impact of different architecture choices for high-performance computing (HPC) hardware/software co-design is crucial. This paper summarizes recent efforts in designing and implementing a novel \{HPC\} hardware/software co-design toolkit. The presented Extreme-scale Simulator (xSim) permits running an \{HPC\} application in a controlled environment with millions of concurrent execution threads while observing its performance in a simulated extreme-scale \{HPC\} system using architectural models and virtual timing. This paper demonstrates the capabilities and usefulness of the xSim performance investigation toolkit, such as its scalability to 227 simulated Message Passing Interface (MPI) ranks on 960 real processor cores, the capability to evaluate the performance of different \{MPI\} collective communication algorithms, and the ability to evaluate the performance of a basic Monte Carlo application with different architectural parameters. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2013.04.014},
  ISSN                     = {0167-739X},
  Keywords                 = {Parallel discrete event simulation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X13000745}
}

@Article{Erel2015317,
  Title                    = {Grade of Service (GoS) based adaptive flow management for Software Defined Heterogeneous Networks (SDHetN) },
  Author                   = {Müge Erel and Zemre Arslan and Yusuf Özçevik and Berk Canberk},
  Journal                  = {Computer Networks },
  Year                     = {2015},
  Pages                    = {317 - 330},
  Volume                   = {76},

  Abstract                 = {Abstract In today’s wireless Heterogeneous Networks (HetNets) deployments, the physical resources which are supposed to handle the huge mobile data requests, are clustered statically by the operators, leading an ineffective resource management. In this paper, we solve this ineffective static resource assignment, by proposing a novel queueing-theoretic Software Defined HetNet (SDHetN) model which orchestrates the HetNets topology using adaptive and scalable flow management heuristics. The proposed \{SDHetN\} takes its flexible and scalable characteristics thanks to two algorithms; the Topology Control Algorithm (TCA) and the Flow Admission Control Algorithm (FACA). Specifically, the proposed \{TCA\} clusters several OpenFlow (OF) switches using the flows’ Grade of Service (GoS) in order to optimize physical resource assignment. The proposed \{FACA\} fairly distributes each Flow Authority Virtual Switch (FAVS) that are created in \{TCA\} by grouping several switches virtually. We also propose a thread-based parallelization in \{TCA\} and \{FACA\} increasing the response time and service rate of the \{SDN\} Controller. The performance of \{SDHetN\} is evaluated by 48 different scenarios and it is shown that \{SDHetN\} provides a scalable and fair flow management according to different performance metrics. },
  Doi                      = {http://dx.doi.org/10.1016/j.comnet.2014.11.012},
  ISSN                     = {1389-1286},
  Keywords                 = {Software Defined Networks (SDN)},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1389128614004010}
}

@Article{Esirkepov,
  Title                    = {Exact charge conservation scheme for Particle-in-Cell simulation with an arbitrary form-factor },
  Author                   = {T.Zh. Esirkepov},
  Journal                  = {Computer Physics Communications },
  Year                     = {2001},
  Number                   = {2},
  Pages                    = {144 - 153},
  Volume                   = {135},

  Abstract                 = {The new method of local electric current density assignment in the Particle-in-Cell code in Cartesian geometry is presented. The method is valid for an arbitrary quasi-particle form-factor assuming that quasi-particle trajectory over time step is a straight line. The method allows one to implement the \{PIC\} code without solving Poisson equation. The presented formula for the current density associated with the motion of a single quasi-particle is the unique linear combination of form-factor differences in consistency with the discrete continuity equation. The computation scheme is demonstrated in 2D and 3D. },
  Doi                      = {http://dx.doi.org/10.1016/S0010-4655(00)00228-9},
  Keywords                 = {Particle-in-Cell method},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465500002289}
}

@Article{Etinski2012615,
  Title                    = {Parallel job scheduling for power constrained \{HPC\} systems },
  Author                   = {M. Etinski and J. Corbalan and J. Labarta and M. Valero},
  Journal                  = {Parallel Computing },
  Year                     = {2012},
  Number                   = {12},
  Pages                    = {615 - 630},
  Volume                   = {38},

  Abstract                 = {Power has become the primary constraint in high performance computing. Traditionally, parallel job scheduling policies have been designed to improve certain job performance metrics when scheduling parallel workloads on a system with a given number of processors. The available number of processors is not anymore the only limitation in parallel job scheduling. The recent increase in processor power consumption has resulted in a new limitation: the available power. Given constraints naturally lead to an optimization problem. We proposed MaxJobPerf, a new parallel job scheduling policy based on integer linear programming. Dynamic Voltage Frequency Scaling (DVFS) is a widely used technique that running applications at reduced \{CPU\} frequency/voltage trades increased execution time for power reduction. The optimization problem determines which jobs should run and at which frequency. In this paper, we compare the MaxJobPerf policy against other power budgeting policies for different power budgets. It clearly outperforms the other power-budgeting approaches at the parallel job scheduling level. Furthermore, we give a detailed analysis of the policy parameters including a discussion on how to manage job reservations to avoid job starvation. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2012.08.001},
  ISSN                     = {0167-8191},
  Keywords                 = {Power budget},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819112000610}
}

@Article{Ettrich20151,
  Title                    = {Diffuse interface method for fluid flow and heat transfer in cellular solids },
  Author                   = {J. Ettrich and B. Nestler},
  Journal                  = {Advances in Engineering Software },
  Year                     = {2015},
  Pages                    = {1 - 12},
  Volume                   = {87},

  Abstract                 = {Abstract This work presents a contribution on the numerical modelling capabilities for the simulation of fluid flow and heat transfer in cellular solids – in particular we focus on open cell aluminium foams. Rather than applying one of the classical academical or commercial numerical finite volume (FV), finite difference (FD) or finite element (FE) interface tracking methods, we base our models on an interface capturing phase field method (Nestler, 2005). A coupled diffuse interface lattice Boltzmann fluid flow solver (Ettrich, 2014) and a diffuse interface heat transfer approach (Ettrich et al., 2014) are combined in view of dealing with even more convoluted geometries, incorporating the dynamics of interfaces and complex multiphysics applications. Numerical results for the combined fluid flow and heat transfer simulations in open cell metal foams are in very good agreement with experimental data (Ettrich and Martens, 2012; Ettrich et al., 2012). },
  Doi                      = {http://dx.doi.org/10.1016/j.advengsoft.2015.04.012},
  ISSN                     = {0965-9978},
  Keywords                 = {Phase-field},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S096599781500071X}
}

@Article{Evans2014338,
  Title                    = {A Monte Carlo synthetic-acceleration method for solving the thermal radiation diffusion equation },
  Author                   = {Thomas M. Evans and Scott W. Mosher and Stuart R. Slattery and Steven P. Hamilton},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2014},
  Pages                    = {338 - 358},
  Volume                   = {258},

  Abstract                 = {Abstract We present a novel synthetic-acceleration-based Monte Carlo method for solving the equilibrium thermal radiation diffusion equation in three spatial dimensions. The algorithm performance is compared against traditional solution techniques using a Marshak benchmark problem and a more complex multiple material problem. Our results show that our Monte Carlo method is an effective solver for sparse matrix systems. For solutions converged to the same tolerance, it performs competitively with deterministic methods including preconditioned conjugate gradient and GMRES. We also discuss various aspects of preconditioning the method and its general applicability to broader classes of problems. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2013.10.043},
  ISSN                     = {0021-9991},
  Keywords                 = {Radiation diffusion},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999113007195}
}

@Article{Fabiano20151675,
  Title                    = {OpenDBDDAS Toolkit: Secure MapReduce and Hadoop-like Systems },
  Author                   = {Enrico Fabiano and Mookwon Seo and Xiaoban Wu and Craig C. Douglas},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {1675 - 1684},
  Volume                   = {51},

  Abstract                 = {Abstract The OpenDBDDAS Toolkit is a software framework to provide support for more easily creating and expanding dynamic big data-driven application systems (DBDDAS) that are common in environmental systems, many engineering applications, disaster management, traffic management, and manufacturing. In this paper, we describe key features needed to implement a secure MapReduce and Hadoop-like system for high performance clusters that guarantees a certain level of privacy of data from other concurrent users of the system. We also provide examples of a secure MapReduce prototype and compare it to another high performance MapReduce, MR-MPI. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.302},
  ISSN                     = {1877-0509},
  Keywords                 = {Big data},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915011102}
}

@InCollection{Farber2015129,
  Title                    = {Chapter 7 - Deep-Learning Numerical Optimization },
  Author                   = {Rob Farber},
  Booktitle                = {High Performance Parallelism Pearls },
  Publisher                = {Morgan Kaufmann},
  Year                     = {2015},

  Address                  = {Boston},
  Editor                   = {Jeffers, James ReindersJim },
  Pages                    = {129 - 142},

  Abstract                 = {Abstract The massively parallel mapping and code described in this chapter are generic and can be applied to a broad spectrum of numerical optimization and machine-learning algorithms ranging from neural networks to support vector machines to expectation maximization and independent components analysis. Many of these techniques are heavily used in lucrative data-mining and social media workflows as well as real-time robotics, computer vision, signal processing, and augmented reality applications. The code in this chapter demonstrates that it is possible to exceed a TeraFLOP per second of average sustained performance on a single Intel Xeon Phi coprocessor (KNC) using only user-written C-code (no optimized libraries needed). The message passing interface (MPI) version described in this chapter can run with near-linear scalability and petascale performance on the current generation of leadership class supercomputers. It is expected this same mapping is exascale capable, an assertion that can be tested when such a machine is built. Both high performance and large memory make the Intel Xeon Phi coprocessor family an ideal platform for training on the large datasets that are required to solve complex and high-dimensional pattern recognition problems. However, the goodness does not stop with Intel Xeon Phi coprocessors as the optimized models produced by the code in this chapter can be used on ultra-low-power and small memory-footprint devices such as CPUs, DSPs, FPGA, and \{ASICs\} to perform a variety of real time and robotic tasks. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-802118-7.00007-8},
  ISBN                     = {978-0-12-802118-7},
  Keywords                 = {Deep-learning},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780128021187000078}
}

@Article{Feng2016,
  Title                    = {Two-level locality-aware parallel Delaunay image-to-mesh conversion },
  Author                   = {Daming Feng and Andrey N. Chernikov and Nikos P. Chrisochoides},
  Journal                  = {Parallel Computing },
  Year                     = {2016},
  Pages                    = { - },

  Abstract                 = {Abstract In this paper, we propose a three dimensional two-level Locality-Aware Parallel Delaunay image-to-mesh conversion algorithm (LAPD). The algorithm exploits two levels of parallelism at different granularities: coarse-grain parallelism at the region level (which is mapped to a node with multiple cores) and medium-grain parallelism at the cavity level (which is mapped to a single core). We employ a data locality-aware mesh refinement process to reduce the latency caused by the remote memory access. We evaluated \{LAPD\} on Blacklight, a cache-coherent \{NUMA\} distributed shared memory (DSM) machine in the Pittsburgh Supercomputing Center, and observed a weak scaling efficiency of almost 70% for roughly 200 cores, compared to only 30% for the previous algorithm, Parallel Optimistic Mesh Generation algorithm (PODM). To the best of our knowledge, \{LAPD\} exhibits the best scalability for parallel Delaunay mesh generation algorithms running on \{NUMA\} \{DSM\} supercomputers. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2016.01.007},
  ISSN                     = {0167-8191},
  Keywords                 = {Parallel mesh generation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819116000375}
}

@Article{Ferreira201466,
  Title                    = {Accelerating incremental checkpointing for extreme-scale computing },
  Author                   = {Kurt B. Ferreira and Rolf Riesen and Patrick Bridges and Dorian Arnold and Ron Brightwell},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2014},
  Note                     = {Special Issue on Extreme Scale Parallel Architectures and Systems, Cryptography in Cloud Computing and Recent Advances in Parallel and Distributed Systems, \{ICPADS\} 2012 Selected Papers },
  Pages                    = {66 - 77},
  Volume                   = {30},

  Abstract                 = {Abstract Concern is beginning to grow in the high-performance computing (HPC) community regarding the reliability of future large-scale systems. Disk-based coordinated checkpoint/restart has been the dominant fault tolerance mechanism in \{HPC\} systems for the past 30 years. Checkpoint performance is so fundamental to scalability that nearly all capability applications have custom checkpoint strategies to minimize state and reduce checkpoint time. One well-known optimization to traditional checkpoint/restart is incremental checkpointing, which has a number of known limitations. To address these limitations, we describe libhashckpt, a hybrid incremental checkpointing solution that uses both page protection and hashing on \{GPUs\} to determine changes in application data with very low overhead. Using real capability workloads and a model outlining the viability and application efficiency increase of this technique, we show that hash-based incremental checkpointing can have significantly lower overheads and increased efficiency than traditional coordinated checkpointing approaches at the scales expected for future extreme-class systems. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2013.04.017},
  ISSN                     = {0167-739X},
  Keywords                 = {Fault-tolerance},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X13000770}
}

@Article{Fiore2011290,
  Title                    = {Special section: Data management for eScience },
  Author                   = {S. Fiore and G. Aloisio},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2011},
  Number                   = {3},
  Pages                    = {290 - 291},
  Volume                   = {27},

  Doi                      = {http://dx.doi.org/10.1016/j.future.2010.08.012},
  ISSN                     = {0167-739X},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X10001664}
}

@Article{Fiore20132376,
  Title                    = {Ophidia: Toward Big Data Analytics for eScience },
  Author                   = {S. Fiore and A. D’Anca and C. Palazzo and I. Foster and D.N. Williams and G. Aloisio},
  Journal                  = {Procedia Computer Science },
  Year                     = {2013},
  Note                     = {2013 International Conference on Computational Science },
  Pages                    = {2376 - 2385},
  Volume                   = {18},

  Abstract                 = {Abstract This work introduces Ophidia, a big data analytics research effort aiming at supporting the access, analysis and mining of scientific (n-dimensional array based) data. The Ophidia platform extends, in terms of both primitives and data types, current relational database system implementations (in particular MySQL) to enable efficient data analysis tasks on scientific array-based data. To enable big data analytics it exploits well-known scientific numerical libraries, a distributed and hierarchical storage model and a parallel software framework based on the Message Passing Interface to run from single tasks to more complex dataflows. The current version of the Ophidia platform is being tested on NetCDF data produced by \{CMCC\} climate scientists in the context of the international Coupled Model Intercomparison Project Phase 5 (CMIP5). },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2013.05.409},
  ISSN                     = {1877-0509},
  Keywords                 = {data warehouse},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050913005528}
}

@Article{Flint2015,
  Title                    = {A 9-bit multiple relaxation Lattice Boltzmann magnetohydrodynamic algorithm for 2D turbulence },
  Author                   = {Christopher Flint and George Vahala and Linda Vahala and Min Soe},
  Journal                  = {Computers \& Mathematics with Applications },
  Year                     = {2015},
  Pages                    = { - },

  Abstract                 = {Abstract While a minimalist representation of 2D Magnetohydrodynamics (MHD) on a square lattice is a 9-bit scalar and 5-bit vector distribution functions, here we examine the effect of using the 9-bit vector distribution function on the effect of a magnetic field on the Kelvin–Helmholtz instability. While there is little difference in the simulation results between the 5-bit and the 9-bit vector distribution models in the vorticity, energy spectra, etc., the 9-bit model permits simulations with mean magnetic field a factor of approximately 2 greater than those attainable in the standard 5-bit model. Indeed a 9-bit single-relaxation model can attain such success over a 5-bit multiple-relaxation model at the same computational expense. },
  Doi                      = {http://dx.doi.org/10.1016/j.camwa.2015.09.008},
  ISSN                     = {0898-1221},
  Keywords                 = {Lattice Boltzmann},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0898122115004228}
}

@Article{Forshaw201565,
  Title                    = {Energy-efficient Checkpointing in High-throughput Cycle-stealing Distributed Systems },
  Author                   = {Matthew Forshaw and A. Stephen McGough and Nigel Thomas},
  Journal                  = {Electronic Notes in Theoretical Computer Science },
  Year                     = {2015},
  Note                     = {Proceedings of the Seventh International Workshop on the Practical Application of Stochastic Modelling (PASM) },
  Pages                    = {65 - 90},
  Volume                   = {310},

  Abstract                 = {Abstract Checkpointing is a fault-tolerance mechanism commonly used in High Throughput Computing (HTC) environments to allow the execution of long-running computational tasks on compute resources subject to hardware or software failures as well as interruptions from resource owners and more important tasks. Until recently many researchers have focused on the performance gains achieved through checkpointing, but now with growing scrutiny of the energy consumption of \{IT\} infrastructures it is increasingly important to understand the energy impact of checkpointing within an \{HTC\} environment. In this paper we demonstrate through trace-driven simulation of real-world datasets that existing checkpointing strategies are inadequate at maintaining an acceptable level of energy consumption whilst maintaing the performance gains expected with checkpointing. Furthermore, we identify factors important in deciding whether to exploit checkpointing within an \{HTC\} environment, and propose novel strategies to curtail the energy consumption of checkpointing approaches whist maintaining the performance benefits. },
  Doi                      = {http://dx.doi.org/10.1016/j.entcs.2014.12.013},
  ISSN                     = {1571-0661},
  Keywords                 = {Energy efficiency},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1571066114000978}
}

@Article{Francesquini201532,
  Title                    = {On the energy efficiency and performance of irregular application executions on multicore, \{NUMA\} and manycore platforms },
  Author                   = {Emilio Francesquini and Márcio Castro and Pedro H. Penna and Fabrice Dupros and Henrique C. Freitas and Philippe O.A. Navaux and Jean-François Méhaut},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2015},
  Note                     = {Special Issue on Architecture and Algorithms for Irregular Applications },
  Pages                    = {32 - 48},
  Volume                   = {76},

  Abstract                 = {Abstract Until the last decade, performance of \{HPC\} architectures has been almost exclusively quantified by their processing power. However, energy efficiency is being recently considered as important as raw performance and has become a critical aspect to the development of scalable systems. These strict energy constraints guided the development of a new class of so-called light-weight manycore processors. This study evaluates the computing and energy performance of two well-known irregular NP-hard problems–the Traveling-Salesman Problem (TSP) and K-Means clustering–and a numerical seismic wave propagation simulation kernel–Ondes3D–on multicore, NUMA, and manycore platforms. First, we concentrate on the nontrivial task of adapting these applications to a manycore, specifically the novel MPPA-256 manycore processor. Then, we analyze their performance and energy consumption on those different machines. Our results show that applications able to fully use the resources of a manycore can have better performance and may consume from 3.8 × to 13 × less energy when compared to low-power and general-purpose multicore processors, respectively. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2014.11.002},
  ISSN                     = {0743-7315},
  Keywords                 = {Manycore},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731514002093}
}

@Article{Friese2014203,
  Title                    = {Introduction to Special Issue on Energy Aware Resource Management and Scheduling (EARMS) },
  Author                   = {Ryan Friese and Anne Benoit and H.J. Siegel},
  Journal                  = {Sustainable Computing: Informatics and Systems },
  Year                     = {2014},
  Note                     = {Special Issue on Energy Aware Resource Management and Scheduling (EARMS) },
  Number                   = {4},
  Pages                    = {203 - 204},
  Volume                   = {4},

  Doi                      = {http://dx.doi.org/10.1016/j.suscom.2014.11.002},
  ISSN                     = {2210-5379},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S2210537914000808}
}

@Article{Furumura20111448,
  Title                    = {First International Workshop on Advances in High-Performance Computational Earth Sciences: Applications and Frameworks (IHPCES) },
  Author                   = {Takashi Furumura and Kengo Nakajima and Masaki Satoh},
  Journal                  = {Procedia Computer Science },
  Year                     = {2011},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2011 },
  Pages                    = {1448 - 1449},
  Volume                   = {4},

  Doi                      = {http://dx.doi.org/10.1016/j.procs.2011.04.156},
  ISSN                     = {1877-0509},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050911002146}
}

@Article{Galizia20121588,
  Title                    = {Job allocation strategies for energy-aware and efficient Grid infrastructures },
  Author                   = {Antonella Galizia and Alfonso Quarati},
  Journal                  = {Journal of Systems and Software },
  Year                     = {2012},
  Note                     = {Software Ecosystems },
  Number                   = {7},
  Pages                    = {1588 - 1606},
  Volume                   = {85},

  Abstract                 = {Complex distributed architectures, like Grid, supply effective platforms to solve computations on huge datasets, often at the cost of increased power consumption. This energy issue affects the sustainability of the infrastructures and increases their environmental impact. On the other hand, due to Grid heterogeneity and scalability, possible power savings could be achieved if effective energy-aware allocation policies were adopted. These policies are meant to implement a better coupling between application requirements and the Grid resources, also taking energy parameters into account. In this paper, we discuss different allocation strategies which address jobs submitted to Grid resources, subject to efficiency and energy constraints. Our aim is to analyze the potential benefits that can be obtained from the adoption of a metric able to capture both performance and energy-savings. Based on an experimental study, we simulated two alternative scenarios aimed at comparing the behavior of different strategies for allocating jobs to resources. Moreover we introduced the Performance/Energy Trade-off function as a useful means to evaluate the tendency of an allocation strategy toward efficiency or power consumption. Our conclusion seems to suggest that performance and energy-savings are not always enemies, and these objectives may be combined if suitable energy metrics are adopted. },
  Doi                      = {http://dx.doi.org/10.1016/j.jss.2012.01.050},
  ISSN                     = {0164-1212},
  Keywords                 = {Grid},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0164121212000362}
}

@Article{Gallard2012136,
  Title                    = {Architecture for the next generation system management tools },
  Author                   = {Jérôme Gallard and Adrien Lèbre and Christine Morin and Thomas Naughton and Stephen L. Scott and Geoffroy Vallée},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2012},
  Number                   = {1},
  Pages                    = {136 - 146},
  Volume                   = {28},

  Abstract                 = {To get more results or greater accuracy, computational scientists execute their applications on distributed computing platforms such as clusters, grids, and clouds. These platforms are different in terms of hardware and software resources as well as locality: some span across multiple sites and multiple administrative domains, whereas others are limited to a single site/domain. As a consequence, in order to scale their applications up, the scientists have to manage technical details for each target platform. From our point of view, this complexity should be hidden from the scientists, who, in most cases, would prefer to focus on their research rather than spending time dealing with platform configuration concerns. In this article, we advocate for a system management framework that aims to automatically set up the whole run-time environment according to the applications’ needs. The main difference with regards to usual approaches is that they generally only focus on the software layer whereas we address both the hardware and the software expectations through a unique system. For each application, scientists describe their requirements through the definition of a virtual platform (VP) and a virtual system environment (VSE). Relying on the VP/VSE definitions, the framework is in charge of (i) the configuration of the physical infrastructure to satisfy the \{VP\} requirements, (ii) the set-up of the VP, and (iii) the customization of the execution environment (VSE) upon the former VP. We propose a new formalism that the system can rely upon to successfully perform each of these three steps without burdening the user with the specifics of the configuration for the physical resources, and system management tools. This formalism leverages Goldberg’s theory for recursive virtual machines (Goldberg, 1973 [6]) by introducing new concepts based on system virtualization (identity, partitioning, aggregation) and emulation (simple, abstraction). This enables the definition of complex VP/VSE configurations without making assumptions about the hardware and the software resources. For each requirement, the system executes the corresponding operation with the appropriate management tool. As a proof of concept, we implemented a first prototype that currently interacts with several system management tools (e.g., OSCAR, the Grid’5000 toolkit, and XtreemOS) and that can be easily extended to integrate new resource brokers or cloud systems such as Nimbus, OpenNebula, or Eucalyptus, for instance. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2011.06.003},
  ISSN                     = {0167-739X},
  Keywords                 = {\{HPC\} system resource management},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X11001142}
}

@Article{Garain2015237,
  Title                    = {Comparing Coarray Fortran (CAF) with \{MPI\} for several structured mesh \{PDE\} applications },
  Author                   = {Sudip Garain and Dinshaw S. Balsara and John Reid},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2015},
  Pages                    = {237 - 253},
  Volume                   = {297},

  Abstract                 = {Abstract Language-based approaches to parallelism have been incorporated into the Fortran standard. These Fortran extensions go under the name of Coarray Fortran (CAF) and full-featured compilers that support \{CAF\} have become available from Cray and Intel; the \{GNU\} implementation is expected in 2015. \{CAF\} combines elegance of expression with simplicity of implementation to yield an efficient parallel programming language. Elegance of expression results in very compact parallel code. The existence of a standard helps with portability and maintainability. \{CAF\} was designed to excel at one-sided communication and similar functions that support one-sided communication are also available in the recent MPI-3 standard. One-sided communication is expected to be very valuable for structured mesh applications involving partial differential equations, amongst other possible applications. This paper focuses on a comparison of \{CAF\} and \{MPI\} for a few very useful applications areas that are routinely used for solving partial differential equations on structured meshes. The three specific areas are Fast Fourier Techniques, Computational Fluid Dynamics, and Multigrid Methods. For each of those applications areas, we have developed optimized \{CAF\} code and optimized \{MPI\} code that is based on the one-sided messaging capabilities of MPI-3. Weak scalability studies that compare \{CAF\} and MPI-3 are presented on up to 65,536 processors. Both paradigms scale well, showing that they are well-suited for Petascale-class applications. Some of the applications shown (like Fast Fourier Techniques and Computational Fluid Dynamics) require large, coarse-grained messaging. Such applications emphasize high bandwidth. Our other application (Multigrid Methods) uses pointwise smoothers which require a large amount of fine-grained messaging. In such applications, a premium is placed on low latency. Our studies show that both \{CAF\} and MPI-3 offer the twin advantages of high bandwidth and low latency for messages of all sizes. Even for large numbers of processors, \{CAF\} either draws level with MPI-3 or shows a slight advantage over MPI-3. Both \{CAF\} and MPI-3 are shown to provide substantial advantages over MPI-2. In addition to the weak scalability studies, we also catalogue some of the best-usage strategies that we have found for our successful implementations of one-sided messaging in \{CAF\} and MPI-3. We show that \{CAF\} code is of course much easier to write and maintain, and the simpler syntax makes the parallelism easier to understand. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2015.05.020},
  ISSN                     = {0021-9991},
  Keywords                 = {PDEs},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S002199911500354X}
}

@Article{Garimella201366,
  Title                    = {Technological drivers in data centers and telecom systems: Multiscale thermal, electrical, and energy management },
  Author                   = {Suresh V. Garimella and Tim Persoons and Justin Weibel and Lian-Tuu Yeh},
  Journal                  = {Applied Energy },
  Year                     = {2013},
  Pages                    = {66 - 80},
  Volume                   = {107},

  Abstract                 = {We identify technological drivers for tomorrow’s data centers and telecommunications systems, including thermal, electrical and energy management challenges, based on discussions at the 2nd Workshop on Thermal Management in Telecommunication Systems and Data Centers in Santa Clara, California, on April 25–26, 2012. The relevance of thermal management in electronic systems is reviewed against the background of the energy usage of the information technology (IT) industry, encompassing perspectives of different sectors of the industry. The underlying drivers for progress at the business and technology levels are identified. The technological challenges are reviewed in two main categories – immediate needs and future needs. Enabling cooling techniques that are currently under development are also discussed. },
  Doi                      = {http://dx.doi.org/10.1016/j.apenergy.2013.02.047},
  ISSN                     = {0306-2619},
  Keywords                 = {Electronics cooling},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0306261913001554}
}

@Article{Garzon2012172,
  Title                    = {Bridging Scales with a Generalized Finite Element Method },
  Author                   = {J. Garzon and V. Gupta and A. Simone and C.A. Duarte},
  Journal                  = {Procedia \{IUTAM\} },
  Year                     = {2012},
  Note                     = {\{IUTAM\} Symposium on Linking Scales in Computations: From Microstructure to Macro-scale Properties },
  Pages                    = {172 - 191},
  Volume                   = {3},

  Abstract                 = {The generalized \{FEM\} (GFEM) has been successfully applied to the simulation of dynamic propagating fractures, polycrystalline and fiber-reinforced microstructures, porous materials, etc. A-priori knowledge about the solution of these problems are used in the definition of their \{GFEM\} approximation spaces. This leads to more accurate and robust simulations than available finite element methods while relaxing some meshing requirements. This is demonstrated in a simulation of intergranular crack propagation in a brittle polycrystal using simple background meshes. For many classes of problems – like those with material non-linearities or involvingmultiscale phenomena – a-priori knowledge of the solution behavior is limited. In this paper, we present a \{GFEMbased\} on the solution of interdependent global (structural) and fine-scale or local problems. The local problems focus on the resolution of fine-scale features of the solution in the vicinity of, e.g., evolving fracture process zones while the global problem addresses the macroscale structural behavior. Fine-scale solutions are accurately solved using an hp-adaptive \{GFEM\} and thus the proposed method does not rely on analytical solutions. These solutions are embedded into the global solution space using the partition of unity method. This \{GFEM\} enables accurate modeling of problems involving multiple scales of interest using meshes with elements that are orders of magnitude larger than those required by the FEM. Numerical examples illustrating the application of this class of \{GFEM\} to high-cycle fatigue crack growth of small cracks and to problems exhibiting localized non-linear material responses are presented. },
  Doi                      = {http://dx.doi.org/10.1016/j.piutam.2012.03.012},
  ISSN                     = {2210-9838},
  Keywords                 = {Generalized Finite Element Method},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S2210983812000132}
}

@Article{George2012166,
  Title                    = {ADFT: An Adaptive Framework for Fault Tolerance on Large Scale Systems using Application Malleability },
  Author                   = {Cijo George and Sathish S. Vadhiyar},
  Journal                  = {Procedia Computer Science },
  Year                     = {2012},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2012 },
  Pages                    = {166 - 175},
  Volume                   = {9},

  Abstract                 = {Exascale systems of the future are predicted to have mean time between failures (MTBF) of less than one hour. Malleable applications, where the number of processors on which the applications execute can be changed during executions, can make use of their malleability to better tolerate high failure rates. We present AdFT, an adaptive fault tolerance framework for long running malleable applications to maximize application performance in the presence of failures. AdFT framework includes cost models for evaluating the benefits of various fault tolerance actions including checkpointing, live-migration and rescheduling, and runtime decisions for dynamically selecting the fault tolerance actions at different points of application execution to maximize performance. Simulations with real and synthetic failure traces show that our approach outperforms existing fault tolerance mechanisms for malleable applications yielding up to 23% improvement in application performance, and is effective even for petascale systems and beyond. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2012.04.018},
  ISSN                     = {1877-0509},
  Keywords                 = {Fault Tolerance},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050912001391}
}

@Article{Georgi20111917,
  Title                    = {Linux Cluster in Theory and Practice: A Novel Approach in Teaching Cluster Computing Based on the Intel Atom Platform },
  Author                   = {Andy Georgi and Stefan Höhlig and Robin Geyer and Wolfgang E. Nagel},
  Journal                  = {Procedia Computer Science },
  Year                     = {2011},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2011 },
  Pages                    = {1917 - 1926},
  Volume                   = {4},

  Abstract                 = {Current trends and studies on future architectures show, that the complexity of parallel computer systems is increasing steadily. Hence, the industry requires skilled employees, who have in addition to the theoretical fundamentals, practical experiences in the design and administration of such systems. However, investigations have shown, that practical approaches are still missing in current curricula, especially in these areas. For this reason, the chair of Computer Architecture at the faculty of Computer Science at the Technische Universiẗat Dresden, developed and introduced the course “Linux Cluster in Theory and Practice” (LCTP). The main objectives of this course are to provide background knowledge about the design and administration of large-scale parallel computer systems and the practical implementation on the available hardware. In addition, students learn how to solve problems in a structured approach and as part of a team. This paper analyzes the current variety of courses in the area of parallel computing systems, describes the structure and implementation of \{LCTP\} and provides first conclusions and an outlook on possible further developments. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2011.04.209},
  ISSN                     = {1877-0509},
  Keywords                 = {Teaching},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050911002675}
}

@Article{Ghoshal2011422,
  Title                    = {Distributed Speculative Parallelization using Checkpoint Restart },
  Author                   = {Devarshi Ghoshal and Sreesudhan R. Ramkumar and Arun Chauhan},
  Journal                  = {Procedia Computer Science },
  Year                     = {2011},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2011 },
  Pages                    = {422 - 431},
  Volume                   = {4},

  Abstract                 = {Speculative software parallelism has gained renewed interest recently as a mechanism to leverage multiple cores on emerging architectures. Two major mechanisms have been used to implement speculation-based parallelism in software, software transactional memory and speculative threads. We propose a third mechanism based on checkpoint restart. With recent developments in checkpoint restart technology this has become an attractive alternative. The approach has the potential advantage of the conceptual simplicity of transactional memory and flexibility of speculative threads. Since many checkpoint restart systems work with large distributed memory programs, this provides an automatic way to perform distributed speculation over clusters. Additionally, since checkpoint restart systems are primarily designed for fault tolerance, using the same system for speculation could provide fault tolerance within speculative execution as well when it is embedded in large-scale applications where fault tolerance is desirable. In this paper we use a series of micro-benchmarks to study the relative performance of a speculative system based on the \{DMTCP\} checkpoint restart system and compare it against a thread level speculative system. We highlight the relative merits of each approach and draw some lessons that could be used to guide future developments in speculative systems. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2011.04.044},
  ISSN                     = {1877-0509},
  Keywords                 = {Speculative parallelization},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050911001025}
}

@Article{Gicquel2012782,
  Title                    = {Large Eddy Simulations of gaseous flames in gas turbine combustion chambers },
  Author                   = {L.Y.M. Gicquel and G. Staffelbach and T. Poinsot},
  Journal                  = {Progress in Energy and Combustion Science },
  Year                     = {2012},
  Number                   = {6},
  Pages                    = {782 - 817},
  Volume                   = {38},

  Abstract                 = {Recent developments in numerical schemes, turbulent combustion models and the regular increase of computing power allow Large Eddy Simulation (LES) to be applied to real industrial burners. In this paper, two types of \{LES\} in complex geometry combustors and of specific interest for aeronautical gas turbine burners are reviewed: (1) laboratory-scale combustors, without compressor or turbine, in which advanced measurements are possible and (2) combustion chambers of existing engines operated in realistic operating conditions. Laboratory-scale burners are designed to assess modeling and fundamental flow aspects in controlled configurations. They are necessary to gauge \{LES\} strategies and identify potential limitations. In specific circumstances, they even offer near model-free or DNS-like \{LES\} computations. \{LES\} in real engines illustrate the potential of the approach in the context of industrial burners but are more difficult to validate due to the limited set of available measurements. Usual approaches for turbulence and combustion sub-grid models including chemistry modeling are first recalled. Limiting cases and range of validity of the models are specifically recalled before a discussion on the numerical breakthrough which have allowed \{LES\} to be applied to these complex cases. Specific issues linked to real gas turbine chambers are discussed: multi-perforation, complex acoustic impedances at inlet and outlet, annular chambers…. Examples are provided for mean flow predictions (velocity, temperature and species) as well as unsteady mechanisms (quenching, ignition, combustion instabilities). Finally, potential perspectives are proposed to further improve the use of \{LES\} for real gas turbine combustor designs. },
  Doi                      = {http://dx.doi.org/10.1016/j.pecs.2012.04.004},
  ISSN                     = {0360-1285},
  Keywords                 = {Large Eddy Simulations},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0360128512000366}
}

@Article{Giorgi2014976,
  Title                    = {TERAFLUX: Harnessing dataflow in next generation teradevices },
  Author                   = {Roberto Giorgi and Rosa M. Badia and François Bodin and Albert Cohen and Paraskevas Evripidou and Paolo Faraboschi and Bernhard Fechner and Guang R. Gao and Arne Garbade and Rahul Gayatri and Sylvain Girbal and Daniel Goodman and Behran Khan and Souad Koliaï and Joshua Landwehr and Nhat Minh Lê and Feng Li and Mikel Lujàn and Avi Mendelson and Laurent Morin and Nacho Navarro and Tomasz Patejko and Antoniu Pop and Pedro Trancoso and Theo Ungerer and Ian Watson and Sebastian Weis and Stéphane Zuckerman and Mateo Valero},
  Journal                  = {Microprocessors and Microsystems },
  Year                     = {2014},
  Number                   = {8, Part B},
  Pages                    = {976 - 990},
  Volume                   = {38},

  Abstract                 = {Abstract The improvements in semiconductor technologies are gradually enabling extreme-scale systems such as teradevices (i.e., chips composed by 1000 billion of transistors), most likely by 2020. Three major challenges have been identified: programmability, manageable architecture design, and reliability. \{TERAFLUX\} is a Future and Emerging Technology (FET) large-scale project funded by the European Union, which addresses such challenges at once by leveraging the dataflow principles. This paper presents an overview of the research carried out by the \{TERAFLUX\} partners and some preliminary results. Our platform comprises 1000+ general purpose cores per chip in order to properly explore the above challenges. An architectural template has been proposed and applications have been ported to the platform. Programming models, compilation tools, and reliability techniques have been developed. The evaluation is carried out by leveraging on modifications of the HP-Labs \{COTSon\} simulator. },
  Doi                      = {http://dx.doi.org/10.1016/j.micpro.2014.04.001},
  ISSN                     = {0141-9331},
  Keywords                 = {Dataflow},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0141933114000490}
}

@Article{Giorgi2015100,
  Title                    = {A scalable thread scheduling co-processor based on data-flow principles },
  Author                   = {R. Giorgi and A. Scionti},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2015},
  Pages                    = {100 - 108},
  Volume                   = {53},

  Abstract                 = {Abstract Large synchronization and communication overhead will become a major concern in future extreme-scale machines (e.g., \{HPC\} systems, supercomputers). These systems will push upwards performance limits by adopting chips equipped with one order of magnitude more cores than today. Alternative execution models can be explored in order to exploit the high parallelism offered by future massive many-core chips. This paper proposes the integration of standard cores with dedicated co-processing units that enable the system to support a fine-grain data-flow execution model developed within the \{TERAFLUX\} project. An instruction set architecture extension for supporting fine-grain thread scheduling and execution is proposed. This instruction set extension is supported by the co-processor that provides hardware units for accelerating thread scheduling and distribution among the available cores. Two fundamental aspects are at the base of the proposed system: the programmers can adopt their preferred programming model, and the compilation tools can produce a large set of threads mainly communicating in a producer–consumer fashion, hence enabling data-flow execution. Experimental results demonstrate the feasibility of the proposed approach and its capability of scaling with the increasing number of cores. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2014.12.014},
  ISSN                     = {0167-739X},
  Keywords                 = {Co-processor architecture},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X1400274X}
}

@Article{SnytnikovJSFI15,
  Title                    = {Co-design of Parallel Numerical Methods for Plasma Physics and Astrophysics},
  Author                   = {Boris Glinskiy and Igor Kulikov and Alexey Snytnikov and Alexey Romanenko and Igor Chernykh and Vitaly Vshivkov},
  Journal                  = {Supercomputing frontiers and innovations},
  Year                     = {2015},
  Number                   = {3},
  Volume                   = {1},

  Abstract                 = {Physically meaningful simulations in plasma physics and astrophysics need powerful hybrid supercomputers equipped with computation accelerators. The development of parallel numerical codes for such supercomputers is a complex scientific problem. In order to solve it the concept of co-design is employed. The co-design is defined as considering the architecture of the supercomputer at all stages of the development of the code. The use of co-design is shown by the example of two physical problems: the interaction of an electron beam with plasma and the collision of galaxies. The resulting speedup and efficiency are shown.},
  ISSN                     = {2313-8734},
  Url                      = {http://superfri.org/superfri/article/view/26}
}

@Article{Göddeke2015117,
  Title                    = {Fault-tolerant finite-element multigrid algorithms with hierarchically compressed asynchronous checkpointing },
  Author                   = {Dominik Göddeke and Mirco Altenbernd and Dirk Ribbrock},
  Journal                  = {Parallel Computing },
  Year                     = {2015},
  Pages                    = {117 - 135},
  Volume                   = {49},

  Abstract                 = {Abstract We analyse novel fault tolerance schemes for data loss in multigrid solvers, which essentially combine ideas of checkpoint-restart with algorithm-based fault tolerance. To improve efficiency compared to conventional global checkpointing, we exploit the inherent data compression of the multigrid hierarchy, and relax the synchronicity requirement through a local failure local recovery approach. We experimentally identify the root cause of convergence degradation in the presence of data loss using smoothness considerations. Our resulting schemes form a family of techniques that can be tailored to the expected error probability of (future) large-scale machines. A performance model gives further insight into the benefits and applicability of our techniques. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2015.07.003},
  ISSN                     = {0167-8191},
  Keywords                 = {Fault tolerance},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819115001064}
}

@Article{Göddeke2013132,
  Title                    = {Energy efficiency vs. performance of the numerical solution of PDEs: An application study on a low-power ARM-based cluster },
  Author                   = {Dominik Göddeke and Dimitri Komatitsch and Markus Geveler and Dirk Ribbrock and Nikola Rajovic and Nikola Puzovic and Alex Ramirez},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2013},
  Pages                    = {132 - 150},
  Volume                   = {237},

  Abstract                 = {Power consumption and energy efficiency are becoming critical aspects in the design and operation of large scale \{HPC\} facilities, and it is unanimously recognised that future exascale supercomputers will be strongly constrained by their power requirements. At current electricity costs, operating an \{HPC\} system over its lifetime can already be on par with the initial deployment cost. These power consumption constraints, and the benefits a more energy-efficient \{HPC\} platform may have on other societal areas, have motivated the \{HPC\} research community to investigate the use of energy-efficient technologies originally developed for the embedded and especially mobile markets. However, lower power does not always mean lower energy consumption, since execution time often also increases. In order to achieve competitive performance, applications then need to efficiently exploit a larger number of processors. In this article, we discuss how applications can efficiently exploit this new class of low-power architectures to achieve competitive performance. We evaluate if they can benefit from the increased energy efficiency that the architecture is supposed to achieve. The applications that we consider cover three different classes of numerical solution methods for partial differential equations, namely a low-order finite element multigrid solver for huge sparse linear systems of equations, a Lattice-Boltzmann code for fluid simulation, and a high-order spectral element method for acoustic or seismic wave propagation modelling. We evaluate weak and strong scalability on a cluster of 96 \{ARM\} Cortex-A9 dual-core processors and demonstrate that the ARM-based cluster can be more efficient in terms of energy to solution when executing the three applications compared to an x86-based reference machine. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2012.11.031},
  ISSN                     = {0021-9991},
  Keywords                 = {High performance computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999112007115}
}

@Article{Goehner2013167,
  Title                    = {LIBI: A framework for bootstrapping extreme scale software systems },
  Author                   = {J.D. Goehner and D.C. Arnold and D.H. Ahn and G.L. Lee and B.R. de Supinski and M.P. LeGendre and B.P. Miller and M. Schulz},
  Journal                  = {Parallel Computing },
  Year                     = {2013},
  Note                     = {High-performance Infrastructure for Scalable Tools },
  Number                   = {3},
  Pages                    = {167 - 176},
  Volume                   = {39},

  Abstract                 = {As the sizes of high-end computing systems continue to grow to massive scales, efficient bootstrapping for distributed software infrastructures is becoming a greater challenge. Distributed software infrastructure bootstrapping is the procedure of instantiating all processes of the distributed system on the appropriate hardware nodes and disseminating to these processes the information that they need to complete the infrastructure’s start-up phase. In this paper, we describe the lightweight infrastructure-bootstrapping infrastructure (LIBI), both a bootstrapping \{API\} specification and a reference implementation. We describe a classification system for process launching mechanism and then present a performance evaluation of different process launching schemes based on our \{LIBI\} prototype. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2012.09.003},
  ISSN                     = {0167-8191},
  Keywords                 = {Infrastructure bootstrapping},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819112000774}
}

@InCollection{Goel20127,
  Title                    = {Chapter two - Techniques to Measure, Model, and Manage Power },
  Author                   = {Bhavishya Goel and Sally A. McKee and Magnus Själander},
  Publisher                = {Elsevier},
  Year                     = {2012},
  Editor                   = {Ali Hurson and Atif Memon},
  Pages                    = {7 - 54},
  Series                   = {Advances in Computers },
  Volume                   = {87},

  Abstract                 = {Society’s increasing dependence on information technology has resulted in the deployment of vast compute resources. The energy costs of operating these resources coupled with environmental concerns have made energy-aware computing one of the primary challenges for the \{IT\} sector. Making energy-efficient computing a rule rather than an exception requires that researchers and system designers use the right set of techniques and tools. These involve measuring, analyzing, and controlling the energy expenditure of computers at varying degrees of granularity. In this chapter, we present techniques to measure power consumption of computer systems at various levels and to compare their effectiveness. We discuss methodologies to estimate processor power consumption using performance-counter-based power modeling and show how the power models can be used for power-aware scheduling. Armed with such techniques and methodologies, we as a research and development community can better address challenges in power-aware management. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-396528-8.00002-X},
  ISSN                     = {0065-2458},
  Keywords                 = {Green computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B978012396528800002X}
}

@Article{Gong20116010,
  Title                    = {\{GPU\} accelerated simulations of 3D deterministic particle transport using discrete ordinates method },
  Author                   = {Chunye Gong and Jie Liu and Lihua Chi and Haowei Huang and Jingyue Fang and Zhenghu Gong},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2011},
  Number                   = {15},
  Pages                    = {6010 - 6022},
  Volume                   = {230},

  Abstract                 = {Graphics Processing Unit (GPU), originally developed for real-time, high-definition 3D graphics in computer games, now provides great faculty in solving scientific applications. The basis of particle transport simulation is the time-dependent, multi-group, inhomogeneous Boltzmann transport equation. The numerical solution to the Boltzmann equation involves the discrete ordinates (Sn) method and the procedure of source iteration. In this paper, we present a \{GPU\} accelerated simulation of one energy group time-independent deterministic discrete ordinates particle transport in 3D Cartesian geometry (Sweep3D). The performance of the \{GPU\} simulations are reported with the simulations of vacuum boundary condition. The discussion of the relative advantages and disadvantages of the \{GPU\} implementation, the simulation on multi GPUs, the programming effort and code portability are also reported. The results show that the overall performance speedup of one \{NVIDIA\} Tesla \{M2050\} \{GPU\} ranges from 2.56 compared with one Intel Xeon \{X5670\} chip to 8.14 compared with one Intel Core \{Q6600\} chip for no flux fixup. The simulation with flux fixup on one \{M2050\} is 1.23 times faster than on one X5670. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2011.04.010},
  ISSN                     = {0021-9991},
  Keywords                 = {Particle transport},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999111002348}
}

@Article{Gong2012588,
  Title                    = {Particle transport with unstructured grid on \{GPU\} },
  Author                   = {Chunye Gong and Jie Liu and Haowei Huang and Zhenghu Gong},
  Journal                  = {Computer Physics Communications },
  Year                     = {2012},
  Number                   = {3},
  Pages                    = {588 - 593},
  Volume                   = {183},

  Abstract                 = {The method of discontinuous finite element discrete ordinates which involves inverting an operator by iteratively sweeping across a mesh from multiple directions is commonly used to solve the time-dependent particle transport equation. Graphics Processing Unit (GPU) provides great faculty in solving scientific applications. The particle transport with unstructured grid bringing forward several challenges while implemented on GPU. This paper presents an efficient implementation of particle transport with unstructured grid under 2D cylindrical Lagrange coordinates system on a fine-grained data level parallelism \{GPU\} platform from three aspects. The first one is determining the sweep order of elements from different angular directions. The second one is mapping the sweep calculation onto the \{GPU\} thread execution model. The last one is efficiently using the on-chip memory to improve performance. As to the authorsʼ knowledge, this is the first implementation of a general purpose particle transport simulation with unstructured grid on GPU. Experimental results show that the performance speedup of \{NVIDIA\} \{M2050\} \{GPU\} with double precision floating operations ranges from 11.03 to 17.96 compared with the serial implementation on Intel Xeon \{X5355\} and Core Q6600. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2011.12.002},
  ISSN                     = {0010-4655},
  Keywords                 = {Particle transport},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465511003870}
}

@Article{GonzálezDomínguez20132483,
  Title                    = {The Servet 3.0 benchmark suite: Characterization of network performance degradation },
  Author                   = {Jorge González-Domínguez and María J. Martín and Guillermo L. Taboada and Roberto R. Expósito and Juan Touriño},
  Journal                  = {Computers \& Electrical Engineering },
  Year                     = {2013},
  Number                   = {8},
  Pages                    = {2483 - 2493},
  Volume                   = {39},

  Abstract                 = {Abstract Servet is a suite of benchmarks focused on extracting a set of parameters with high influence on the overall performance of multicore clusters. These parameters can be used to optimize the performance of parallel applications by adapting part of their behavior to the characteristics of the machine. Up to now the tool considered network bandwidth as constant and independent of the communication pattern. Nevertheless, the inter-node communication bandwidth decreases on modern large supercomputers depending on the number of cores per node that simultaneously access the network and on the distance between the communicating nodes. This paper describes two new benchmarks that improve Servet by characterizing the network performance degradation depending on these factors. This work also shows the experimental results of these benchmarks on a Cray \{XE6\} supercomputer and some examples of how real parallel codes can be optimized by using the information about network degradation. },
  Doi                      = {http://dx.doi.org/10.1016/j.compeleceng.2013.08.012},
  ISSN                     = {0045-7906},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045790613002231}
}

@Article{Goodall2013489,
  Title                    = {Non-uniform data distribution for communication-efficient parallel clustering },
  Author                   = {Tabitha Goodall and David Pettinger and Giuseppe Di Fatta},
  Journal                  = {Journal of Computational Science },
  Year                     = {2013},
  Note                     = {Scalable Algorithms for Large-Scale Systems Workshop (ScalA2011), Supercomputing 2011 },
  Number                   = {6},
  Pages                    = {489 - 495},
  Volume                   = {4},

  Abstract                 = {Global communication requirements and load imbalance of some parallel data mining algorithms are the major obstacles to exploit the computational power of large-scale systems. This work investigates how non-uniform data distributions can be exploited to remove the global communication requirement and to reduce the communication cost in parallel data mining algorithms and, in particular, in the k-means algorithm for cluster analysis. In the straightforward parallel formulation of the k-means algorithm, data and computation loads are uniformly distributed over the processing nodes. This approach has excellent load balancing characteristics that may suggest it could scale up to large and extreme-scale parallel computing systems. However, at each iteration step the algorithm requires a global reduction operation which hinders the scalability of the approach. This work studies a different parallel formulation of the algorithm where the requirement of global communication is removed, while maintaining the same deterministic nature of the centralised algorithm. The proposed approach exploits a non-uniform data distribution which can be either found in real-world distributed applications or can be induced by means of multi-dimensional binary search trees. The approach can also be extended to accommodate an approximation error which allows a further reduction of the communication costs. The effectiveness of the exact and approximate methods has been tested in a parallel computing system with 64 processors and in simulations with 1024 processing elements. },
  Doi                      = {http://dx.doi.org/10.1016/j.jocs.2013.01.007},
  ISSN                     = {1877-7503},
  Keywords                 = {Parallel data mining},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877750313000197}
}

@Article{Gorman20121513,
  Title                    = {Hybrid OpenMP/MPI Anisotropic Mesh Smoothing },
  Author                   = {G.J. Gorman and J. Southern and P.E. Farrell and M.D. Piggott and G. Rokos and P.H.J. Kelly},
  Journal                  = {Procedia Computer Science },
  Year                     = {2012},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2012 },
  Pages                    = {1513 - 1522},
  Volume                   = {9},

  Abstract                 = {Mesh smoothing is an important algorithm for the improvement of element quality in unstructured mesh finite element methods. A new optimisation based mesh smoothing algorithm is presented for anisotropic mesh adaptivity. It is shown that this smoothing kernel is very effective at raising the minimum local quality of the mesh. A number of strategies are employed to reduce the algorithm's cost while maintaining its effectiveness in improving overall mesh quality. The method is parallelised using hybrid OpenMP/MPI programming methods, and graph colouring to identify independent sets. Different approaches are explored to achieve good scaling performance within a shared memory compute node. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2012.04.166},
  ISSN                     = {1877-0509},
  Keywords                 = {unstructured mesh},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050912002876}
}

@Article{Götz20152188,
  Title                    = {On Scalable Data Mining Techniques for Earth Science },
  Author                   = {Markus Götz and Matthias Richerzhagen and Christian Bodenstein and Gabriele Cavallaro and Philipp Glock and Morris Riedel and Jón Atli Benediktsson},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {2188 - 2197},
  Volume                   = {51},

  Abstract                 = {Abstract One of the observations made in earth data science is the massive increase of data volume (e.g, higher resolution measurements) and dimensionality (e.g. hyper-spectral bands). Traditional data mining tools (Matlab, R, etc.) are becoming redundant in the analysis of these datasets, as they are unable to process or even load the data. Parallel and scalable techniques, though, bear the potential to overcome these limitations. In this contribution we therefore evaluate said techniques in a High Performance Computing (HPC) environment on the basis of two earth science case studies: (a) Density-based Spatial Clustering of Applications with Noise (DBSCAN) for automated outlier detection and noise reduction in a 3D point cloud and (b) land cover type classification using multi-class Support Vector Machines (SVMs) in multi- spectral satellite images. The paper compares implementations of the algorithms in traditional data mining tools with \{HPC\} realizations and ’big data’ technology stacks. Our analysis reveals that a wide variety of them are not yet suited to deal with the coming challenges of data mining tasks in earth sciences. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.494},
  ISSN                     = {1877-0509},
  Keywords                 = {Data Mining},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915013022}
}

@Article{Graillat201555,
  Title                    = {Numerical Validation of Compensated Summation Algorithms with Stochastic Arithmetic },
  Author                   = {S. Graillat and F. Jézéquel and R. Picot},
  Journal                  = {Electronic Notes in Theoretical Computer Science },
  Year                     = {2015},
  Note                     = {The Seventh and Eighth International Workshops on Numerical Software Verification (NSV) },
  Pages                    = {55 - 69},
  Volume                   = {317},

  Abstract                 = {Abstract Compensated summation algorithms are designed to improve the accuracy of ill-conditioned sums. They are based on algorithms, such as FastTwoSum, which are proved to provide, with rounding to nearest, the sum of two floating-point numbers and the associated rounding error. Discrete stochastic arithmetic enables one to estimate rounding error propagation in numerical codes. It requires a random rounding mode which consists in rounding each computed result toward −∞ or +∞ with the same probability. In this paper we analyse the impact of this random rounding mode on compensated summations based on the FastTwoSum algorithm. We show the accuracy improvement obtained using such compensated summations in numerical simulations controlled with discrete stochastic arithmetic. },
  Doi                      = {http://dx.doi.org/10.1016/j.entcs.2015.10.007},
  ISSN                     = {1571-0661},
  Keywords                 = {floating-point arithmetic},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1571066115000481}
}

@Article{Guo2015227,
  Title                    = {Developing a scalable hybrid MPI/OpenMP unstructured finite element model },
  Author                   = {Xiaohu Guo and Michael Lange and Gerard Gorman and Lawrence Mitchell and Michèle Weiland},
  Journal                  = {Computers \& Fluids },
  Year                     = {2015},
  Note                     = {ParCFD 2013 },
  Pages                    = {227 - 234},
  Volume                   = {110},

  Abstract                 = {Abstract The trend of all modern computer architectures, and the path to exascale, is towards increasing numbers of lower power cores, with a decreasing memory to core ratio. This imposes a strong evolutionary pressure on algorithms and software to efficiently utilise all levels of parallelism available on a given platform while minimising data movement. Unstructured finite elements codes have long been effectively parallelised using domain decomposition methods, implemented using libraries such as the Message Passing Interface (MPI). However, there are many optimisation opportunities when threading is used for intra-node parallelisation for the latest multi-core/many-core platforms. The benefits include increased algorithmic freedom, reduced memory requirements, cache sharing, reduced number of partitions, less \{MPI\} communication and I/O overhead. In this paper, we report progress in implementing a hybrid OpenMP–MPI version of the unstructured finite element code Fluidity. For matrix assembly kernels, the OpenMP parallel algorithm uses graph colouring to identify independent sets of elements that can be assembled concurrently with no race conditions. In this phase there are no \{MPI\} overheads as each \{MPI\} process only assembles its own local part of the global matrix. We use an OpenMP threaded fork of \{PETSc\} to solve the resulting sparse linear systems of equations. We experiment with a range of preconditioners, including \{HYPRE\} which provides the algebraic multigrid preconditioner BoomerAMG where the smoother is also threaded. Since unstructured finite element codes are well known to be memory latency bound, particular attention is paid to ccNUMA architectures where data locality is particularly important to achieve good intra-node scaling characteristics. We also demonstrate that utilising non-blocking algorithms and libraries are critical to mixed-mode application so that it can achieve better parallel performance than the pure \{MPI\} version. },
  Doi                      = {http://dx.doi.org/10.1016/j.compfluid.2014.09.007},
  ISSN                     = {0045-7930},
  Keywords                 = {Fluidity-ICOM},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045793014003442}
}

@Article{Gupta20151,
  Title                    = {IMSuite: A benchmark suite for simulating distributed algorithms },
  Author                   = {Suyash Gupta and V. Krishna Nandivada},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2015},
  Pages                    = {1 - 19},
  Volume                   = {75},

  Abstract                 = {Abstract Considering the diverse nature of real-world distributed applications that makes it hard to identify a representative subset of distributed benchmarks, we focus on their underlying distributed algorithms. We present and characterize a new kernel benchmark suite (named IMSuite) that simulates some of the classical distributed algorithms in task parallel languages. We present multiple variations of our kernels, broadly categorized under two heads: (a) varying synchronization primitives (with and without fine grain synchronization primitives); and (b) varying forms of parallelization (data parallel and recursive task parallel). Our characterization covers interesting aspects of distributed applications such as distribution of remote communication requests, number of synchronization, task creation, task termination and atomic operations. We study the behavior (execution time) of our kernels by varying the problem size, the number of compute threads, and the input configurations. We also present an involved set of input generators and output validators. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2014.10.010},
  ISSN                     = {0743-7315},
  Keywords                 = {Benchmarks},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731514002032}
}

@Article{Hadka2015353,
  Title                    = {Large-scale parallelization of the Borg multiobjective evolutionary algorithm to enhance the management of complex environmental systems },
  Author                   = {David Hadka and Patrick Reed},
  Journal                  = {Environmental Modelling \& Software },
  Year                     = {2015},
  Pages                    = {353 - 369},
  Volume                   = {69},

  Abstract                 = {Abstract The Borg \{MOEA\} is a self-adaptive multiobjective evolutionary algorithm capable of solving complex, many-objective environmental systems problems efficiently and reliably. Water and environmental resources problems pose significant computational challenges due to their potential for large Pareto optimal sets, the presence of disjoint Pareto-optimal regions that arise from discrete choices, multi-modal suboptimal regions, and expensive objective function calculations. This work develops two large-scale parallel implementations of the Borg MOEA, the master–slave and multi-master Borg MOEA, and applies them to a highly challenging risk-based water supply portfolio planning problem. The performance and scalability of both implementations are compared on up to 16384 processors. The multi-master Borg \{MOEA\} is shown to scale efficiently on tens of thousands of cores while dramatically improving the reliability of attaining high-quality solutions. Our results dramatically expand the scale and scope of complex environmental systems that can be addressed using many-objective evolutionary optimization. },
  Doi                      = {http://dx.doi.org/10.1016/j.envsoft.2014.10.014},
  ISSN                     = {1364-8152},
  Keywords                 = {Evolutionary algorithm},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1364815214003041}
}

@Article{Hadri20131834,
  Title                    = {Mining Software Usage with the Automatic Library Tracking Database (ALTD) },
  Author                   = {Bilel Hadri and Mark Fahey},
  Journal                  = {Procedia Computer Science },
  Year                     = {2013},
  Note                     = {2013 International Conference on Computational Science },
  Pages                    = {1834 - 1843},
  Volume                   = {18},

  Abstract                 = {Abstract Tracking software usage is important for \{HPC\} centers, computer vendors, code developers and funding agencies to provide more efficient and targeted software support, and to forecast needs and guide \{HPC\} software effort towards the Exascale era. However, accurately tracking software usage on \{HPC\} systems has been a challenging task. In this paper, we present a tool called Automatic Library Tracking Database (ALTD) that has been developed and put in production on several Cray systems. The \{ALTD\} infrastructure prototype automatically and transparently stores information about libraries linked into an application at compilation time and also the executables launched in a batch job. We will illustrate the usage of libraries, compilers and third party software applications on a system managed by the National Institute for Computational Sciences. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2013.05.352},
  ISSN                     = {1877-0509},
  Keywords                 = {ALTD},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S187705091300495X}
}

@Article{Hag2015476,
  Title                    = {On Uniform Traffic Pattern of Symmetric Midimew Connected Mesh Network },
  Author                   = {Ala Ahmed Yahya Hag and M.M. Hafizur Rahman and Rizal Mohd Nor and Tengku Mohd Tengku Sembok},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {Big Data, Cloud and Computing Challenges },
  Pages                    = {476 - 481},
  Volume                   = {50},

  Abstract                 = {Abstract A Symmetric Midimew Mesh connected network (SMMN) is a hierarchical interconnection networks (HIN) that capable to interconnect vast number of nodes that could reach up to millions of nodes in the network. \{SMMN\} has multiple basic modules of 2D-mesh networks that are recursively interconnected by Midimew network to create higher-level networks. In this paper, we explain the architectural details of SMMN,we also present the a deadlock-free routing algorithm for \{SMMN\} using four virtual channels and evaluate the performance of dynamic communication of \{SMMN\} network using proposed routing algorithm under uniform traffic pattern .We also evaluate the performance of dynamic communication of \{TESH\} network using topaz simulator. It is shown that the \{SMMN\} network has high throughput and low latency, which yield higher performance of dynamic communication compare to other Hierarchical networks. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.04.017},
  ISSN                     = {1877-0509},
  Keywords                 = {Massively Parallel Computer},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915005189}
}

@Article{Hag2015400,
  Title                    = {Uniform Traffic Patterns using Virtual Cut-Through Flow Control on \{VMMN\} },
  Author                   = {Ala Ahmed Yahya Hag and M.M. Hafizur Rahman and Rizal Mohd Nor and Tengku Mohd Tengku Sembok and Yasuyuki Miura and Yasushi Inoguchi},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference on Computer Science and Computational Intelligence (ICCSCI 2015) },
  Pages                    = {400 - 409},
  Volume                   = {59},

  Abstract                 = {Abstract The previous study of static network performance of a Vertical Midimew connected Mesh Network (VMMN) was shown to be good. However, its dynamic communication performance has not been evaluated yet, we have proposed a deadlock free dimension order routing algorithm using 4 virtual channels. In this paper, The \{TOPAZ\} simulator is used to evaluate the dynamic communication performance of a \{VMMN\} with virtual cut-through flow control under uniform traffic pattern. We found that the \{VMMN\} dynamic communication performance is better than that of the hierarchical \{TESH\} network and its counter rival MMN. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.07.553},
  ISSN                     = {1877-0509},
  Keywords                 = {\{TOPAZ\} Simulator ;Virtual Cut Through},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915020827}
}

@Article{Hahn2016108,
  Title                    = {Symmetric tilt boundaries in body-centered cubic tantalum },
  Author                   = {Eric N. Hahn and Saryu J. Fensin and Timothy C. Germann and Marc A. Meyers},
  Journal                  = {Scripta Materialia },
  Year                     = {2016},
  Pages                    = {108 - 111},
  Volume                   = {116},

  Abstract                 = {Abstract Grain boundaries can play a significant role in the mechanical response of materials. Atomistic simulations are used to investigate 79 coincidence site lattice grain boundary structures and energies in tantalum, a model body-centered cubic transition metal. Quasi-symmetric Σ3, Σ5, Σ7, Σ13, and Σ27 boundaries are observed, of which Σ3 and Σ7 also exist as traditional mirror-symmetry conserving boundary structures. These results are supported by previous observations of similar phenomena in other bcc transition metal Σ5 boundaries. Metastable low energy Σ3 boundary structures in tantalum could influence the formation and stability of deformation twins and abnormal growth grain favoring Σ3 boundaries. },
  Doi                      = {http://dx.doi.org/10.1016/j.scriptamat.2016.01.038},
  ISSN                     = {1359-6462},
  Keywords                 = {Coincidence lattice},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1359646216300379}
}

@Article{Hahn2015101,
  Title                    = {Grain-size dependent mechanical behavior of nanocrystalline metals },
  Author                   = {Eric N. Hahn and Marc A. Meyers},
  Journal                  = {Materials Science and Engineering: A },
  Year                     = {2015},
  Pages                    = {101 - 134},
  Volume                   = {646},

  Abstract                 = {Abstract Grain size has a profound effect on the mechanical response of metals. Molecular dynamics continues to expand its range from a handful of atoms to grain sizes up to 50 nm, albeit commonly at strain rates generally upwards of 106 s−1. In this review we examine the most important theories of grain size dependent mechanical behavior pertaining to the nanocrystalline regime. For the sake of clarity, grain sizes d are commonly divided into three regimes: d&gt;1 μm, 1 μm&lt;d&lt;100 nm; and d&lt;100 nm. These different regimes are dominated by different mechanisms of plastic flow initiation. We focus here in the region d&lt;100 nm, aptly named the nanocrystalline region. An interesting and representative phenomenon at this reduced spatial scale is the inverse Hall–Petch effect observed experimentally and in \{MD\} simulations in FCC, BCC, and \{HCP\} metals. Significantly, we compare the results of molecular dynamics simulations with analytical models and mechanisms based on the contributions of Conrad and Narayan and Argon and Yip, who attribute the inverse Hall–Petch relationship to the increased contribution of grain-boundary shear as the grain size is reduced. The occurrence of twinning, more prevalent at the high strain rates enabled by shock compression, is evaluated. },
  Doi                      = {http://dx.doi.org/10.1016/j.msea.2015.07.075},
  ISSN                     = {0921-5093},
  Keywords                 = {Nanocrystalline metals},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0921509315302276}
}

@Article{vanderHeiden201542,
  Title                    = {The role of education and training in absorptive capacity of international technology transfer in the aerospace sector },
  Author                   = {Patrick van der Heiden and Christine Pohl and Shuhaimi Bin Mansor and John van Genderen},
  Journal                  = {Progress in Aerospace Sciences },
  Year                     = {2015},
  Pages                    = {42 - 54},
  Volume                   = {76},

  Abstract                 = {Abstract The role of education and training in the aerospace sector for establishing sufficient levels of absorptive capacity in newly industrialized countries is substantial and forms a fundamental part of a nation’s ability to establish and cultivate absorptive capacity on a national or organization-specific level. Successful international technology transfer as well as absorption of aerospace technology and knowledge into recipient organizations, depends prodigiously on the types of policy adopted in education and training of all groups and individuals specifically outlined in this paper. The conducted literature review revealed surprisingly few papers that translate these vital issues from theoretical scrutiny into representations that have practical policy value. Through exploration of the seven key aspects of education and training, this paper provides a practical template for policy-makers and practitioners in Asian newly industrialized countries, which may be utilized as a prototype to coordinate relevant policy aspects of education and training in international technology transfer projects across a wide variety of actors and stakeholders in the aerospace realm. A pragmatic approach through tailored practical training for the identified groups and individuals identified in this paper may lead to an enhanced ability to establish and strengthen absorptive capacity in newly industrialized countries through the development of appropriate policy guidelines. The actual coordination between education and training efforts deserves increased research and subsequent translation into policies with practical content in the aerospace sector. },
  Doi                      = {http://dx.doi.org/10.1016/j.paerosci.2015.05.003},
  ISSN                     = {0376-0421},
  Keywords                 = {Education},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0376042115000342}
}

@Article{Herbein201617,
  Title                    = {Performance characterization of irregular I/O at the extreme scale },
  Author                   = {S. Herbein and S. McDaniel and N. Podhorszki and J. Logan and S. Klasky and M. Taufer},
  Journal                  = {Parallel Computing },
  Year                     = {2016},
  Note                     = {Special Issue on Parallel Programming Models and SystemsSoftware for High-End Computing },
  Pages                    = {17 - 36},
  Volume                   = {51},

  Abstract                 = {Abstract This paper reports our experience with irregular I/O and describes lessons learned when running applications with such I/O on supercomputers at the extreme scale. Specifically, we study how irregularities in I/O patterns (i.e., irregular amount of data written per process at each I/O step) in scientific simulations can cause increasing I/O times and substantial loss in scalability. To this end, we quantify the impact of irregular I/O patterns on the I/O performance of scientific applications at the extreme scale by statistically modeling the irregular I/O behavior of two scientific applications: the Monte Carlo application \{QMCPack\} and the adaptive mesh refinement application ENZO. For our testing, we feed our model into I/O kernels of two well-known I/O data models (i.e., \{ADIOS\} and HDF) to measure the performance of the two applications’ I/O under different I/O settings. Empirically, we show how the growing data sizes and the irregular I/O patterns in these applications are both relevant factors impacting performance. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2015.10.009},
  ISSN                     = {0167-8191},
  Keywords                 = {Exascale},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819115001386}
}

@InCollection{Hodges2014,
  Title                    = {Hydrodynamical Modeling☆ },
  Author                   = {B.R. Hodges},
  Booktitle                = {Reference Module in Earth Systems and Environmental Sciences },
  Publisher                = {Elsevier},
  Year                     = {2014},
  Pages                    = { - },

  Abstract                 = {Abstract Hydrodynamic models are tools for quantifying flow and transport through inland waters. Although such models can be visually quite stunning, their accuracy and believability depends on careful model selection, setup, validation, and analysis. This article examines general model types, capabilities and limitations. The focus is on underlying issues of dimensionality, boundary conditions, calibration, grid selection, time and space resolution, solution methods, and accuracy. These issues are not model-specific, but apply across a broad class of models. Tabulated overview of some previous models are provided, along with some thoughts on overall limitations and possible future advances. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-409548-9.09123-5},
  ISBN                     = {978-0-12-409548-9},
  Keywords                 = {1D},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780124095489091235}
}

@Article{Hodges201316,
  Title                    = {Challenges in Continental River Dynamics },
  Author                   = {Ben R. Hodges},
  Journal                  = {Environmental Modelling \& Software },
  Year                     = {2013},
  Pages                    = {16 - 20},
  Volume                   = {50},

  Abstract                 = {Abstract Continental River Dynamics (CRD) is herein defined as modelling the flow dynamics in all channels of a continental-scale river basin using the physics-based Saint-Venant equations. At the boundary of hydraulics and hydrology, \{CRD\} requires significant collaborative efforts to make new progress. Six constraints and seven challenges are identified in the areas of dynamics, dimensionality, resolution, uncertainty, model coupling, and data availability. Three key short-term needs for \{CRD\} are identified as (1) scaling up Saint-Venant river models to continental scales, (2) standards for integrating river and hydrology models, and (3) methods for effective use of lidar data and synthetic methods for approximating geometry for 1D dynamic models. An over-arching need for comprehensive data collection programs for river geometry is discussed. },
  Doi                      = {http://dx.doi.org/10.1016/j.envsoft.2013.08.010},
  ISSN                     = {1364-8152},
  Keywords                 = {Saint-Venant equations},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1364815213001898}
}

@Article{Horelik2014646,
  Title                    = {Monte Carlo domain decomposition for robust nuclear reactor analysis },
  Author                   = {Nicholas Horelik and Andrew Siegel and Benoit Forget and Kord Smith},
  Journal                  = {Parallel Computing },
  Year                     = {2014},
  Number                   = {10},
  Pages                    = {646 - 660},
  Volume                   = {40},

  Abstract                 = {Abstract Monte Carlo (MC) neutral particle transport codes are considered the gold-standard for nuclear simulations, but they cannot be robustly applied to high-fidelity nuclear reactor analysis without accommodating several terabytes of materials and tally data. While this is not a large amount of aggregate data for a typical high performance computer, \{MC\} methods are only embarrassingly parallel when the key data structures are replicated for each processing element, an approach which is likely infeasible on future machines. The present work explores the use of spatial domain decomposition to make full-scale nuclear reactor simulations tractable with Monte Carlo methods, presenting a simple implementation in a production-scale code. Good performance is achieved for mesh-tallies of up to 2.39 \{TB\} distributed across 512 compute nodes while running a full-core reactor benchmark on the Mira Blue Gene/Q supercomputer at the Argonne National Laboratory. In addition, the effects of load imbalances are explored with an updated performance model that is empirically validated against observed timing results. Several load balancing techniques are also implemented to demonstrate that imbalances can be largely mitigated, including a new and efficient way to distribute extra compute resources across finer domain meshes. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2014.10.001},
  ISSN                     = {0167-8191},
  Keywords                 = {Monte Carlo},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819114001240}
}

@Article{Horio2015623,
  Title                    = {Potential of the ‘Renewable Energy Exodus’ (a mass rural remigration) for massive \{GHG\} reduction in Japan },
  Author                   = {Masayuki Horio and Sawako Shigeto and Ryota Ii and Yukihiro Shimatani and Masato Hidaka},
  Journal                  = {Applied Energy },
  Year                     = {2015},
  Pages                    = {623 - 632},
  Volume                   = {160},

  Abstract                 = {Abstract For the utilization of renewable energy from sources widely distributed in low-density non-urban areas the grid augmentation for its transmission to urban areas of high population density is often discussed under the premise that the present demand distribution remains invariant. Instead of grid augmentation, this study examined an alternative option of creating a power demand close to renewable sources and inducing population movements (i.e., Renewable Energy Exodus). First, the capacity of renewable energy to maintain populations in hilly and mountainous farming areas of Japan was evaluated from two perspectives: Task (1) a challenging nationwide balance based on possible energy demand saving scenario for the future, and Task (2) a conservative nationwide balance based on the current per capita energy demand and on the region-by-region generation–consumption matching concept. Because Task (2) indicated that Hokkaido, the northern-most island, has a huge capacity, Task (3) was conducted for Hokkaido by examining both energy balance and economic evaluation including job creation for the following two scenarios: (A) a supply to Tokyo scenario and (B) a local demand generation scenario, keeping the same conservativeness as Task (2) by using the current data for energy consumption per capita. The nationwide Renewable Energy Exodus estimates gave 48 million people for Task (1) (with the future per capita energy demand) and 10 million people for Task (2) (with the current per capita energy demand and region-by-region self-sustained balance), respectively. For Hokkaido Task (3) (with an additional economic assessment) gave 1 million people. The Renewable Energy Exodus concept combined with the green economy promotion was found to have a significant merit for a sustainable future of countries like Japan where economic and social disparities are serious between urban areas and non-urban areas. },
  Doi                      = {http://dx.doi.org/10.1016/j.apenergy.2015.03.087},
  ISSN                     = {0306-2619},
  Keywords                 = {Massive \{GHG\} emission reduction},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S030626191500389X}
}

@Article{Hsu2010701,
  Title                    = {Special section: Peer-to-peer grid technologies },
  Author                   = {Ching-Hsien Hsu and Hai Jin and Franck Cappello},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2010},
  Number                   = {5},
  Pages                    = {701 - 703},
  Volume                   = {26},

  Doi                      = {http://dx.doi.org/10.1016/j.future.2010.02.005},
  ISSN                     = {0167-739X},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X1000021X}
}

@Article{Hugues2011471,
  Title                    = {\{ASIODS\} - An Asynchronous and Smart I/O Delegation System },
  Author                   = {Maxime R. Hugues and Michael Moretti and Serge G. Petiton and Henri Calandra},
  Journal                  = {Procedia Computer Science },
  Year                     = {2011},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2011 },
  Pages                    = {471 - 478},
  Volume                   = {4},

  Abstract                 = {In high performance computing, many large scientific and engineering problems are solved on a supercomputer which is the gathering of two specialized entities, one dedicated to computations and another one to I/O. Many applications to settle problems have deterministic behaviors in computations and I/O. This knowledge may be used to load data in advance or delegate data writing on dedicated nodes. Thereby, it could be interesting to use the specialized parts of the supercomputer and this knowledge in order to have a better cache management by uncoupling computations and I/O. This has led to the design and evaluation of a first prototype of ASIODS. This paper presents the architecture of our approach and the results obtained showing the concept capabilities. We demonstrate that the approach reduces the execution time by avoiding I/O access penalties. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2011.04.049},
  ISSN                     = {1877-0509},
  Keywords                 = {I/O Delegation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050911001074}
}

@Article{Huenich20151383,
  Title                    = {Providing Parallel Debugging for \{DASH\} Distributed Data Structures with \{GDB\} },
  Author                   = {Denis Hünich and Andreas Knüpfer and José Gracia},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {1383 - 1392},
  Volume                   = {51},

  Abstract                 = {Abstract The C + + \{DASH\} template library provides distributed data container for Partitioned Global Address Space (PGAS)-like programming. Because \{DASH\} is new and under development no debugger is capable to handle the parallel processes or access/modify container elements in a convenient way. This paper describes how the \{DASH\} library has to be extended to interrupt the start-up process to connect a debugger with all started processes and to enable the debugger for accessing and modifying \{DASH\} container elements. Furthermore, an \{GDB\} extension to output well formatted \{DASH\} container information is presented. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.345},
  ISSN                     = {1877-0509},
  Keywords                 = {C++ templates},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915011539}
}

@Article{Hupp201678,
  Title                    = {Global communication schemes for the numerical solution of high-dimensional \{PDEs\} },
  Author                   = {Philipp Hupp and Mario Heene and Riko Jacob and Dirk Pflüger},
  Journal                  = {Parallel Computing },
  Year                     = {2016},
  Pages                    = {78 - 105},
  Volume                   = {52},

  Abstract                 = {Abstract The numerical treatment of high-dimensional partial differential equations is among the most compute-hungry problems and in urgent need for current and future high-performance computing (HPC) systems. It is thus also facing the grand challenges of exascale computing such as the requirement to reduce global communication. To cope with high dimensionalities we employ a hierarchical discretization scheme, the sparse grid combination technique. Based on an extrapolation scheme, the combination technique additionally mitigates the need for global communication: multiple and much smaller problems can be computed independently for each time step, and the global communication shrinks to a reduce/broadcast step in between. Here, we focus on this remaining synchronization step of the combination technique and present two communication schemes designed to either minimize the number of communication rounds or the total communication volume. Experiments on two different supercomputers show that either of the schemes outperforms the other depending on the size of the problem. Furthermore, we present a communication model based on the system’s latency and bandwidth and validate the model with the experiments. The model can be used to predict the runtime of the reduce/broadcast step for dimensionalities that are yet out of scope on current supercomputers. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2015.12.006},
  ISSN                     = {0167-8191},
  Keywords                 = {Global communication},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819115001623}
}

@Article{Hursey201215,
  Title                    = {Analyzing fault aware collective performance in a process fault tolerant \{MPI\} },
  Author                   = {Joshua Hursey and Richard L. Graham},
  Journal                  = {Parallel Computing },
  Year                     = {2012},
  Note                     = {Extensions for Next-Generation Parallel Programming Models },
  Number                   = {1–2},
  Pages                    = {15 - 25},
  Volume                   = {38},

  Abstract                 = {Application developers are investigating Algorithm Based Fault Tolerance (ABFT) techniques to improve the efficiency of application recovery beyond what traditional techniques alone can provide. Applications will depend on libraries to sustain failure-free performance across process failure to continue to use High Performance Computing (HPC) systems efficiently even in the presence of process failure. Optimized Message Passing Interface (MPI) collective operations are a critical component of many scalable \{HPC\} applications. However, most of the collective algorithms are not able to handle process failure. Next generation \{MPI\} implementations must provide fault aware versions of such algorithms that can sustain performance across process failure. This paper discusses the design and implementation of fault aware collective algorithms for tree structured communication patterns. The three design approaches of rerouting, lookup avoiding and rebalancing are described, and analyzed for their performance impact relative to similar fault unaware barrier and broadcast collective algorithms. The analysis shows that the rerouting approach causes a significant performance degradation while the rebalancing approach can bring the performance within 1% of the fault unaware performance. This paper also presents the impact of the run-through stabilization prototype on point-to-point communication, and analyzes the time to rebalance the tree while accounting for process failures. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2011.10.010},
  ISSN                     = {0167-8191},
  Keywords                 = {MPI},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819111001414}
}

@Article{Hwu20142574,
  Title                    = {What is ahead for parallel computing },
  Author                   = {Wen-mei Hwu},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2014},
  Note                     = {Special Issue on Perspectives on Parallel and Distributed Processing },
  Number                   = {7},
  Pages                    = {2574 - 2581},
  Volume                   = {74},

  Abstract                 = {Abstract With the industry-wide switch to multicore and manycore architectures, parallel computing has become the only venue in sight for continued growth in application performance. In order for the performance of an application to grow with future generations of hardware, a significant portion of its computation must be done with scalable parallel algorithms. It is therefore important to develop and deploy as many scalable parallel algorithms as possible. This paper takes a critical look at the major challenges involved in the development of scalable parallel algorithms and points to needs for compiler tool innovations to help address these challenges. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2014.02.005},
  ISSN                     = {0743-7315},
  Keywords                 = {Parallel algorithms},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731514000331}
}

@Article{Igual2015139,
  Title                    = {Non-negative Matrix Factorization on Low-Power Architectures and Accelerators: A Comparative Study },
  Author                   = {Francisco D. Igual and Carlos García and Guillermo Botella and Luis Piñuel and Manuel Prieto-Matías and Francisco Tirado},
  Journal                  = {Computers \& Electrical Engineering },
  Year                     = {2015},
  Pages                    = {139 - 156},
  Volume                   = {46},

  Abstract                 = {Abstract Power consumption is emerging as one of the main concerns in the High Performance Computing (HPC) field. As a growing number of bioinformatics applications require \{HPC\} techniques and parallel architectures to meet performance requirements, power consumption arises as an additional limitation when accelerating them. In this paper, we present a comparative study of optimized implementations of the Non-negative Matrix Factorization (NMF), that is widely used in many fields of bioinformatics, taking into account both performance and power consumption. We target a wide range of state-of-the-art parallel architectures, including general-purpose, low-power processors and specific-purpose accelerators like GPUs, \{DSPs\} or the Intel Xeon Phi. From our study, we gain insights in both performance and energy consumption for each one of them under a number of experimental conditions, and conclude that the most appropriate architecture is usually a trade-off between performance and energy consumption for a given experimental setup and dataset. },
  Doi                      = {http://dx.doi.org/10.1016/j.compeleceng.2015.03.035},
  ISSN                     = {0045-7906},
  Keywords                 = {NMF},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045790615001287}
}

@Article{Imran20161,
  Title                    = {Performance evaluation of hybrid optical switch architecture for data center networks },
  Author                   = {Muhammad Imran and Martin Collier and Pascal Landais and Kostas Katrinis},
  Journal                  = {Optical Switching and Networking },
  Year                     = {2016},
  Pages                    = {1 - 15},
  Volume                   = {21},

  Abstract                 = {Abstract In response to the need for high bandwidth and power efficient data center interconnection networks, different interconnects have been proposed based on the optical technology used: micro-electromechanical system (MEMS), optical cross connects (OXCs), arrayed waveguide grating routers (AWGRs) and semiconductor optical amplifier (SOAs). \{MEMS\} switches are based on mature technology, have low insertion loss and cross-talk, and are data rate independent. They are also the most scalable and the cheapest class of optical switches. However, the reconfiguration time of these switches is of the order of tens of milliseconds while fast optical switches have switching time in the range of a few nanoseconds. Fast optical switches can be based on \{AWGRs\} in conjunction with tunable wavelength converters or tunable lasers or they are based on \{SOAs\} in broadcast-and-select architecture. In this paper, we propose an optical interconnect architecture for the large scale data centers. The proposed interconnect: Hybrid Optical Switch Architecture (HOSA) is a hybrid design that features slow and fast optical switches. The hybrid design leverages strengths of both types of optical switches. To reduce complexity, we employ a single stage core topology that can be easily scaled up (in capacity) and scaled out (in the number of racks) without requiring major re-cabling and network reconfiguration. We investigate the scalability of the \{HOSA\} and show that by using a single stage core topology, it can be scaled to a hundreds of thousands of servers. We also investigate a trade-off between cost and power consumption of our design by comparing it with other well-known interconnects by using analytical modelling. We demonstrate power efficiency as compared to other conventional interconnects on account of upfront \{CAPEX\} but the additional \{CAPEX\} incurred in deploying our solution instead of traditional architecture is mitigated to some extent by reduced OPEX, due to its greater energy efficiency. We evaluate the performance of the system using network-level simulation by considering diverse workload communication patterns and system design parameters. Our results show low latency and high throughput with different workload communication patterns. },
  Doi                      = {http://dx.doi.org/10.1016/j.osn.2015.12.003},
  ISSN                     = {1573-4277},
  Keywords                 = {Optical interconnects},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1573427715001277}
}

@Article{Jacobsen20131,
  Title                    = {Multi-level parallelism for incompressible flow computations on \{GPU\} clusters },
  Author                   = {Dana A. Jacobsen and Inanc Senocak},
  Journal                  = {Parallel Computing },
  Year                     = {2013},
  Number                   = {1},
  Pages                    = {1 - 20},
  Volume                   = {39},

  Abstract                 = {We investigate multi-level parallelism on \{GPU\} clusters with MPI-CUDA and hybrid MPI-OpenMP-CUDA parallel implementations, in which all computations are done on the \{GPU\} using CUDA. We explore efficiency and scalability of incompressible flow computations using up to 256 \{GPUs\} on a problem with approximately 17.2 billion cells. Our work addresses some of the unique issues faced when merging fine-grain parallelism on the \{GPU\} using \{CUDA\} with coarse-grain parallelism that use either \{MPI\} or MPI-OpenMP for communications. We present three different strategies to overlap computations with communications, and systematically assess their impact on parallel performance on two different \{GPU\} clusters. Our results for strong and weak scaling analysis of incompressible flow computations demonstrate that \{GPU\} clusters offer significant benefits for large data sets, and a dual-level MPI-CUDA implementation with maximum overlapping of computation and communication provides substantial benefits in performance. We also find that our tri-level MPI-OpenMP-CUDA parallel implementation does not offer a significant advantage in performance over the dual-level implementation on \{GPU\} clusters with two \{GPUs\} per node, but on clusters with higher \{GPU\} counts per node or with different domain decomposition strategies a tri-level implementation may exhibit higher efficiency than a dual-level implementation and needs to be investigated further. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2012.10.002},
  ISSN                     = {0167-8191},
  Keywords                 = {GPU},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819112000804}
}

@Article{Jafer201354,
  Title                    = {Synchronization methods in parallel and distributed discrete-event simulation },
  Author                   = {Shafagh Jafer and Qi Liu and Gabriel Wainer},
  Journal                  = {Simulation Modelling Practice and Theory },
  Year                     = {2013},
  Pages                    = {54 - 73},
  Volume                   = {30},

  Abstract                 = {This work attempts to provide insight into the problem of executing discrete event simulation in a distributed fashion. The article serves as the state of the art in Parallel Discrete-Event Simulation (PDES) by surveying existing algorithms and analyzing the merits and drawbacks of various techniques. We discuss the main characteristics of existing synchronization methods for parallel and distributed discrete event simulation. The two major categories of synchronization protocols, namely conservative and optimistic, are introduced and various approaches within each category are presented. We also present the latest efforts towards \{PDES\} on emerging platforms such as heterogeneous multicore processors, Web services, as well as Grid and Cloud environment. },
  Doi                      = {http://dx.doi.org/10.1016/j.simpat.2012.08.003},
  ISSN                     = {1569-190X},
  Keywords                 = {Discrete-event simulation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1569190X12001244}
}

@InCollection{Jamshed201521,
  Title                    = {Chapter 2 - Introduction to High-Performance Computing },
  Author                   = {Shamoon Jamshed},
  Booktitle                = {Using \{HPC\} for Computational Fluid Dynamics },
  Publisher                = {Academic Press},
  Year                     = {2015},

  Address                  = {Oxford},
  Editor                   = {Jamshed, Shamoon },
  Pages                    = {21 - 40},

  Abstract                 = {Abstract This chapter introduces high-performance computing (HPC). High-performance computing is used in every field of science and engineering and cannot be taken for granted. The pioneers of \{HPC\} and their contribution are discussed and the world's top five computers are mentioned and discussed in detail. Sparse matrices, libraries necessary to run an \{HPC\} environment, such as \{LAPACK\} and BLAS, are also discussed in detail. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-801567-4.00002-7},
  ISBN                     = {978-0-12-801567-4},
  Keywords                 = {BLAS},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780128015674000027}
}

@Article{Jia20139,
  Title                    = {The analysis of a plane wave pseudopotential density functional theory code on a \{GPU\} machine },
  Author                   = {Weile Jia and Zongyan Cao and Long Wang and Jiyun Fu and Xuebin Chi and Weiguo Gao and Lin-Wang Wang},
  Journal                  = {Computer Physics Communications },
  Year                     = {2013},
  Number                   = {1},
  Pages                    = {9 - 18},
  Volume                   = {184},

  Abstract                 = {Plane wave pseudopotential (PWP) density functional theory (DFT) calculation is the most widely used material science simulation, and the \{PWP\} \{DFT\} codes are arguably the most important material science codes. We have implemented a \{PWP\} \{DFT\} code \{PEtot\} on a multi-node \{GPU\} machine. Starting from a previous work, we have further improved the speed of the code, and achieved x13-x22 speedups over the \{CPU\} calculations for a typical 512 atom system. Such speedups are much higher than other similar works for this important class of material simulation codes on \{GPU\} clusters. The current achievement is obtained by (1) moving the calculation fully into the GPU; (2) adopting a new algorithm to reduce the data amount for \{MPI\} communication; and (3) using new \{GPU\} and \{CPU\} numerical libraries. We have also provided a detail quantitative analysis of the computational times for different physical systems and number of \{GPU\} units, which helps one to understand the challenges and bottlenecks of the \{PWP\} \{DFT\} simulations on \{GPU\} machines. Based on the analysis, we listed the machine and library requirements in order to further improve the performances of the \{PWP\} \{DFT\} calculations. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2012.08.002},
  ISSN                     = {0010-4655},
  Keywords                 = {Electronic structure},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S001046551200255X}
}

@Article{Jin20131774,
  Title                    = {Extending the Eclipse Parallel Tools Platform Debugger with Scalable Parallel Debugging Library },
  Author                   = {Chao Jin and Liang Ding and David Abramson},
  Journal                  = {Procedia Computer Science },
  Year                     = {2013},
  Note                     = {2013 International Conference on Computational Science },
  Pages                    = {1774 - 1783},
  Volume                   = {18},

  Abstract                 = {Abstract The Eclipse Parallel Tools Platform (PTP) is an open source Integrated Development Environment (IDE) aiding the development of Supercomputer applications. The \{PTP\} parallel debugger is used by a growing community of developers in scientific and engineering fields. This paper proposes a method of improving the communication infrastructure of the \{PTP\} debugger by taking advantage of a Scalable Parallel Debugging Library (SPDL). Unlike the present communication framework of PTP, the Scalable Debug Manager (SDM), \{SPDL\} provides a pluggable architecture that allows developers to select a communication protocol suitable for a targeted supercomputer. It currently supports a number of scalable protocols, including \{MRNet\} and SCI. The advanced features provided by these communication trees, like programmable filters and configurable topologies, allow developers to create more flexible solutions of efficient reduction and aggregation operations for parallel debugging. In particular, they allow parallel debuggers to handle the large amounts of back-end messages in peta-scale environments with better efficiency. The architecture of the \{PTP\} debugger is extended to support SPDL. The extended architecture combines the advantages of the \{PTP\} debugger at the front-end and \{SPDL\} at the back-end. It improves the scalability and performance of the \{PTP\} debugger. Consequently, it provides a flexible option of utilizing the \{PTP\} debugger with pluggable communication protocols to address the debugging challenges in peta-scale environments. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2013.05.346},
  ISSN                     = {1877-0509},
  Keywords                 = {Parallel debugging},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050913004894}
}

@Article{Jin2011562,
  Title                    = {High performance computing using \{MPI\} and OpenMP on multi-core parallel systems },
  Author                   = {Haoqiang Jin and Dennis Jespersen and Piyush Mehrotra and Rupak Biswas and Lei Huang and Barbara Chapman},
  Journal                  = {Parallel Computing },
  Year                     = {2011},
  Note                     = {Emerging Programming Paradigms for Large-Scale Scientific Computing },
  Number                   = {9},
  Pages                    = {562 - 575},
  Volume                   = {37},

  Abstract                 = {The rapidly increasing number of cores in modern microprocessors is pushing the current high performance computing (HPC) systems into the petascale and exascale era. The hybrid nature of these systems – distributed memory across nodes and shared memory with non-uniform memory access within each node – poses a challenge to application developers. In this paper, we study a hybrid approach to programming such systems – a combination of two traditional programming models, \{MPI\} and OpenMP. We present the performance of standard benchmarks from the multi-zone \{NAS\} Parallel Benchmarks and two full applications using this approach on several multi-core based systems including an \{SGI\} Altix 4700, an \{IBM\} p575+ and an \{SGI\} Altix \{ICE\} 8200EX. We also present new data locality extensions to OpenMP to better match the hierarchical memory structure of multi-core architectures. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2011.02.002},
  ISSN                     = {0167-8191},
  Keywords                 = {Hybrid \{MPI\} + OpenMP programming},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819111000159}
}

@Article{Jin20131808,
  Title                    = {Performance comparison under failures of \{MPI\} and MapReduce: An analytical approach },
  Author                   = {Hui Jin and Xian-He Sun},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2013},
  Note                     = {Including Special sections: Cyber-enabled Distributed Computing for Ubiquitous Cloud and Network Services \&amp; Cloud Computing and Scientific Applications — Big Data, Scalable Analytics, and Beyond },
  Number                   = {7},
  Pages                    = {1808 - 1815},
  Volume                   = {29},

  Abstract                 = {Abstract \{MPI\} has been the de facto standard of parallel programming for decades. There has been an increasing concern about the reliability of \{MPI\} applications in recent years, partially due to the inefficiency of parallel checkpointing. MapReduce is a new programming model originally introduced to handle massive data processing. There are numerous efforts recently that transform classical \{MPI\} based scientific applications to MapReduce, due to the merits of easy programming, automatic parallelism, and fault tolerance of MapReduce. However, the stricter synchronization primitive supported by MapReduce also imposes considerable overhead. While the failure-free performance comparison between \{MPI\} and MapReduce has been investigated, there exists little work in comparing the two programming models under failures. In this paper, we propose an analytical approach to quantifying the capabilities of the two programming models to tolerate failures for a comparison. We also carry out extensive numerical analysis to study the impact of different parameters on fault tolerance. This work can be used by the \{HPC\} community for various purposes in making critical decisions. For example, it helps algorithm designers to answer the question such as, at which scale should we give up \{MPI\} and use MapReduce as the programming model for a better performance under the presence of failures? },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2013.01.013},
  ISSN                     = {0167-739X},
  Keywords                 = {Fault tolerance},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X13000290}
}

@Article{Josey2016715,
  Title                    = {Windowed multipole for cross section Doppler broadening },
  Author                   = {C. Josey and P. Ducru and B. Forget and K. Smith},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2016},
  Pages                    = {715 - 727},
  Volume                   = {307},

  Abstract                 = {Abstract This paper presents an in-depth analysis on the accuracy and performance of the windowed multipole Doppler broadening method. The basic theory behind cross section data is described, along with the basic multipole formalism followed by the approximations leading to windowed multipole method and the algorithm used to efficiently evaluate Doppler broadened cross sections. The method is tested by simulating the \{BEAVRS\} benchmark with a windowed multipole library composed of 70 nuclides. Accuracy of the method is demonstrated on a single assembly case where total neutron production rates and U 238 capture rates compare within 0.1% to \{ACE\} format files at the same temperature. With regards to performance, clock cycle counts and cache misses were measured for single temperature \{ACE\} table lookup and for windowed multipole. The windowed multipole method was found to require 39.6% more clock cycles to evaluate, translating to a 7.9% performance loss overall. However, the algorithm has significantly better last-level cache performance, with 3 fewer misses per evaluation, or a 65% reduction in last-level misses. This is due to the small memory footprint of the windowed multipole method and better memory access pattern of the algorithm. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2015.08.013},
  ISSN                     = {0021-9991},
  Keywords                 = {Monte Carlo},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S002199911500532X}
}

@Article{Joshi2011200,
  Title                    = {Multiscale simulation of microbe structure and dynamics },
  Author                   = {Harshad Joshi and Abhishek Singharoy and Yuriy V. Sereda and Srinath C. Cheluvaraja and Peter J. Ortoleva},
  Journal                  = {Progress in Biophysics and Molecular Biology },
  Year                     = {2011},
  Note                     = {Experimental and Computational Model Interactions in Bio-Research: State of the Art },
  Number                   = {1},
  Pages                    = {200 - 217},
  Volume                   = {107},

  Abstract                 = {A multiscale mathematical and computational approach is developed that captures the hierarchical organization of a microbe. It is found that a natural perspective for understanding a microbe is in terms of a hierarchy of variables at various levels of resolution. This hierarchy starts with the N -atom description and terminates with order parameters characterizing a whole microbe. This conceptual framework is used to guide the analysis of the Liouville equation for the probability density of the positions and momenta of the N atoms constituting the microbe and its environment. Using multiscale mathematical techniques, we derive equations for the co-evolution of the order parameters and the probability density of the N-atom state. This approach yields a rigorous way to transfer information between variables on different space-time scales. It elucidates the interplay between equilibrium and far-from-equilibrium processes underlying microbial behavior. It also provides framework for using coarse-grained nanocharacterization data to guide microbial simulation. It enables a methodical search for free-energy minimizing structures, many of which are typically supported by the set of macromolecules and membranes constituting a given microbe. This suite of capabilities provides a natural framework for arriving at a fundamental understanding of microbial behavior, the analysis of nanocharacterization data, and the computer-aided design of nanostructures for biotechnical and medical purposes. Selected features of the methodology are demonstrated using our multiscale bionanosystem simulator DeductiveMultiscaleSimulator. Systems used to demonstrate the approach are structural transitions in the cowpea chlorotic mosaic virus, \{RNA\} of satellite tobacco mosaic virus, virus-like particles related to human papillomavirus, and iron-binding protein lactoferrin. },
  Doi                      = {http://dx.doi.org/10.1016/j.pbiomolbio.2011.07.006},
  ISSN                     = {0079-6107},
  Keywords                 = {Microbial systems},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0079610711000691}
}

@Article{Joubert2015123,
  Title                    = {Accelerated application development: The \{ORNL\} Titan experience },
  Author                   = {Wayne Joubert and Rick Archibald and Mark Berrill and W. Michael Brown and Markus Eisenbach and Ray Grout and Jeff Larkin and John Levesque and Bronson Messer and Matt Norman and Bobby Philip and Ramanan Sankaran and Arnold Tharrington and John Turner},
  Journal                  = {Computers \& Electrical Engineering },
  Year                     = {2015},
  Pages                    = {123 - 138},
  Volume                   = {46},

  Abstract                 = {Abstract The use of computational accelerators such as \{NVIDIA\} \{GPUs\} and Intel Xeon Phi processors is now widespread in the high performance computing community, with many applications delivering impressive performance gains. However, programming these systems for high performance, performance portability and software maintainability has been a challenge. In this paper we discuss experiences porting applications to the Titan system. Titan, which began planning in 2009 and was deployed for general use in 2013, was the first multi-petaflop system based on accelerator hardware. To ready applications for accelerated computing, a preparedness effort was undertaken prior to delivery of Titan. In this paper we report experiences and lessons learned from this process and describe how users are currently making use of computational accelerators on Titan. },
  Doi                      = {http://dx.doi.org/10.1016/j.compeleceng.2015.04.008},
  ISSN                     = {0045-7906},
  Keywords                 = {High performance computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045790615001366}
}

@Article{Kageyama201479,
  Title                    = {An approach to exascale visualization: Interactive viewing of in-situ visualization },
  Author                   = {Akira Kageyama and Tomoki Yamada},
  Journal                  = {Computer Physics Communications },
  Year                     = {2014},
  Number                   = {1},
  Pages                    = {79 - 85},
  Volume                   = {185},

  Abstract                 = {Abstract In the coming era of exascale supercomputing, in-situ visualization will be a crucial approach for reducing the output data size. A problem of in-situ visualization is that it loses interactivity if a steering method is not adopted. In this paper, we propose a new method for the interactive analysis of in-situ visualization images produced by a batch simulation job. A key idea is to apply numerous (thousands to millions) in-situ visualizations simultaneously. The viewer then analyzes the image database interactively during postprocessing. If each movie can be compressed to 100 MB, one million movies will only require 100 TB, which is smaller than the size of the raw numerical data in exascale supercomputing. We performed a feasibility study using the proposed method. Multiple movie files were produced by a simulation and they were analyzed using a specially designed movie player. The user could change the viewing angle, the visualization method, and the parameters interactively by retrieving an appropriate sequence of images from the movie dataset. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2013.08.017},
  ISSN                     = {0010-4655},
  Keywords                 = {In-situ visualization },
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465513002804}
}

@Article{Kalinnik20142722,
  Title                    = {Online auto-tuning for the time-step-based parallel solution of \{ODEs\} on shared-memory systems },
  Author                   = {Natalia Kalinnik and Matthias Korch and Thomas Rauber},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2014},
  Number                   = {8},
  Pages                    = {2722 - 2744},
  Volume                   = {74},

  Abstract                 = {Abstract This article considers automatic performance tuning of time-step-based parallel solution methods for initial value problems (IVPs) of systems of ordinary differential equations (ODEs). We apply auto-tuning to the parallel execution of a class of explicit predictor–corrector (PC) methods of Runge–Kutta (RK) type on shared-memory architectures. The performance of parallel multi-threaded implementation variants of these methods depends on various factors only known at runtime, for example, the coupling structure of the \{ODE\} system to be solved, the memory access pattern resulting from this coupling structure, and the number of threads executing the program. We propose an online auto-tuning approach that exploits the time-stepping nature of \{ODE\} methods by selecting the best parallel implementation variant from a set of candidate implementations at runtime during the first time steps. Thus, the auto-tuning process is not isolated from the computation, but rather contributes to the progress of the solution process. The search space of candidate implementations is a priori reduced by estimating the synchronization overhead of each implementation variant. For implementation variants containing tiled loops, suitable tile sizes are selected using a heuristic empirical search guided by an analytical model. Runtime experiments with two different test problems show the efficiency of the online auto-tuning approach on two different shared-memory systems equipped with 48 and 1040 cores. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2014.03.006},
  ISSN                     = {0743-7315},
  Keywords                 = {Auto-tuning},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731514000628}
}

@Article{Kambatla20142561,
  Title                    = {Trends in big data analytics },
  Author                   = {Karthik Kambatla and Giorgos Kollias and Vipin Kumar and Ananth Grama},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2014},
  Note                     = {Special Issue on Perspectives on Parallel and Distributed Processing },
  Number                   = {7},
  Pages                    = {2561 - 2573},
  Volume                   = {74},

  Abstract                 = {Abstract One of the major applications of future generation parallel and distributed systems is in big-data analytics. Data repositories for such applications currently exceed exabytes and are rapidly increasing in size. Beyond their sheer magnitude, these datasets and associated applications’ considerations pose significant challenges for method and software development. Datasets are often distributed and their size and privacy considerations warrant distributed techniques. Data often resides on platforms with widely varying computational and network capabilities. Considerations of fault-tolerance, security, and access control are critical in many applications (Dean and Ghemawat, 2004; Apache hadoop). Analysis tasks often have hard deadlines, and data quality is a major concern in yet other applications. For most emerging applications, data-driven models and methods, capable of operating at scale, are as-yet unknown. Even when known methods can be scaled, validation of results is a major issue. Characteristics of hardware platforms and the software stack fundamentally impact data analytics. In this article, we provide an overview of the state-of-the-art and focus on emerging trends to highlight the hardware, software, and application landscape of big-data analytics. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2014.01.003},
  ISSN                     = {0743-7315},
  Keywords                 = {Big-data},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731514000057}
}

@Article{KatesHarbeck2016231,
  Title                    = {Simplex-in-cell technique for collisionless plasma simulations },
  Author                   = {Julian Kates-Harbeck and Samuel Totorica and Jonathan Zrake and Tom Abel},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2016},
  Pages                    = {231 - 251},
  Volume                   = {304},

  Abstract                 = {Abstract We extend the simplex-in-cell (SIC) technique recently introduced in the context of collisionless dark matter fluids [1,2] to the case of collisionless plasmas. The six-dimensional phase space distribution function f ( x , v ) is represented by an ensemble of three-dimensional manifolds, which we refer to as sheets. The electric potential field is obtained by solving the Poisson equation on a uniform mesh, where the charge density is evaluated by a spatial projection of the phase space sheets. The \{SIC\} representation of phase space density facilitates robust, high accuracy numerical evolution of the Vlasov–Poisson system using significantly fewer tracer particles than comparable particle-in-cell (PIC) approaches by reducing the numerical shot-noise associated with the latter. We introduce the \{SIC\} formulation and describe its implementation in a new code, which we validate using standard test problems including plasma oscillations, Landau damping, and two stream instabilities in one dimension. Merits of the new scheme are shown to include higher accuracy and faster convergence rates in the number of particles. We finally motivate and outline the efficient application of \{SIC\} to higher dimensional problems. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2015.10.017},
  ISSN                     = {0021-9991},
  Keywords                 = {Vlasov equation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999115006816}
}

@Article{Kelly20127988,
  Title                    = {Continuous and discontinuous Galerkin methods for a scalable three-dimensional nonhydrostatic atmospheric model: Limited-area mode },
  Author                   = {James F. Kelly and Francis X. Giraldo},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2012},
  Number                   = {24},
  Pages                    = {7988 - 8008},
  Volume                   = {231},

  Abstract                 = {This paper describes a unified, element based Galerkin (EBG) framework for a three-dimensional, nonhydrostatic model for the atmosphere. In general, \{EBG\} methods possess high-order accuracy, geometric flexibility, excellent dispersion properties and good scalability. Our nonhydrostatic model, based on the compressible Euler equations, is appropriate for both limited-area and global atmospheric simulations. Both a continuous Galerkin (CG), or spectral element, and discontinuous Galerkin (DG) model are considered using hexahedral elements. The formulation is suitable for both global and limited-area atmospheric modeling, although we restrict our attention to 3D limited-area phenomena in this study; global atmospheric simulations will be presented in a follow-up paper. Domain decomposition and communication algorithms used by both our \{CG\} and \{DG\} models are presented. The communication volume and exchange algorithms for \{CG\} and \{DG\} are compared and contrasted. Numerical verification of the model was performed using two test cases: flow past a 3D mountain and buoyant convection of a bubble in a neutral atmosphere; these tests indicate that both \{CG\} and \{DG\} can simulate the necessary physics of dry atmospheric dynamics. Scalability of both methods is shown up to 8192 \{CPU\} cores, with near ideal scaling for \{DG\} up to 32,768 cores. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2012.04.042},
  ISSN                     = {0021-9991},
  Keywords                 = {Compressible flow},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999112002252}
}

@Article{Kerbyson2014291,
  Title                    = {A performance comparison of current \{HPC\} systems: Blue Gene/Q, Cray \{XE6\} and InfiniBand systems },
  Author                   = {Darren J. Kerbyson and Kevin J. Barker and Abhinav Vishnu and Adolfy Hoisie},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2014},
  Note                     = {Special Issue on Extreme Scale Parallel Architectures and Systems, Cryptography in Cloud Computing and Recent Advances in Parallel and Distributed Systems, \{ICPADS\} 2012 Selected Papers },
  Pages                    = {291 - 304},
  Volume                   = {30},

  Abstract                 = {Abstract We present here a performance analysis of three of current architectures that have become commonplace in the High Performance Computing world. Blue Gene/Q is the third generation of systems from \{IBM\} that use modestly performing cores but at large-scale in order to achieve high performance. The \{XE6\} is the latest in a long line of Cray systems that use a 3-D topology but the first to use its Gemini interconnection network. InfiniBand provides the flexibility of using compute nodes from many vendors that can be connected in many possible topologies. The performance characteristics of each vary vastly, and the way in which nodes are allocated in each type of system can significantly impact on achieved performance. In this work we compare these three systems using a combination of micro-benchmarks and a set of production applications. In addition we also examine the differences in performance variability observed on each system and quantify the lost performance using a combination of both empirical measurements and performance models. Our results show that significant performance can be lost in normal production operation of the Cray \{XE6\} and InfiniBand Clusters in comparison to Blue Gene/Q. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2013.06.019},
  ISSN                     = {0167-739X},
  Keywords                 = {High performance computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X13001337}
}

@Article{Keyes2011,
  Title                    = {Exaflop/s: The why and the how },
  Author                   = {David E. Keyes},
  Journal                  = {Comptes Rendus Mécanique },
  Year                     = {2011},
  Note                     = {High Performance ComputingLe Calcul Intensif },
  Number                   = {2–3},
  Pages                    = {70 - 77},
  Volume                   = {339},

  Abstract                 = {The best paths to the exascale summit are debatable, but all are narrow and treacherous, constrained by fundamental laws of physics, capital cost, operating cost, power requirements, programmability, and reliability. Many scientific and engineering applications force the modeling community to attempt to scale this summit. Drawing on vendor projections and experiences with scientific codes on contemporary platforms, we outline the challenges and propose roles and essential adaptations for mathematical modelers in one of the great global scientific quests the next decade. },
  Doi                      = {http://dx.doi.org/10.1016/j.crme.2010.11.002},
  ISSN                     = {1631-0721},
  Keywords                 = {Computer science},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1631072110002032}
}

@InCollection{Khalatur2012417,
  Title                    = {1.16 - Molecular Dynamics Simulations in Polymer Science: Methods and Main Results },
  Author                   = {P.G. Khalatur},
  Booktitle                = {Polymer Science: A Comprehensive Reference },
  Publisher                = {Elsevier},
  Year                     = {2012},

  Address                  = {Amsterdam},
  Editor                   = {Möller, Krzysztof MatyjaszewskiMartin },
  Pages                    = {417 - 460},

  Abstract                 = {Abstract This chapter surveys the dynamic simulation methods for polymers, from ab initio molecular dynamics (MD) to the coarse-grained and continuum-level descriptions, passing through the atomistic \{MD\} simulations, both nonreactive and reactive. For different scales in the space and time domains, we review the simulation techniques and tools, as well as discuss important recent contributions. The focus is on the issue of how to coherently combine the different computational strategies to address the problem of hierarchical multiscale modeling. The limitations of various methods for computing polymer dynamics are discussed in terms of the physical limits of the specific theory and generally of what can reasonably be computed. We also discuss several directions in which future research in this field may proceed. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-444-53349-4.00016-9},
  ISBN                     = {978-0-08-087862-1},
  Keywords                 = {Coarse-graining},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780444533494000169}
}

@Article{Khanjari2015403,
  Title                    = {The Impact of Traffic Localisation on the Performance of NoCs for Very Large Manycore Systems },
  Author                   = {Sharifa Al Khanjari and Wim Vanderbauwhede},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {The 10th International Conference on Future Networks and Communications (FNC 2015) / The 12th International Conference on Mobile Systems and Pervasive Computing (MobiSPC 2015) Affiliated Workshops },
  Pages                    = {403 - 408},
  Volume                   = {56},

  Abstract                 = {Abstract The scaling of semiconductor technologies is leading to processors with increasing numbers of cores. The adoption of Networks-on-Chip (NoC) in manycore systems requires a shift in focus from computation to communication, as communication is fast becoming the dominant factor in processor performance. In large manycore systems, performance is predicated on the locality of communication. In this work, we investigate the performance of three NoC topologies for systems with thousands of processor cores under two types of localised traffic. We present latency and throughput results comparing fat quadtree, concentrated mesh and mesh topologies under different degrees of localisation. Our results, based on the \{ITRS\} physical data for 2023, show that the type and degree of localisation of traffic significantly affects the NoC performance, and that scale-invariant topologies perform worse than flat topologies. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.07.227},
  ISSN                     = {1877-0509},
  Keywords                 = {Manycore},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915017081}
}

@Article{Khunjush2009430,
  Title                    = {Hiding message delivery latency using Direct-to-Cache-Transfer techniques in message passing environments },
  Author                   = {Farshad Khunjush and Nikitas J. Dimopoulos},
  Journal                  = {Microprocessors and Microsystems },
  Year                     = {2009},
  Number                   = {7–8},
  Pages                    = {430 - 440},
  Volume                   = {33},

  Abstract                 = {Communication overhead is the key obstacle to reaching hardware performance limits. The majority is associated with software overhead, a significant portion of which is attributed to message copying. To reduce this copying overhead, we have devised techniques that do not require to copy a received message in order for it to be bound to its final destination. Rather, a late-binding mechanism, which involves address translation and a dedicated cache, facilitates fast access to received messages by the consuming process/thread. We have introduced two policies namely Direct to Cache Transfer (DTCT) and lazy \{DTCT\} that determine whether a message after it is bound needs to be transferred into the data cache. We have studied the proposed methods in simulation and have shown their effectiveness in reducing access times to message payloads by the consuming process. },
  Doi                      = {http://dx.doi.org/10.1016/j.micpro.2009.07.001},
  ISSN                     = {0141-9331},
  Keywords                 = {Message Passing Interface (MPI)},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0141933109000647}
}

@InCollection{Kidd2015487,
  Title                    = {Chapter 25 - Power Analysis for Applications and Data Centers },
  Author                   = {Taylor Kidd and Rob Farber and Belinda Liviero and Evan Felix},
  Booktitle                = {High Performance Parallelism Pearls },
  Publisher                = {Morgan Kaufmann},
  Year                     = {2015},

  Address                  = {Boston},
  Editor                   = {Reinders, James and Jeffers, Jim },
  Pages                    = {487 - 510},

  Abstract                 = {Abstract This chapter discusses two methods that can potentially save megawatts of power on leadership class systems and provide significant reductions in power consumption on small clusters over the long term. The chapter first examines how a developer can make simple nonalgorithmic application changes, such as thread distribution, in concert with power measurements, which can significantly change the application’s performance per watt. The chapter also takes a look at how administrators and developers can use big data techniques like waterfall plots to examine profiling information across cluster environments, and their potential impact on data center performance. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-803819-2.00014-8},
  ISBN                     = {978-0-12-803819-2},
  Keywords                 = {Power},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780128038192000148}
}

@Article{Kim2011312,
  Title                    = {Toward Malleable Model Coupling },
  Author                   = {Daihee Kim and J. Walter Larson and Kenneth Chiu},
  Journal                  = {Procedia Computer Science },
  Year                     = {2011},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2011 },
  Pages                    = {312 - 321},
  Volume                   = {4},

  Abstract                 = {Model coupling is a method to simulate complex multiphysics and multiscale phenomena. Most approaches involve static data distribution among processes without the consideration of top-level dynamic load balancing. Malleability, the ability to change the number of processes during execution, allows applications to configure themselves to better utilize available system resources. To date, however, malleability has been applied primarily to monolithic applications. We have extended the Model Coupling Toolkit (MCT) to support processing element malleability for coupled models, resulting in the Malleable Model Coupling Toolkit (MMCT). \{MMCT\} consists of a load balance manager (LBM) implementing a practical dynamic load-balancing algorithm and a malleable model registry that allows management of dynamically evolving \{MPI\} communicators. \{MMCT\} requires only standard MPI-2, sockets, and MCT. We benchmark \{MMCT\} using a synthetic, simplified coupled model application similar to the Community Climate System Model. Preliminary performance data demonstrate the efficacy of the \{LBM\} and a low (≈3%) monitoring overhead. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2011.04.033},
  ISSN                     = {1877-0509},
  Keywords                 = {MPI},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050911000913}
}

@Article{Kluge2013230,
  Title                    = {Performance and quality of service of data and video movement over a 100 Gbps testbed },
  Author                   = {Michael Kluge and Stephen Simms and Thomas William and Robert Henschel and Andy Georgi and Christian Meyer and Matthias S. Mueller and Craig A. Stewart and Wolfgang Wünsch and Wolfgang E. Nagel},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2013},
  Note                     = {Including Special section: AIRCC-NetCoM 2009 and Special section: Clouds and Service-Oriented Architectures },
  Number                   = {1},
  Pages                    = {230 - 240},
  Volume                   = {29},

  Abstract                 = {Digital instruments and simulations are creating an ever-increasing amount of data. The need for institutions to acquire these data and transfer them for analysis, visualization, and archiving is growing as well. In parallel, networking technology is evolving, but at a much slower rate than our ability to create and store data. Single fiber 100 Gbps networking solutions have recently been deployed as national infrastructure. This article describes our experiences with data movement and video conferencing across a networking testbed, using the first commercially available single fiber 100 Gbps technology. The testbed is unique in its ability to be configured for a total length of 60, 200, or 400 km, allowing for tests with varying network latency. We performed low-level \{TCP\} tests and were able to use more than 99.9% of the theoretical available bandwidth with minimal tuning efforts. We used the Lustre file system to simulate how end users would interact with a remote file system over such a high performance link. We were able to use 94.4% of the theoretical available bandwidth with a standard file system benchmark, essentially saturating the wide area network. Finally, we performed tests with H.323 video conferencing hardware and quality of service (QoS) settings, showing that the link can reliably carry a full high-definition stream. Overall, we demonstrated the practicality of 100 Gbps networking and Lustre as excellent tools for data management. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2012.05.028},
  ISSN                     = {0167-739X},
  Keywords                 = {High performance computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X12001380}
}

@InCollection{Knobloch20131,
  Title                    = {Chapter 1 - Energy-Aware High Performance Computing—A Survey },
  Author                   = {Michael Knobloch},
  Booktitle                = {Green and Sustainable Computing: Part II},
  Publisher                = {Elsevier},
  Year                     = {2013},
  Editor                   = {Ali Hurson},
  Pages                    = {1 - 78},
  Series                   = {Advances in Computers },
  Volume                   = {88},

  Abstract                 = {Power consumption of hardware and energy-efficiency of software have become major topics in High Performance Computing in the last couple of years. To reach the goal of 20 \{MW\} for an Exascale system, a holistic approach is needed—the efficiency of the data center itself, the hardware components, and the software have to be taken into account and optimized. We present the current state of hardware power management and sketch the next generation of hardware components. Furthermore, special \{HPC\} architectures with a strong focus on energy-efficiency are presented. Software efficiency is essential on all levels from cluster management over system software to the applications running on the system. Solutions to increase the efficiency are presented on all that levels, we discuss vendor tools for cluster management, tools and run-time systems to increase the efficiency of parallel applications, and show algorithmic improvements. Finally we present the eeClust project, a project that aims to reduce the energy consumption of \{HPC\} clusters by an integrated approach of application analysis, hardware management, and monitoring. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-407725-6.00001-0},
  ISSN                     = {0065-2458},
  Keywords                 = {Power},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780124077256000010}
}

@Article{Kodama2014362,
  Title                    = {Scalable rank-mapping algorithm for an icosahedral grid system on the massive parallel computer with a 3-D torus network },
  Author                   = {Chihiro Kodama and Masaaki Terai and Akira T. Noda and Yohei Yamada and Masaki Satoh and Tatsuya Seiki and Shin-ichi Iga and Hisashi Yashiro and Hirofumi Tomita and Kazuo Minami},
  Journal                  = {Parallel Computing },
  Year                     = {2014},
  Number                   = {8},
  Pages                    = {362 - 373},
  Volume                   = {40},

  Abstract                 = {Abstract In this paper, we develop a rank-mapping algorithm for an icosahedral grid system on a massive parallel computer with the 3-D torus network topology, specifically on the K computer. Our aim is to improve the weak scaling performance of the point-to-point communications for exchanging grid-point values between adjacent grid regions on a sphere. We formulate a new rank-mapping algorithm to reduce the maximum number of hops for the point-to-point communications. We evaluate both the new algorithm and the standard ones on the K computer, using the communication kernel of the Nonhydrostatic Icosahedral Atmospheric Model (NICAM), a global atmospheric model with an icosahedral grid system. We confirm that, unlike the standard algorithms, the new one achieves almost perfect performance in the weak scaling on the K computer, even for 10,240 nodes. Results of additional experiments imply that the high scalability of the new rank-mapping algorithm on the K computer is achieved by reducing network congestion in the links between adjacent nodes. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2014.06.002},
  ISSN                     = {0167-8191},
  Keywords                 = {MPI},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819114000659}
}

@Article{Kong2011,
  Title                    = {Particle-in-cell simulations with charge-conserving current deposition on graphic processing units },
  Author                   = {Xianglong Kong and Michael C. Huang and Chuang Ren and Viktor K. Decyk},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2011},
  Number                   = {4},
  Pages                    = {1676 - 1685},
  Volume                   = {230},

  Abstract                 = {We present an implementation of a 2D fully relativistic, electromagnetic particle-in-cell code, with charge-conserving current deposition, on parallel graphics processors (GPU) with CUDA. The \{GPU\} implementation achieved a one particle-step process time of 2.52 ns for cold plasma runs and 9.15 ns for extremely relativistic plasma runs, which are respectively 81 and 27 times faster than a single threaded state-of-art \{CPU\} code. A particle-based computation thread assignment was used in the current deposition scheme and write conflicts among the threads were resolved by a thread racing technique. A parallel particle sorting scheme was also developed and used. The implementation took advantage of fast on-chip shared memory, and can in principle be extended to 3D. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2010.11.032},
  ISSN                     = {0021-9991},
  Keywords                 = {Graphics processing unit (GPU)},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999110006479}
}

@Article{Kopta2011372,
  Title                    = {Parallel application benchmarks and performance evaluation of the Intel Xeon 7500 family processors },
  Author                   = {Piotr Kopta and Michal Kulczewski and Krzysztof Kurowski and Tomasz Piontek and Pawel Gepner and Mariusz Puchalski and Jacek Komasa},
  Journal                  = {Procedia Computer Science },
  Year                     = {2011},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2011 },
  Pages                    = {372 - 381},
  Volume                   = {4},

  Abstract                 = {With the recent advent of novel multi- and many-core hardware architectures, application programmers have to deal with many hardware-specific implementation details and have to be familiar with software optimization techniques to benefit from new high-performance computing machines. Highly effcient parallel application design is in fact an interdisciplinary process involving domain specific and \{IT\} experts. Therefore, this paper aims to present early experiences with computationally demanding applications, development efforts and evaluation of their performance on the new family of Intel Xeon 7500 processors. We selected two application benchmarks applicable to real quantum chemistry and Computational Fluid Dynamics (CFD) problems as they can potentially take advantage of parallel processing on novel hardware architectures and built-in new features. Additionally, we discuss various parallel software improvements to mentioned applications, including appropriate changes to data structures as well as to communication and synchronization routines to deal with multi-level parallelism and hybrid hardware architectures. The obtained results confirmed that new hardware solutions can improve the overall application performance. However, in order to obtain a high level of parallel scalability various application modifications and tuning procedures are required as hardware configurations, including processors characteristics, interconnects and topologies, and they have a great influence on large-scale simulations. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2011.04.039},
  ISSN                     = {1877-0509},
  Keywords                 = {Intel Xeon 7500},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050911000974}
}

@Article{Kordilla20131,
  Title                    = {A smoothed particle hydrodynamics model for droplet and film flow on smooth and rough fracture surfaces },
  Author                   = {J. Kordilla and A.M. Tartakovsky and T. Geyer},
  Journal                  = {Advances in Water Resources },
  Year                     = {2013},
  Pages                    = {1 - 14},
  Volume                   = {59},

  Abstract                 = {Abstract Flow on fracture surfaces has been identified by many authors as an important flow process in unsaturated fractured rock formations. Given the complexity of flow dynamics on such small scales, robust numerical methods have to be employed in order to capture the highly dynamic interfaces and flow intermittency. In this work we use a three-dimensional multiphase Smoothed Particle Hydrodynamics (SPH) model to simulate surface tension dominated flow on smooth fracture surfaces. We model droplet and film flow over a wide range of contact angles and Reynolds numbers encountered in such flows on rock surfaces. We validate our model via comparison with existing empirical and semi-analytical solutions for droplet flow. We use the \{SPH\} model to investigate the occurrence of adsorbed trailing films left behind droplets under various flow conditions and its importance for the flow dynamics when films and droplets coexist. It is shown that flow velocities are higher on prewetted surfaces covered by a thin film which is qualitatively attributed to the enhanced dynamic wetting and dewetting at the trailing and advancing contact lines. Finally, we demonstrate that the \{SPH\} model can be used to study flow on rough surfaces. },
  Doi                      = {http://dx.doi.org/10.1016/j.advwatres.2013.04.009},
  ISSN                     = {0309-1708},
  Keywords                 = {Unsaturated flow},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0309170813000729}
}

@Article{Kotov2016189,
  Title                    = {Numerical dissipation control in high order shock-capturing schemes for \{LES\} of low speed flows },
  Author                   = {D.V. Kotov and H.C. Yee and A.A. Wray and B. Sjögreen and A.G. Kritsuk},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2016},
  Pages                    = {189 - 202},
  Volume                   = {307},

  Abstract                 = {Abstract The Yee &amp; Sjögreen adaptive numerical dissipation control in high order scheme (High Order Filter Methods for Wide Range of Compressible Flow Speeds, \{ICOSAHOM\} 09, 2009) is further improved for \{DNS\} and \{LES\} of shock-free turbulence and low speed turbulence with shocklets. There are vastly different requirements in the minimization of numerical dissipation for accurate turbulence simulations of different compressible flow types and flow speeds. Traditionally, the method of choice for shock-free turbulence and low speed turbulence are by spectral, high order central or high order compact schemes with high order linear filters. With a proper control of a local flow sensor, appropriate amount of numerical dissipation in high order shock-capturing schemes can have spectral-like accuracy for compressible low speed turbulent flows. The development of the method includes an adaptive flow sensor with automatic selection on the amount of numerical dissipation needed at each flow location for more accurate \{DNS\} and \{LES\} simulations with less tuning of parameters for flows with a wide range of flow speed regime during the time-accurate evolution, e.g., time varying random forcing. An automatic selection of the different flow sensors catered to the different flow types is constructed. A Mach curve and high-frequency oscillation indicators are used to reduce the tuning of parameters in controlling the amount of shock-capturing numerical dissipation to be employed for shock-free turbulence, low speed turbulence and turbulence with strong shocks. In Kotov et al. (High Order Numerical Methods for \{LES\} of Turbulent Flows with Shocks, ICCFD8, Chengdu, Sichuan, China, July 14–18, 2014) the \{LES\} of a turbulent flow with a strong shock by the Yee &amp; Sjögreen scheme indicated a good agreement with the filtered \{DNS\} data. A work in progress for the application of the adaptive flow sensor for compressible turbulence with time-varying random forcing is forthcoming. The present study examines the versatility of the Yee &amp; Sjögreen scheme for \{DNS\} and \{LES\} of traditional low speed flows without forcing. Special attention is focused on the accuracy performance of this scheme using the Smagorinsky and the Germano–Lilly \{SGS\} models. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2015.11.029},
  ISSN                     = {0021-9991},
  Keywords                 = {DNS},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S002199911500769X}
}

@Article{Krause2016164,
  Title                    = {Enabling local time stepping in the parallel implicit solution of reaction–diffusion equations via space-time finite elements on shallow tree meshes },
  Author                   = {D. Krause and R. Krause},
  Journal                  = {Applied Mathematics and Computation },
  Year                     = {2016},
  Pages                    = {164 - 179},
  Volume                   = {277},

  Abstract                 = {Abstract For many applications, local time stepping offers an interesting and worthwhile alternative to the by now well established global time step control. In fact, local time stepping can allow for a highly detailed resolution of localized features of the solution with strongly reduced computational cost, when compared to global time step control. However local time stepping is not applicable in a straight-forward manner in the context of fully implicit time-discretizations. Here, we present a method for the efficient parallel adaptive solution of (non-linear) partial differential equations, in particular reaction–diffusion equations, using spatially adapted time step sizes in the context of a fully implicit solution strategy. Our proposed method uses a discontinuous Galerkin method in-time approach within a full space-time approach. Moreover, it is designed from scratch for efficient parallel computation. We employ shallow tree-based mesh data structures in order to ensure a low memory footprint of the adaptive meshes. By solving the time-dependent partial differential equation on a ( d + 1 ) -dimensional non-conforming mesh, space-time adaptivity is naturally achieved. In combination with a discontinuous Galerkin method in-time the size of the arising systems can be precisely controlled. We additionally introduce and discuss a stabilization scheme for space-time mortar element methods that also has a highly positive impact on the efficiency of preconditioning techniques for the arising systems of equations. We present results from extensive numerical experiments that address the question of convergence and efficiency, linear and non-linear solver performance, parallel scalability up to 2048 cores as well as accuracy for the linear heat equation and a real world, non-linear reaction–diffusion equation from the field of computational electrocardiology. },
  Doi                      = {http://dx.doi.org/10.1016/j.amc.2015.12.017},
  ISSN                     = {0096-3003},
  Keywords                 = {Local time stepping},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0096300315300059}
}

@Article{Kulikov201571,
  Title                    = {AstroPhi: A code for complex simulation of the dynamics of astrophysical objects using hybrid supercomputers },
  Author                   = {I.M. Kulikov and I.G. Chernykh and A.V. Snytnikov and B.M. Glinskiy and A.V. Tutukov},
  Journal                  = {Computer Physics Communications },
  Year                     = {2015},
  Pages                    = {71 - 80},
  Volume                   = {186},

  Abstract                 = {Abstract We propose a new code named AstroPhi for simulation of the dynamics of astrophysical objects on hybrid supercomputers equipped with Intel Xenon Phi computation accelerators. The details of parallel implementation are described, as well as changes to the computational algorithm that facilitate efficient parallel implementation. A single Xeon Phi accelerator yielded 27-fold acceleration. The use of 32 Xeon Phi accelerators resulted in 94% parallel efficiency. Several collapse problems are simulated using the AstroPhi code. Program summary Program title: AstroPhi Catalogue identifier: AEUM_v1_0 Program summary URL:http://cpc.cs.qub.ac.uk/summaries/AEUM_v1_0.html Program obtainable from: \{CPC\} Program Library, Queen’s University, Belfast, N. Ireland Licensing provisions: Standard \{CPC\} licence, http://cpc.cs.qub.ac.uk/licence/licence.html No. of lines in distributed program, including test data, etc.: 99604 No. of bytes in distributed program, including test data, etc.: 305433 Distribution format: tar.gz Programming language: C++. Computer: MVS-10P - \{RSC\} Tornado, Xeon E5-2690 8C 2.900 GHz, Infiniband FDR, Intel Xeon Phi SE10X. Operating system: Linux. Has the code been vectorized or parallelized?: Parallelized on MPI + OpenMP for Intel \{MIC\} architecture, 32 Intel Xeon Phi (60 cores per 1 Intel Xeon Phi = 1920 cores of Intel Xeon Phi). RAM: 137438953472 bytes (128 GB) bytes Classification: 1.9. External routines: MPI, OpenMP for Intel Xeon Phi, \{FFTW\} 2.1.5 Nature of problem: Complex numerical simulation of dynamics of astrophysical objects plays an important role due to significant growth of observational astronomic data. The new astrophysical models and codes need to be developed for detailed simulation of different physical effects in astrophysics with the use of modern supercomputers with hybrid architecture. Solution method: AstroPhi code consisting of particle-in-cell and Godunov methods combination adapted for hybrid supercomputer architecture. Restrictions: For this version maximum grid size is restricted to 10243. Running time: Typical running on MVS-10P is 24 h. The test provided only takes a few minutes. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2014.09.004},
  ISSN                     = {0010-4655},
  Keywords                 = {Numerical astrophysics},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465514003099}
}

@Article{Kumar20132251,
  Title                    = {High Performance Solvers for Implicit Particle in Cell Simulation },
  Author                   = {Pawan Kumar and Stefano Markidis and Giovanni Lapenta and Karl Meerbergen and Dirk Roose},
  Journal                  = {Procedia Computer Science },
  Year                     = {2013},
  Note                     = {2013 International Conference on Computational Science },
  Pages                    = {2251 - 2258},
  Volume                   = {18},

  Abstract                 = {Abstract A three-dimensional implicit particle-in-cell (iPIC3D) method implemented by S. Markidis et. al. in [“Multiscale simulations of plasma with iPIC3D”, Mathematics and Computers in Simulation, 80(2010), 1509-1519] allows time steps at magnetohy- drodynamics time scale. The code requires the solution of two linear systems: a Poisson system related to divergence cleaning, and a system related to a second order formulation of Maxwell equation. In iPIC3D, the former is the most costly. To reduce the cost of solving the Poisson system, a parallel matrix assembly and partitioning method are implemented, and conjugate gradient and algebraic multigrid (AMG) solvers from the Hypre library are called. The scalability of \{AMG\} as a solver is studied for 1D and 3D partitionings and compared to that of CG. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2013.05.396},
  ISSN                     = {1877-0509},
  Keywords                 = {Implicit PIC},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050913005395}
}

@Article{Lang20142884,
  Title                    = {An execution time and energy model for an energy-aware execution of a conjugate gradient method with CPU/GPU collaboration },
  Author                   = {Jens Lang and Gudula Rünger},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2014},
  Number                   = {9},
  Pages                    = {2884 - 2897},
  Volume                   = {74},

  Abstract                 = {Abstract The parallel preconditioned conjugate gradient method (CGM) is used in many applications of scientific computing and often has a critical impact on their performance and energy consumption. This article investigates the energy-aware execution of the \{CGM\} on multi-core \{CPUs\} and \{GPUs\} used in an adaptive FEM. Based on experiments, an application-specific execution time and energy model is developed. The model considers the execution speed of the \{CPU\} and the GPU, their electrical power, voltage and frequency scaling, the energy consumption of the memory as well as the time and energy needed for transferring the data between main memory and \{GPU\} memory. The model makes it possible to predict how to distribute the data to the processing units for achieving the most energy efficient execution: the execution might deploy the \{CPU\} only, the \{GPU\} only or both simultaneously using a dynamic and adaptive collaboration scheme. The dynamic collaboration enables an execution minimising the execution time. By measuring execution times for every \{FEM\} iteration, the data distribution is adapted automatically to changing properties, e.g. the data sizes. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2014.06.001},
  ISSN                     = {0743-7315},
  Keywords                 = {Conjugate gradient method},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731514001038}
}

@Article{Lapenta,
  Title                    = {Particle Rezoning for Multidimensional Kinetic Particle-In-Cell Simulations },
  Author                   = {Giovanni Lapenta},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2002},
  Number                   = {1},
  Pages                    = {317 - 337},
  Volume                   = {181},

  Abstract                 = {The adaptation of \{PIC\} methods requires the ability to change the number of particles during the calculation. For \{PIC\} methods it is not sufficient to adapt the computational grid. It also necessary to control the local number of particles per cell (particle rezoning) by increasing or decreasing its value to control the local accuracy. In the present paper, we describe some general theoretical considerations regarding the accuracy of various particle rezoning methods. Four algorithms are derived and applied to 1D and 2D \{PIC\} simulations. The merits and drawbacks of the algorithms are discussed. Particle rezoning is then applied to 1D studies of collisionless shocks and the 2D simulations of charging of dust immersed in a plasma. },
  Doi                      = {http://dx.doi.org/10.1006/jcph.2002.7126},
  ISSN                     = {0021-9991},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999102971263}
}

@Article{Larson2013130,
  Title                    = {Fault-Tolerant Grid-Based Solvers: Combining Concepts from Sparse Grids and MapReduce },
  Author                   = {J.W. Larson and M. Hegland and B. Harding and S. Roberts and L. Stals and A.P. Rendell and P. Strazdins and M.M. Ali and C. Kowitz and R. Nobes and J. Southern and N. Wilson and M. Li and Y. Oishi},
  Journal                  = {Procedia Computer Science },
  Year                     = {2013},
  Note                     = {2013 International Conference on Computational Science },
  Pages                    = {130 - 139},
  Volume                   = {18},

  Abstract                 = {Abstract A key issue confronting petascale and exascale computing is the growth in probability of soft and hard faults with increasing system size. A promising approach to this problem is the use of algorithms that are inherently fault tolerant. We introduce such an algorithm for the solution of partial differential equations, based on the sparse grid approach. Here, the solution of multiple component grids are efficiently combined to achieve a solution on a full grid. The technique also lends itself to a (modified) MapReduce framework on a cluster of processors, with the map stage corresponding to allocating each component grid for solution over a subset of the processors, and the reduce stage corresponding to their combination. We describe how the sparse grid combination method can be modified to robustly solve partial differential equations in the presence of faults. This is based on a modified combination formula that can accommodate the loss of one or two component grids. We also discuss accuracy issues associated with this formula. We give details of a prototype implementation within a MapReduce framework using the dynamic process features and asynchronous message passing facilities of MPI. Results on a two-dimensional advection problem show that the errors after the loss of one or two sub-grids are within a factor of 3 of the sparse grid solution in the presence of no faults. They also indicate that the sparse grid technique with four times the resolution has approximately the same error as a full grid, while requiring (for a sufficiently high resolution) much lower computation and memory requirements. We finally outline a MapReduce variant capable of responding to faults in ways other than re-scheduling of failed tasks. We discuss the likely software requirements for such a flexible MapReduce framework, the requirements it will impose on users’ legacy codes, and the system's runtime behavior. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2013.05.176},
  ISSN                     = {1877-0509},
  Keywords                 = {Parallel computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050913003190}
}

@Article{Larson2012917,
  Title                    = {Visualizing Climate Variability with Time-Dependent Probability Density Functions, Detecting It Using Information Theory },
  Author                   = {J. Walter Larson},
  Journal                  = {Procedia Computer Science },
  Year                     = {2012},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2012 },
  Pages                    = {917 - 926},
  Volume                   = {9},

  Abstract                 = {A framework for visualizing and detecting climate variability and change based on time-dependent probability density functions (PDFs) is developed. A set of information-theoretic statistics based on the Shannon Entropy and the Kullback-Leibler Divergence (KLD) are defined to assess \{PDF\} complexity and temporal variability. The \{KLD\} based measures quantify the representativeness of a thirty year sampling window of a larger climatic record, how well a long sample can predict a smaller sample's PDF, and how well one thirty year sample matches a similar sample shifted in time. These techniques are applied the the Central England Temperature record, the longest continuous meteorological observational record. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2012.04.098},
  ISSN                     = {1877-0509},
  Keywords                 = {Probability Density Function},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050912002190}
}

@Article{Lastovetsky20121397,
  Title                    = {Special issue of Journal of Parallel and Distributed Computing: Heterogeneity in parallel and distributed computing },
  Author                   = {Alexey Lastovetsky},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2012},
  Number                   = {10},
  Pages                    = {1397 - },
  Volume                   = {72},

  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2012.06.002},
  ISSN                     = {0743-7315},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731512001414}
}

@Article{Lawson2015100,
  Title                    = {Changing \{CPU\} Frequency in CoMD Proxy Application Offloaded to Intel Xeon Phi Co-processors },
  Author                   = {Gary Lawson and Masha Sosonkina and Yuzhong Shen},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {100 - 109},
  Volume                   = {51},

  Abstract                 = {Abstract Obtaining exascale performance is a challenge. Although the technology of today features hardware with very high levels of concurrency, exascale performance is primarily limited by energy consumption. This limitation has lead to the use of \{GPUs\} and specialized hardware such as many integrated core (MIC) co-processors and \{FPGAs\} for computation acceleration. The Intel Xeon Phi co-processor, built upon the \{MIC\} architecture, features many low frequency, energy efficient cores. Applications, even those which do not saturate the large vector processing unit in each core, may benefit from the energy-efficient hardware and software of the Xeon Phi. This work explores the energy savings of applications which have not been optimized for the co-processor. Dynamic voltage and frequency scaling (DVFS) is often used to reduce energy consumption during portions of the execution where performance is least likely to be affected. This work investigates the impact on energy and performance when \{DVFS\} is applied to the \{CPU\} during MIC-offloaded sections (i.e., code segments to be processed on the co-processor). Experiments, conducted on the molecular dynamics proxy application CoMD, show that as much as 14% energy may be saved if two Xeon Phi's are used. When \{DVFS\} is applied to the host \{CPU\} frequency, energy savings of as high as 9% are obtained in addition to the 8% saved from reducing link-cell count. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.207},
  ISSN                     = {1877-0509},
  Keywords                 = {Molecular dynamics},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915010157}
}

@Article{Lebensohn20136918,
  Title                    = {Modeling void growth in polycrystalline materials },
  Author                   = {Ricardo A. Lebensohn and Juan P. Escobedo and Ellen K. Cerreta and Darcie Dennis-Koller and Curt A. Bronkhorst and John F. Bingert},
  Journal                  = {Acta Materialia },
  Year                     = {2013},
  Number                   = {18},
  Pages                    = {6918 - 6932},
  Volume                   = {61},

  Abstract                 = {Abstract Most structural materials are polycrystalline aggregates whose constituent crystals are irregular in shape, have anisotropic mechanical properties and contain a variety of defects, resulting in very complicated damage evolution. Failure models of these materials remain empirically calibrated due to the lack of a thorough understanding of the controlling processes at the scale of the materials’ heterogeneity, i.e. the mesoscale. This paper describes a novel formulation for a quantitative, microstructure-sensitive three-dimensional mesoscale prediction of ductile damage of polycrystalline materials, in the important void growth phase of the process. Specifically, we have extended a formulation based on fast Fourier transforms to compute growth of intergranular voids in porous polycrystalline materials. In this way, two widely used micromechanical formulations, i.e. polycrystal plasticity and dilatational plasticity, have been efficiently combined, with crystals and voids represented explicitly, to predict porosity evolution. The proposed void growth algorithm is first validated by comparison with corresponding finite-element unit cell results. Next, in order to isolate the influence of microstructure on void growth, the extended formulation is applied to a face-centered cubic polycrystal with uniform texture and intergranular cavities, and to a porous material with homogenous isotropic matrix and identical initial porosity distribution. These simulations allow us to assess the effect of the matrix’s polycrystallinity on porosity evolution. Microstructural effects, such as the influence of the Taylor factor of the crystalline ligaments linking interacting voids, were predicted and qualitatively confirmed by post-shocked microstrostructural characterization of polycrystalline copper. },
  Doi                      = {http://dx.doi.org/10.1016/j.actamat.2013.08.004},
  ISSN                     = {1359-6454},
  Keywords                 = {Polycrystal},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1359645413005909}
}

@Article{Lee2011991,
  Title                    = {Improving job scheduling algorithms in a grid environment },
  Author                   = {Yun-Han Lee and Seiven Leu and Ruay-Shiung Chang},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2011},
  Number                   = {8},
  Pages                    = {991 - 998},
  Volume                   = {27},

  Abstract                 = {Due to the advances in human civilization, problems in science and engineering are becoming more complicated than ever before. To solve these complicated problems, grid computing becomes a popular tool. A grid environment collects, integrates, and uses heterogeneous or homogeneous resources scattered around the globe by a high-speed network. A grid environment can be classified into two types: computing grids and data grids. This paper mainly focuses on computing grids. In computing grid, job scheduling is a very important task. A good scheduling algorithm can assign jobs to resources efficiently and can balance the system load. In this paper, we propose a hierarchical framework and a job scheduling algorithm called Hierarchical Load Balanced Algorithm (HLBA) for Grid environment. In our algorithm, we use the system load as a parameter in determining a balance threshold. And the scheduler adapts the balance threshold dynamically when the system load changes. The main contributions of this paper are twofold. First, the scheduling algorithm balances the system load with an adaptive threshold and second, it minimizes the makespan of jobs. Experimental results show that the performance of \{HLBA\} is better than those of other algorithms. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2011.05.014},
  ISSN                     = {0167-739X},
  Keywords                 = {Grid computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X11000963}
}

@Article{Leite20142260,
  Title                    = {A Fine-grained Approach for Power Consumption Analysis and Prediction },
  Author                   = {Alessandro Leite and Claude Tadonki and Christine Eisenbeis and Alba de Melo},
  Journal                  = {Procedia Computer Science },
  Year                     = {2014},
  Note                     = {2014 International Conference on Computational Science },
  Pages                    = {2260 - 2271},
  Volume                   = {29},

  Abstract                 = {Abstract Power consumption has became a critical concern in modern computing systems for various reasons including financial savings and environmental protection. With battery powered devices, we need to care about the available amount of energy since it is limited. For the case of supercomputers, as they imply a large aggregation of heavy \{CPU\} activities, we are exposed to a risk of overheating. As the design of current and future hardware is becoming more and more complex, energy prediction or estimation is as elusive as that of time performance. However, having a good prediction of power consumption is still an important request to the computer science community. Indeed, power consumption might become a common performance and cost metric in the near future. A good methodology for energy prediction could have a great impact on power-aware programming, compilation, or runtime monitoring. In this paper, we try to understand from measurements where and how power is consumed at the level of a computing node. We focus on a set of basic programming instructions, more precisely those related to \{CPU\} and memory. We propose an analytical prediction model based on the hypothesis that each basic instruction has an average energy cost that can be estimated on a given architecture through a series of micro-benchmarks. The considered energy cost per operation includes both the overhead of the embedding loop and associated (hardware/software) optimizations. Using these precalculated values, we derive a linear extrapolation model to predict the energy of a given algorithm expressed by means of atomic instructions. We then use three selected applications to check the accuracy of our prediction method by comparing our estimations with the corresponding measurements obtained using a multimeter. We show a 9.48% energy prediction on sorting. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2014.05.211},
  ISSN                     = {1877-0509},
  Keywords                 = {power consumption},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050914003883}
}

@Article{Leiter2013401,
  Title                    = {An algorithm for massively parallel dislocation dynamics simulations of small scale plasticity },
  Author                   = {Kenneth W. Leiter and Joshua C. Crone and Jaroslaw Knap},
  Journal                  = {Journal of Computational Science },
  Year                     = {2013},
  Number                   = {5},
  Pages                    = {401 - 411},
  Volume                   = {4},

  Abstract                 = {Accurate modeling of dislocation motion in bounded bodies is essential for the goal of obtaining desired properties, for example electronic or optical, of many microelectronic devices. At present, we lack high fidelity computer codes for such modeling that efficiently utilize modern parallel computer architectures. In contrast, many dislocation simulation codes are available for periodic or infinite bodies. In principle, these codes can be extended to allow for dislocation modeling in finite bodies. However, such extension may involve an additional solver to be employed, coupled with a dislocation simulation code. We present an algorithm for development of parallel dislocation simulation capability for bounded bodies based on such coupling. Subsequently, we analyze the performance of the algorithm for a demanding dislocation dynamics model problem. },
  Doi                      = {http://dx.doi.org/10.1016/j.jocs.2013.02.002},
  ISSN                     = {1877-7503},
  Keywords                 = {Dislocation dynamics},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877750313000227}
}

@Article{Leokhin20151696,
  Title                    = {A Study of Cloud/IX Operating System for the ARM-based Data Center Server Platform },
  Author                   = {Yury Leokhin and Peter Panfilov},
  Journal                  = {Procedia Engineering },
  Year                     = {2015},
  Note                     = {25th \{DAAAM\} International Symposium on Intelligent Manufacturing and Automation, 2014 },
  Pages                    = {1696 - 1705},
  Volume                   = {100},

  Abstract                 = {Abstract Exponential growth in data production and a prominent trend in data center design architecture – a shift from expensive hardware towards a multitude of simple servers – pose new tasks and demand the use of different strategies for data center architects. In this work, a new solutions to distributed systems design are discussed, which are based on Plan9 operating system model. We first overview application and research projects including project of porting Plan9 to the \{IBM\} Blue Gene/L supercomputer, project of the Plan9 use in data centers and cloud systems, and projects aimed at distributed embedded systems. Then we introduce a Cloud/IX operating system for the ARM-based server platforms that also follows the Plan9 model and is implemented on top of one of Plan 9 derivatives called 9front - a free software distributed operating system. We also present the experimental testbed setup and results of experimental study of the Cloud/IX on multi-computer server farm in actual data center environment. },
  Doi                      = {http://dx.doi.org/10.1016/j.proeng.2015.01.545},
  ISSN                     = {1877-7058},
  Keywords                 = {operating systems},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S187770581500572X}
}

@Article{Leone2010148,
  Title                    = {Targeting biomolecular flexibility with metadynamics },
  Author                   = {Vanessa Leone and Fabrizio Marinelli and Paolo Carloni and Michele Parrinello},
  Journal                  = {Current Opinion in Structural Biology },
  Year                     = {2010},
  Note                     = {Theory and simulation / Macromolecular assemblages },
  Number                   = {2},
  Pages                    = {148 - 154},
  Volume                   = {20},

  Abstract                 = {Metadynamics calculations allow investigating structure, plasticity, and energetics in a variety of biological processes spanning from molecular docking to protein folding. Recent theoretical developments have led to applications to increasingly complex systems and processes stepping up the biological relevance of the problem solved. Here, after summarizing recent technical advances and applications, we give a perspective of the method as a tool for enzymology and for the prediction of \{NMR\} and other spectroscopic data. },
  Doi                      = {http://dx.doi.org/10.1016/j.sbi.2010.01.011},
  ISSN                     = {0959-440X},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0959440X1000014X}
}

@Article{Levitt201598,
  Title                    = {Parallel eigensolvers in plane-wave Density Functional Theory },
  Author                   = {Antoine Levitt and Marc Torrent},
  Journal                  = {Computer Physics Communications },
  Year                     = {2015},
  Pages                    = {98 - 105},
  Volume                   = {187},

  Abstract                 = {Abstract We consider the problem of parallelizing electronic structure computations in plane-wave Density Functional Theory. Because of the limited scalability of Fourier transforms, parallelism has to be found at the eigensolver level. We show how a recently proposed algorithm based on Chebyshev polynomials can scale into the tens of thousands of processors, outperforming block conjugate gradient algorithms for large computations. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2014.10.015},
  ISSN                     = {0010-4655},
  Keywords                 = {Density Functional Theory},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465514003531}
}

@Article{Li199955,
  Title                    = {Algebraic properties of \{DNA\} operations },
  Author                   = {Zhuo Li},
  Journal                  = {Biosystems },
  Year                     = {1999},
  Number                   = {1–3},
  Pages                    = {55 - 61},
  Volume                   = {52},

  Abstract                 = {Any \{DNA\} strand can be identified with a word in the language X* where X={A, C, G, T}. By encoding A as 000, C as 010, G as 101, and T as 111, we treat the \{DNA\} operations concatenation, union, reverse, complement, annealing and melting, from the algebraic point of view. The concatenation and union play the roles of multiplication and addition over some algebraic structures, respectively. Then the rest of the operations turn out to be the homomorphisms or anti-homomorphisms of these algebraic structures. Using this technique, we find the relationship among these \{DNA\} operations. },
  Doi                      = {http://dx.doi.org/10.1016/S0303-2647(99)00032-5},
  ISSN                     = {0303-2647},
  Keywords                 = {Insertion},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0303264799000325}
}

@Article{Lieb2014246,
  Title                    = {Efficient Global Element Indexing for Parallel Adaptive Flow Solvers },
  Author                   = {Michael Lieb and Tobias Neckel and Thomas Schöps and Hans-Joachim Bungartz},
  Journal                  = {Procedia Computer Science },
  Year                     = {2014},
  Note                     = {2014 International Conference on Computational Science },
  Pages                    = {246 - 255},
  Volume                   = {29},

  Abstract                 = {Abstract Many grid-based solvers for partial differential equations (PDE) assemble matrices explicitly for discretizing the underlying \{PDE\} operators and/or for the underlying (non-) linear systems of equations. Often, the data structures or solver packages require a consecutive global numbering of the degrees of freedom across the boundaries of different parallel subdomains. Straightfor- ward approaches to realize this global indexing in parallel frequently result in serial parts of the assembling algorithms which causes a considerable bottleneck, in particular in large-scale applications. We present an efficient way to set up such a global indexing numbering scheme for large configurations via a position-based numeration on all parallel processes locally. The global number of shared nodes is determined via a tree-based communication pattern. We verified our implementation via state-of-the-art benchmark scenarios for incompressible flow simulations. A small performance study shows the parallel capability of our approach. The corresponding results can be generalized to other grid-based solvers that demand for global indexing in the context of large-scale parallelization. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2014.05.022},
  ISSN                     = {1877-0509},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050914001999}
}

@Article{Lim2015,
  Title                    = {Technological forecasting of supercomputer development: The March to Exascale computing },
  Author                   = {Dong-Joon Lim and Timothy R. Anderson and Tom Shott},
  Journal                  = {Omega },
  Year                     = {2015},
  Pages                    = {128 - 135},
  Volume                   = {51},

  Abstract                 = {Abstract Advances in supercomputers have come at a steady pace over the past 20 years. The next milestone is to build an Exascale computer however this requires not only speed improvement but also significant enhancements for energy efficiency and massive parallelism. This paper examines technological progress of supercomputer development to identify the innovative potential of three leading technology paths toward Exascale development: hybrid system, multicore system and manycore system. Performance measurement and rate of change calculation were made by technology forecasting using data envelopment analysis (TFDEA.) The results indicate that the current level of technology and rate of progress can achieve Exascale performance between early 2021 and late 2022 as either hybrid systems or manycore systems. },
  Doi                      = {http://dx.doi.org/10.1016/j.omega.2014.09.009},
  ISSN                     = {0305-0483},
  Keywords                 = {Data envelopment analysis},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0305048314001200}
}

@Article{Lim2015,
  Title                    = {Technological forecasting of supercomputer development: The March to Exascale computing },
  Author                   = {Dong-Joon Lim and Timothy R. Anderson and Tom Shott},
  Journal                  = {Omega },
  Year                     = {2015},
  Pages                    = {128 - 135},
  Volume                   = {51},

  Abstract                 = {Abstract Advances in supercomputers have come at a steady pace over the past 20 years. The next milestone is to build an Exascale computer however this requires not only speed improvement but also significant enhancements for energy efficiency and massive parallelism. This paper examines technological progress of supercomputer development to identify the innovative potential of three leading technology paths toward Exascale development: hybrid system, multicore system and manycore system. Performance measurement and rate of change calculation were made by technology forecasting using data envelopment analysis (TFDEA.) The results indicate that the current level of technology and rate of progress can achieve Exascale performance between early 2021 and late 2022 as either hybrid systems or manycore systems. },
  Doi                      = {http://dx.doi.org/10.1016/j.omega.2014.09.009},
  ISSN                     = {0305-0483},
  Keywords                 = {Data envelopment analysis},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0305048314001200}
}

@Article{Lingerfelt20141504,
  Title                    = {Near Real-time Data Analysis of Core-collapse Supernova Simulations with Bellerophon },
  Author                   = {E.J. Lingerfelt and O.E.B. Messer and S.S. Desai and C.A. Holt and E.J. Lentz},
  Journal                  = {Procedia Computer Science },
  Year                     = {2014},
  Note                     = {2014 International Conference on Computational Science },
  Pages                    = {1504 - 1514},
  Volume                   = {29},

  Abstract                 = {Abstract We present an overview of a software system, Bellerophon, built to support a production-level \{HPC\} application called CHIMERA, which simulates core-collapse supernova events at the petascale. Developed over the last four years, Bellerophon enables CHIMERA's geographically dispersed team of collaborators to perform data analysis in near real-time. Its n-tier architecture provides an encapsulated, end-to-end software solution that enables the \{CHIMERA\} team to quickly and easily access highly customizable animated and static views of results from anywhere in the world via a web- deliverable, cross-platform desktop application. In addition, Bellerophon addresses software engineering tasks for the \{CHIMERA\} team by providing an automated mechanism for performing regression testing on a variety of supercomputing platforms. Elements of the team's workflow management needs are met with software tools that dynamically generate code repository statistics, access important online resources, and monitor the current status of several supercomputing resources. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2014.05.136},
  ISSN                     = {1877-0509},
  Keywords                 = {data analysis},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050914003135}
}

@Article{Lingerfelt20112076,
  Title                    = {A Multitier System for the Verification, Visualization and Management of \{CHIMERA\} },
  Author                   = {E.J. Lingerfelt and O.E.B. Messer and J.A. Osborne and R.D. Budiardja and A. Mezzacappa},
  Journal                  = {Procedia Computer Science },
  Year                     = {2011},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2011 },
  Pages                    = {2076 - 2085},
  Volume                   = {4},

  Abstract                 = {\{CHIMERA\} is a multi-dimensional radiation hydrodynamics code designed to study core-collapse supernovae. The code is made up of three essentially independent parts: a hydrodynamics module, a nuclear burning module, and a neutrino transport solver combined within an operator-split approach. Given CHIMERA's complexity and pace of ongoing development, a new support system, Bellerophon, has been designed and implemented to perform automated verification, visualization and management tasks while integrating with other workflow systems utilized by CHIMERA's development group. In order to achieve these goals, a multitier approach has been adopted. By integrating supercomputing platforms, visualization clusters, a dedicated web server and a client-side desktop application, this system attempts to provide an encapsulated, end-to-end solution to these needs. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2011.04.227},
  ISSN                     = {1877-0509},
  Keywords                 = {Supernovae},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050911002857}
}

@Article{Liu2011261,
  Title                    = {A Multilevel Parallelism Support for Multi-Physics Coupling },
  Author                   = {Fang Liu and Masha Sosonkina},
  Journal                  = {Procedia Computer Science },
  Year                     = {2011},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2011 },
  Pages                    = {261 - 270},
  Volume                   = {4},

  Abstract                 = {A new challenge in scientific computing is to merge existing simulation models to create new higher fidelity combined (often multi-level) models. While this challenge has been a driving force in climate modeling for nearly a decade, fusion energy and space weather modeling are starting just now to integrate different sub-physics into a single model. Hence, the demand for novel software paradigms and tools increases drastically. A programming style that mixes task and data parallelism and enables concurrent execution of independent tasks on disjoint processor subsets is called multi-level parallelism. Combined models naturally map into this style, such that sub-models run simultaneously on different processor subgroups. In authors’ previous work, software interfaces supporting the model coupling based on component representations are proposed and shown to successfully combine multi-physics packages via an inter-model solver. In this paper, the inter-model solver, called Coupler, is extended for the execution in multiple processes rather than as a single process. In essence, the multiple program multiple data paradigm is applied to multi-physics coupling. A pure C++ implementation has been developed to bypass the application adaptation to the Common Component Architecture (CCA) framework used in the previous work and to generalize the proposed approach. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2011.04.028},
  ISSN                     = {1877-0509},
  Keywords                 = {Parallel model coupling},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S187705091100086X}
}

@Article{Liu2015117,
  Title                    = {Hierarchical Collective I/O Scheduling for High-Performance Computing },
  Author                   = {Jialin Liu and Yu Zhuang and Yong Chen},
  Journal                  = {Big Data Research },
  Year                     = {2015},
  Note                     = {Big Data, Analytics, and High-Performance Computing },
  Number                   = {3},
  Pages                    = {117 - 126},
  Volume                   = {2},

  Abstract                 = {Abstract The non-contiguous access pattern of many scientific applications results in a large number of I/O requests, which can seriously limit the data-access performance. Collective I/O has been widely used to address this issue. However, the performance of collective I/O could be dramatically degraded in today's high-performance computing systems due to the increasing shuffle cost caused by highly concurrent data accesses. This situation tends to be even worse as many applications become more and more data intensive. Previous research has primarily focused on optimizing I/O access cost in collective I/O but largely ignored the shuffle cost involved. Previous works assume that the lowest average response time leads to the best QoS and performance, while that is not always true for collective requests when considering the additional shuffle cost. In this study, we propose a new hierarchical I/O scheduling (HIO) algorithm to address the increasing shuffle cost in collective I/O. The fundamental idea is to schedule applications' I/O requests based on a shuffle cost analysis to achieve the optimal overall performance, instead of achieving optimal I/O accesses only. The algorithm is currently evaluated with the \{MPICH3\} and PVFS2. Both theoretical analysis and experimental tests show that the proposed hierarchical I/O scheduling has a potential in addressing the degraded performance issue of collective I/O with highly concurrent accesses. },
  Doi                      = {http://dx.doi.org/10.1016/j.bdr.2015.01.007},
  ISSN                     = {2214-5796},
  Keywords                 = {Collective I/O},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S2214579615000088}
}

@Article{Liu201598,
  Title                    = {A scalable parallel genetic algorithm for the Generalized Assignment Problem },
  Author                   = {Yan Y. Liu and Shaowen Wang},
  Journal                  = {Parallel Computing },
  Year                     = {2015},
  Pages                    = {98 - 119},
  Volume                   = {46},

  Abstract                 = {Abstract Known as an effective heuristic for finding optimal or near-optimal solutions to difficult optimization problems, a genetic algorithm (GA) is inherently parallel for exploiting high performance and parallel computing resources for randomized iterative evolutionary computation. It remains to be a significant challenge, however, to devise parallel genetic algorithms (PGAs) that can scale to massively parallel computer architecture (also known as the mainstream supercomputer architecture) primarily because: (1) a common \{PGA\} design adopts synchronized migration, which becomes increasingly costly as more processor cores are involved in global synchronization; and (2) asynchronous \{PGA\} design and associated performance evaluation are intricate due to the fact that \{PGA\} is a type of stochastic algorithm and the amount of computation work needed to solve a problem is not simply dependent on the problem size. To address the challenge, this paper describes a scalable coarse-grained PGA–PGAP, for a well-known NP-hard optimization problem: Generalized Assignment Problem (GAP). Specifically, an asynchronous migration strategy is developed to enable efficient deme interactions and significantly improve the overlapping of computation and communication. Buffer overflow and its relationship with migration parameters were investigated to resolve the issues of observed message buffer overflow and the loss of good solutions obtained from migration. Two algorithmic conditions were then established to detect these issues caused by communication delays and improper configuration of migration parameters and, thus, guide the dynamic tuning of \{PGA\} parameters to detect and avoid these issues. A set of computational experiments is designed to evaluate the scalability and numerical performance of PGAP. These experiments were conducted for large \{GAP\} instances on multiple supercomputers as part of the National Science Foundation Extreme Science and Engineering Discovery Environment (XSEDE). Results showed that, \{PGAP\} exhibited desirable scalability by achieving low communication cost when using up to 16,384 processor cores. Near-linear and super-linear speedups on large \{GAP\} instances were obtained in strong scaling tests. Desirable scalability to both population size and the number of processor cores were observed in weak scaling tests. The design strategies applied in \{PGAP\} are applicable to general asynchronous \{PGA\} development. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2014.04.008},
  ISSN                     = {0167-8191},
  Keywords                 = {Generalized Assignment Problem},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819114000519}
}

@Article{Lohner201353,
  Title                    = {Handling tens of thousands of cores with industrial/legacy codes: Approaches, implementation and timings },
  Author                   = {Rainald Löhner and Joseph D. Baum},
  Journal                  = {Computers \& Fluids },
  Year                     = {2013},
  Note                     = {International Workshop on Future of \{CFD\} and Aerospace Sciences },
  Pages                    = {53 - 62},
  Volume                   = {85},

  Abstract                 = {Abstract The consequences that the recent stagnation in clockrates for \{CPUs\} has had on large-scale \{CFD\} runs are examined. At first sight, the conclusion is that only massive parallelism at the loop or domain decomposition level will lead to higher \{FLOP\} counts. However, the significant differences in advances for CPUs/GPUs versus \{RAM\} and interprocessor communication bandwidth lead to a so-called ‘limiting domain size’, below which communication dominates execution times and performance degrades drastically. The consequences of this ‘red-shift’ for the future of \{CFD\} are manifold: the time to advance the solution one timestep is limited, implying that even with unlimited number of processors/cores, LES, \{DES\} and \{DNS\} runs for realistic Reynolds-numbers will require days or weeks of execution. },
  Doi                      = {http://dx.doi.org/10.1016/j.compfluid.2012.09.030},
  ISSN                     = {0045-7930},
  Keywords                 = {Massive parallelism},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045793012004112}
}

@Article{Löhner201353,
  Title                    = {Handling tens of thousands of cores with industrial/legacy codes: Approaches, implementation and timings },
  Author                   = {Rainald Löhner and Joseph D. Baum},
  Journal                  = {Computers \& Fluids },
  Year                     = {2013},
  Note                     = {International Workshop on Future of \{CFD\} and Aerospace Sciences },
  Pages                    = {53 - 62},
  Volume                   = {85},

  Abstract                 = {Abstract The consequences that the recent stagnation in clockrates for \{CPUs\} has had on large-scale \{CFD\} runs are examined. At first sight, the conclusion is that only massive parallelism at the loop or domain decomposition level will lead to higher \{FLOP\} counts. However, the significant differences in advances for CPUs/GPUs versus \{RAM\} and interprocessor communication bandwidth lead to a so-called ‘limiting domain size’, below which communication dominates execution times and performance degrades drastically. The consequences of this ‘red-shift’ for the future of \{CFD\} are manifold: the time to advance the solution one timestep is limited, implying that even with unlimited number of processors/cores, LES, \{DES\} and \{DNS\} runs for realistic Reynolds-numbers will require days or weeks of execution. },
  Doi                      = {http://dx.doi.org/10.1016/j.compfluid.2012.09.030},
  ISSN                     = {0045-7930},
  Keywords                 = {Massive parallelism},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045793012004112}
}

@Article{Lugones201478,
  Title                    = {A reconfigurable, regular-topology cluster/datacenter network using commodity optical switches },
  Author                   = {Diego Lugones and Kostas Katrinis and Georgios Theodoropoulos and Martin Collier},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2014},
  Note                     = {Special Issue on Extreme Scale Parallel Architectures and Systems, Cryptography in Cloud Computing and Recent Advances in Parallel and Distributed Systems, \{ICPADS\} 2012 Selected Papers },
  Pages                    = {78 - 89},
  Volume                   = {30},

  Abstract                 = {Abstract Hybrid optical/electrical interconnects using commercial optical circuit switches have been previously proposed as an attractive alternative to fully-connected electronically-switched networks. Among other advantages, such a design offers increased port density, bandwidth/port, cabling and energy efficiency, compared to conventional packet-switched counterparts. Recent proposals for such system designs have looked at small and/or medium scale networks employing hybrid interconnects. In our previous work, we presented a hybrid optical/electrical interconnect architecture targeting large-scale deployments in high-performance computing and datacenter environments. To reduce complexity, our architecture employs a regular shuffle network topology that allows for simple management and cabling. Thanks to using a single-stage core interconnect and multiple optical planes, our design can be both incrementally scaled up (in capacity) and scaled out (in the number of racks) without requiring major re-cabling and network re-configuration. In this paper, we extend the fundamentals of our existing work towards quantifying and understanding the performance of these type of systems against more diverse workload communication patterns and system design parameters. In this context, we evaluate–among other characteristics–the overhead of the reconfiguration (decomposition and routing) scheme proposed and extend our simulations to highly adversarial flow generation rate/duration values that challenge the reconfiguration latency of the system. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2013.04.016},
  ISSN                     = {0167-739X},
  Keywords                 = {Datacenter networks},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X13000769}
}

@Article{Dongarra2015,
  Title                    = {HPC Programming on Intel Many-Integrated-Core Hardware with MAGMA Port to Xeon Phi},
  Author                   = {Jack Dongarra Mark Gates Azzam Haidar Yulu Jia Khairul Kabir Piotr Luszczek and Stanimire Tomov},
  Journal                  = {Scientific Programming},
  Year                     = {2015},
  Volume                   = {2015}
}

@Article{Ma201547,
  Title                    = {Remote sensing big data computing: Challenges and opportunities },
  Author                   = {Yan Ma and Haiping Wu and Lizhe Wang and Bormin Huang and Rajiv Ranjan and Albert Zomaya and Wei Jie},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2015},
  Note                     = {Special Section: A Note on New Trends in Data-Aware Scheduling and Resource Provisioning in Modern \{HPC\} Systems },
  Pages                    = {47 - 60},
  Volume                   = {51},

  Abstract                 = {Abstract As we have entered an era of high resolution earth observation, the \{RS\} data are undergoing an explosive growth. The proliferation of data also give rise to the increasing complexity of \{RS\} data, like the diversity and higher dimensionality characteristic of the data. \{RS\} data are regarded as \{RS\} “Big Data”. Fortunately, we are witness the coming technological leapfrogging. In this paper, we give a brief overview on the Big Data and data-intensive problems, including the analysis of \{RS\} Big Data, Big Data challenges, current techniques and works for processing \{RS\} Big Data. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2014.10.029},
  ISSN                     = {0167-739X},
  Keywords                 = {Remote sensing data processing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X14002234}
}

@Article{Majumder201336,
  Title                    = {High-throughput, energy-efficient network-on-chip-based hardware accelerators },
  Author                   = {Turbo Majumder and Partha Pratim Pande and Ananth Kalyanaraman},
  Journal                  = {Sustainable Computing: Informatics and Systems },
  Year                     = {2013},
  Number                   = {1},
  Pages                    = {36 - 46},
  Volume                   = {3},

  Abstract                 = {Several emerging application domains in scientific computing demand high computation throughputs to achieve terascale or higher performance. Dedicated centers hosting scientific computing tools on a few high-end servers could rely on hardware accelerator co-processors that contain multiple lightweight custom cores interconnected through an on-chip network. With increasing workloads, these many-core platforms need to deliver high overall computation throughput while also being energy-efficient. Conventional multicore architectures can achieve a limited computational throughput due to the inherent multi-hop nature of the on-chip network infrastructure. By inserting long-range links that act as shortcuts in a regular network-on-chip (NoC) architecture, both the achievable bandwidth and energy efficiency of a multicore platform can be significantly enhanced. In this paper, we first propose a NoC-driven use-case model for throughput-oriented scientific applications, and subsequently use the model to study the effect of using long-range links in conjunction with different resource allocation strategies on reducing the overall on-chip communication and enhancing computational throughput. NoCs with both wired and on-chip wireless links are explored in the study. We also evaluate our NoC-based platforms with respect to energy-efficiency and power consumption. We analyze how throughput and power consumption are correlated with the statistical properties of the application traffic. In addition, we compare and analyze chip-level thermal profiles for these alternatives. Our experiments using kernels from a popular phylogenetic inference application suite show that we can deliver computation throughput over 1011 operations per second, consuming ∼0.5 nJ per operation, while ensuring that on-chip temperature variation is within 26 °C. },
  Doi                      = {http://dx.doi.org/10.1016/j.suscom.2013.01.001},
  ISSN                     = {2210-5379},
  Keywords                 = {Network-on-chip},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S2210537913000024}
}

@Article{Malossi201524,
  Title                    = {Systematic derivation of time and power models for linear algebra kernels on multicore architectures },
  Author                   = {A. Cristiano I. Malossi and Yves Ineichen and Costas Bekas and Alessandro Curioni and Enrique S. Quintana-Ortí},
  Journal                  = {Sustainable Computing: Informatics and Systems },
  Year                     = {2015},
  Pages                    = {24 - 40},
  Volume                   = {7},

  Abstract                 = {Abstract The power wall asks for a holistic effort from the high performance and scientific communities to develop power-aware tools and applications which ultimately drive the design of energy-efficient hardware. Toward this goal, we introduce a systematic methodology to derive reliable time and power models for algebraic kernels employing a bottom-up approach. This strategy helps to understand the contribution of the different kernels to the total energy consumption of applications, as well as to distinguish between the cost of fine-grain components such as arithmetic, memory access, and overheads introduced by, e.g., multithreading or reductions. To study and validate our methodology, we initially focus on two key memory-bound BLAS-1 vector kernels: the dot product and the axpy operation. Subsequently, we show how these kernels can be composed to accurately predict the energy consumption of more heterogeneous algorithms, such as the Conjugate Gradient method, while tackling the elaborate memory hierarchy and the high degree of concurrency of today's processors; in particular, the evaluation of the models on the IBM® Blue Gene/Q supercomputer, as well as on the IBM® Power 755 server, reveals that average power consumption is captured at high accuracy, yet the models and the methodology are universal to be portable to any general-purpose multicore architecture. },
  Doi                      = {http://dx.doi.org/10.1016/j.suscom.2015.02.001},
  ISSN                     = {2210-5379},
  Keywords                 = {Performance modeling},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S2210537915000037}
}

@InProceedings{MalyshkinASSY,
  Title                    = {Functionality in ASSY system and language of functional programming},
  Author                   = {V. E. Malyshkin},
  Booktitle                = {Parallel Algorithms/Architecture Synthesis, 1995. Proceedings., First Aizu International Symposium on},
  Year                     = {1995},
  Month                    = {Mar},
  Pages                    = {92-97},

  Doi                      = {10.1109/AISPAS.1995.401350},
  Keywords                 = {functional languages;functional programming;parallel programming;program assemblers;programming theory;ASSY system;application problem parallelization;functional language;functional programming;image processing;integrated system;natural phenomena modeling;nuclear physics;parallel programming system;parallel programs;partitioning;seismic data;specific multiprocessor system;wide range application problems;Algorithm design and analysis;Assembly systems;Computer languages;Concurrent computing;Functional programming;Image processing;Multiprocessing systems;Nuclear physics;Parallel programming;Supercomputers}
}

@Article{Markowitz2015730,
  Title                    = {Ten Years of Maintaining and Expanding a Microbial Genome and Metagenome Analysis System },
  Author                   = {Victor M. Markowitz and I-Min A. Chen and Ken Chu and Amrita Pati and Natalia N. Ivanova and Nikos C. Kyrpides},
  Journal                  = {Trends in Microbiology },
  Year                     = {2015},
  Number                   = {11},
  Pages                    = {730 - 741},
  Volume                   = {23},

  Abstract                 = {Launched in March 2005, the Integrated Microbial Genomes (IMG) system is a comprehensive data management system that supports multidimensional comparative analysis of genomic data. At the core of the \{IMG\} system is a data warehouse that contains genome and metagenome datasets sequenced at the Joint Genome Institute or provided by scientific users, as well as public genome datasets available at the National Center for Biotechnology Information Genbank sequence data archive. Genomes and metagenome datasets are processed using IMG's microbial genome and metagenome sequence data processing pipelines and are integrated into the data warehouse using IMG's data integration toolkits. Microbial genome and metagenome application specific data marts and user interfaces provide access to different subsets of IMG's data and analysis toolkits. This review article revisits IMG's original aims, highlights key milestones reached by the system during the past 10 years, and discusses the main challenges faced by a rapidly expanding system, in particular the complexity of maintaining such a system in an academic setting with limited budgets and computing and data management infrastructure. },
  Doi                      = {http://dx.doi.org/10.1016/j.tim.2015.07.012},
  ISSN                     = {0966-842X},
  Keywords                 = {microbial genomics},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0966842X15001754}
}

@Article{Markram201139,
  Title                    = {Introducing the Human Brain Project },
  Author                   = {Henry Markram and Karlheinz Meier and Thomas Lippert and Sten Grillner and Richard Frackowiak and Stanislas Dehaene and Alois Knoll and Haim Sompolinsky and Kris Verstreken and Javier DeFelipe and Seth Grant and Jean-Pierre Changeux and Alois Saria},
  Journal                  = {Procedia Computer Science },
  Year                     = {2011},
  Note                     = {Proceedings of the 2nd European Future Technologies Conference and Exhibition 2011 (FET 11) },
  Pages                    = {39 - 42},
  Volume                   = {7},

  Abstract                 = {The Human Brain Project (HBP) is a candidate project in the European Union's \{FET\} Flagship Program, funded by the \{ICT\} Program in the Seventh Framework Program. The project will develop a new integrated strategy for understanding the human brain and a novel research platform that will integrate all the data and knowledge we can acquire about the structure and function of the brain and use it to build unifying models that can be validated by simulations running on supercomputers. The project will drive the development of supercomputing for the life sciences, generate new neuroscientific data as a benchmark for modeling, develop radically new tools for informatics, modeling and simulation, and build virtual laboratories for collaborative basic and clinical studies, drug simulation and virtual prototyping of neuroprosthetic, neuromorphic, and robotic devices. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2011.12.015},
  ISSN                     = {1877-0509},
  Keywords                 = {Human brain},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050911006806}
}

@Article{Marras2015360,
  Title                    = {A parameter-free dynamic alternative to hyper-viscosity for coupled transport equations: Application to the simulation of 3D squall lines using spectral elements },
  Author                   = {Simone Marras and Francis X. Giraldo},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2015},
  Pages                    = {360 - 373},
  Volume                   = {283},

  Abstract                 = {Abstract The stabilization of high order spectral elements to solve the transport equations for tracers in the atmosphere remains an active topic of research among atmospheric modelers. This paper builds on our previous work on variational multiscale stabilization (VMS) and discontinuity capturing (DC) (Marras et al. (2012) [7]) and shows the applicability of VMS+DC to realistic atmospheric problems that involve physics coupling with phase change in the simulation of 3D deep convection. We show that the VMS+DC approach is a robust technique that can damp the high order modes characterizing the spectral element solution of complex coupled transport problems. The method has important properties that techniques of more common use often lack: 1) it is free of a user-defined parameter, 2) it is anisotropic in that it only acts along the flow direction, 3) it is numerically consistent, and 4) it can improve the monotonicity of high-order spectral elements. The proposed method is assessed by comparing the results against those obtained with a fourth-order hyper-viscosity programmed in the same code. The main conclusion that arises is that tuning can be fully avoided without loss of accuracy if the dissipative scheme is properly designed. Finally, the cost of parallel communication is that of a second order operator which means that fewer communications are required by VMS+DC than by a hyper-viscosity method; fewer communications translate into a faster and more scalable code, which is of vital importance as we approach the exascale range of computing. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2014.11.046},
  ISSN                     = {0021-9991},
  Keywords                 = {Residual-based stabilization},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999114008158}
}

@Article{Marras201577,
  Title                    = {Stabilized high-order Galerkin methods based on a parameter-free dynamic \{SGS\} model for \{LES\} },
  Author                   = {Simone Marras and Murtazo Nazarov and Francis X. Giraldo},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2015},
  Pages                    = {77 - 101},
  Volume                   = {301},

  Abstract                 = {Abstract The high order spectral element approximation of the Euler equations is stabilized via a dynamic sub-grid scale model (Dyn-SGS). This model was originally designed for linear finite elements to solve compressible flows at large Mach numbers. We extend its application to high-order spectral elements to solve the Euler equations of low Mach number stratified flows. The major justification of this work is twofold: stabilization and large eddy simulation are achieved via one scheme only. Because the diffusion coefficients of the regularization stresses obtained via Dyn-SGS are residual-based, the effect of the artificial diffusion is minimal in the regions where the solution is smooth. The direct consequence is that the nominal convergence rate of the high-order solution of smooth problems is not degraded. To our knowledge, this is the first application in atmospheric modeling of a spectral element model stabilized by an eddy viscosity scheme that, by construction, may fulfill stabilization requirements, can model turbulence via LES, and is completely free of a user-tunable parameter. From its derivation, it will be immediately clear that Dyn-SGS is independent of the numerical method; it could be implemented in a discontinuous Galerkin, finite volume, or other environments alike. Preliminary discontinuous Galerkin results are reported as well. The straightforward extension to non-linear scalar problems is also described. A suite of 1D, 2D, and 3D test cases is used to assess the method, with some comparison against the results obtained with the most known Lilly–Smagorinsky \{SGS\} model. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2015.07.034},
  ISSN                     = {0021-9991},
  Keywords                 = {Large eddy simulation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999115004799}
}

@Article{Mattei20144,
  Title                    = {“Ex Nihilo Nihil Fit”: Massive Funding Promises a Golden Decade of Functional Brain Research },
  Author                   = {Tobias A. Mattei},
  Journal                  = {World Neurosurgery },
  Year                     = {2014},
  Number                   = {1},
  Pages                    = {4 - 6},
  Volume                   = {81},

  Doi                      = {http://dx.doi.org/10.1016/j.wneu.2013.11.017},
  ISSN                     = {1878-8750},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1878875013015635}
}

@Article{Mattila201662,
  Title                    = {A prospect for computing in porous materials research: Very large fluid flow simulations },
  Author                   = {Keijo Mattila and Tuomas Puurtinen and Jari Hyväluoma and Rodrigo Surmas and Markko Myllys and Tuomas Turpeinen and Fredrik Robertsén and Jan Westerholm and Jussi Timonen},
  Journal                  = {Journal of Computational Science },
  Year                     = {2016},
  Pages                    = {62 - 76},
  Volume                   = {12},

  Abstract                 = {Abstract Properties of porous materials, abundant both in nature and industry, have broad influences on societies via, e.g. oil recovery, erosion, and propagation of pollutants. The internal structure of many porous materials involves multiple scales which hinders research on the relation between structure and transport properties: typically laboratory experiments cannot distinguish contributions from individual scales while computer simulations cannot capture multiple scales due to limited capabilities. Thus the question arises how large domain sizes can in fact be simulated with modern computers. This question is here addressed using a realistic test case; it is demonstrated that current computing capabilities allow the direct pore-scale simulation of fluid flow in porous materials using system sizes far beyond what has been previously reported. The achieved system sizes allow the closing of some particular scale gaps in, e.g. soil and petroleum rock research. Specifically, a full steady-state fluid flow simulation in a porous material, represented with an unprecedented resolution for the given sample size, is reported: the simulation is executed on a CPU-based supercomputer and the 3D geometry involves 16,3843 lattice cells (around 590 billion of them are pore sites). Using half of this sample in a benchmark simulation on a GPU-based system, a sustained computational performance of 1.77 \{PFLOPS\} is observed. These advances expose new opportunities in porous materials research. The implementation techniques here utilized are standard except for the tailored high-performance data layouts as well as the indirect addressing scheme with a low memory overhead and the truly asynchronous data communication scheme in the case of \{CPU\} and \{GPU\} code versions, respectively. },
  Doi                      = {http://dx.doi.org/10.1016/j.jocs.2015.11.013},
  ISSN                     = {1877-7503},
  Keywords                 = {Porous material},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877750315300478}
}

@Article{Maxville20111953,
  Title                    = {eScience: Building our Body of Knowledge },
  Author                   = {Valerie Maxville},
  Journal                  = {Procedia Computer Science },
  Year                     = {2011},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2011 },
  Pages                    = {1953 - 1963},
  Volume                   = {4},

  Abstract                 = {This paper describes the need for an eScience BoK, particularly as a resource for educators. eScience is a term representing the computational technology and techniques utilised when undertaking research. As eScience matures, stakeholders, and particularly educators, can benefit from the clarity that a defined Body of Knowledge (BOK) can provide. The \{BOK\} would require domain-specific and technological aspects to be addressed. This paper describes a framework for a prototype \{BOK\} for eScience and discusses how the \{BOK\} can be used as a tool to drive education, outreach and infrastructure planning. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2011.04.213},
  ISSN                     = {1877-0509},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050911002717}
}

@Article{Mehl2016869,
  Title                    = {Parallel coupling numerics for partitioned fluid–structure interaction simulations },
  Author                   = {Miriam Mehl and Benjamin Uekermann and Hester Bijl and David Blom and Bernhard Gatzhammer and Alexander van Zuijlen},
  Journal                  = {Computers \& Mathematics with Applications },
  Year                     = {2016},
  Number                   = {4},
  Pages                    = {869 - 891},
  Volume                   = {71},

  Abstract                 = {Abstract Within the last decade, very sophisticated numerical methods for the iterative and partitioned solution of fluid–structure interaction problems have been developed that allow for high accuracy and very complex scenarios. The combination of these two aspects–accuracy and complexity–demands very high computational grid resolutions and, thus, high performance computing methods designed for massively parallel hardware architectures. For those architectures, currently used coupling methods, which mainly work with a staggered execution of the fluid and the structure solver, i.e., the execution of one solver after the other in every outer iteration, lead to severe load imbalances: if the flow solver, e.g., scales on a very large number of processors but the structural solver does not due to its limited amount of data and required operations, almost all processors assigned to the coupled simulations are idle during the execution of the structure solver. We propose two new iterative coupling methods that allow for the simultaneous execution of flow and structure solvers. In both cases, we show that pure fixed-point iterations based on the parallel execution of the solvers do not lead to good results, but the combination of parallel solver execution and so-called quasi-Newton methods yields very efficient and robust methods. Those methods are known to be very efficient also for the stabilization of critical scenarios solved with the standard staggered solver execution. We demonstrate the competitive convergence of our methods for various established benchmark scenarios. Both methods are perfectly suited for use with black-box solvers because the quasi-Newton approach uses solely input and output information of the solvers to approximate the effect of the unknown Jacobians that would be required in a standard Newton solver. },
  Doi                      = {http://dx.doi.org/10.1016/j.camwa.2015.12.025},
  ISSN                     = {0898-1221},
  Keywords                 = {Fluid–structure interaction},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0898122115005933}
}

@Article{Melancon2012177,
  Title                    = {Challenges to effective cancer nanotheranostics },
  Author                   = {Marites P. Melancon and R. Jason Stafford and Chun Li},
  Journal                  = {Journal of Controlled Release },
  Year                     = {2012},
  Note                     = {Drug Delivery and Cancer: Today's Challenges, Tomorrow's Directions. },
  Number                   = {2},
  Pages                    = {177 - 182},
  Volume                   = {164},

  Abstract                 = {Advances in nanotechnology for oncology will arise from an increased understanding of the interaction between nanomaterials and biological systems; refinement of multifunctional nanocomposites for applications such as simultaneous imaging and therapy (theranostics); and harnessing of the unique physicochemical properties arising from nanoscale effects which distinguish them from small-molecular-weight molecules in the detection and destruction of cancer cells with high selectivity and efficiency. The major challenges in successful clinical translation of tumor specific nanoparticle delivery include overcoming various biological barriers and demonstrating enhanced therapeutic efficacy over the current standard of care in the clinic. For many nanoparticle mediated theranostic applications, image guidance can play a crucial role not only in exploiting the cancer specific imaging capabilities of these novel particles, but in planning, targeting, monitoring and verifying treatment delivery, thus enhancing the safety and efficacy of these emerging procedures. },
  Doi                      = {http://dx.doi.org/10.1016/j.jconrel.2012.07.045},
  ISSN                     = {0168-3659},
  Keywords                 = {Nanoparticles},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0168365912006220}
}

@Article{Melnikova2015679,
  Title                    = {\{CAVE\} 3D: Software Extensions for Scientific Visualization of Large-scale Models },
  Author                   = {Natalia Melnikova and Stepan Orlov and Nikolay Shabrov and Vlad Kiev and Aleksey Kuzin and Michael Resch and Uwe Woessner and Martin Aumüller},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {4th International Young Scientist Conference on Computational Science },
  Pages                    = {679 - 688},
  Volume                   = {66},

  Abstract                 = {Abstract Numerical analysis of large-scale and multidisciplinary problems on high-performance computer systems is one of the main computational challenges of the 21st century. The amount of data processed in complex systems analyses approaches peta- and exascale. The technical possibility for real-time visualization, post-processing and analysis of large-scale models is extremely important for carrying out comprehensive numerical studies. Powerful visualization is going to play an important role in the future of large-scale models. In this paper, we describe several software extensions aimed to improve visualization performance for large-scale models and developed by our team for 3D virtual environment systems such as \{CAVEs\} and Powerwalls. These extensions include an algorithm for real-time generation of isosurfaces on large meshes and a visualization system designed for massively parallel computing environment. Besides, we describe an augmented reality system developed by the part of our team in Stuttgart. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.11.077},
  ISSN                     = {1877-0509},
  Keywords                 = {\{CAVE\} 3D},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915034262}
}

@Article{Membarth20143191,
  Title                    = {Towards a performance-portable description of geometric multigrid algorithms using a domain-specific language },
  Author                   = {Richard Membarth and Oliver Reiche and Christian Schmitt and Frank Hannig and Jürgen Teich and Markus Stürmer and Harald Köstler},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2014},
  Note                     = {Domain-Specific Languages and High-Level Frameworks for High-Performance Computing },
  Number                   = {12},
  Pages                    = {3191 - 3201},
  Volume                   = {74},

  Abstract                 = {Abstract High Performance Computing (HPC) systems are nowadays more and more heterogeneous. Different processor types can be found on a single node including accelerators such as Graphics Processing Units (GPUs). To cope with the challenge of programming such complex systems, this work presents a domain-specific approach to automatically generate code tailored to different processor types. Low-level \{CUDA\} and OpenCL code is generated from a high-level description of an algorithm specified in a Domain-Specific Language (DSL) instead of writing hand-tuned code for \{GPU\} accelerators. The \{DSL\} is part of the Heterogeneous Image Processing Acceleration (HIPAcc) framework and was extended in this work to handle grid hierarchies in order to model different cycle types. Language constructs are introduced to process and represent data at different resolutions. This allows to describe image processing algorithms that work on image pyramids as well as multigrid methods in the stencil domain. By decoupling the algorithm from its schedule, the proposed approach allows to generate efficient stencil code implementations. Our results show that similar performance compared to hand-tuned codes can be achieved. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2014.08.008},
  ISSN                     = {0743-7315},
  Keywords                 = {Multigrid},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731514001506}
}

@Article{Meneses2014536,
  Title                    = {Energy profile of rollback-recovery strategies in high performance computing },
  Author                   = {Esteban Meneses and Osman Sarood and Laxmikant V. Kalé},
  Journal                  = {Parallel Computing },
  Year                     = {2014},
  Number                   = {9},
  Pages                    = {536 - 547},
  Volume                   = {40},

  Abstract                 = {Abstract Extreme-scale computing is set to provide the infrastructure for the advances and breakthroughs that will solve some of the hardest problems in science and engineering. However, resilience and energy concerns loom as two of the major challenges for machines at that scale. The number of components that will be assembled in the supercomputers plays a fundamental role in these challenges. First, a large number of parts will substantially increase the failure rate of the system compared to the failure frequency of current machines. Second, those components have to fit within the power envelope of the installation and keep the energy consumption within operational margins. Extreme-scale machines will have to incorporate fault tolerance mechanisms and honor the energy and power restrictions. Therefore, it is essential to understand how fault tolerance and energy consumption interplay. This paper presents a comparative evaluation and analysis of energy consumption of three different rollback-recovery protocols: checkpoint/restart, message logging and parallel recovery. Our experimental evaluation shows parallel recovery has the minimum execution time and energy consumption. Additionally, we present an analytical model that projects parallel recovery can reduce energy consumption more than 37% compared to checkpoint/restart at extreme scale. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2014.03.005},
  ISSN                     = {0167-8191},
  Keywords                 = {Rollback-recovery},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819114000350}
}

@Article{Merta2015,
  Title                    = {Numerical libraries solving large-scale problems developed at \{IT4Innovations\} Research Programme Supercomputing for Industry },
  Author                   = {Michal Merta and Jan Zapletal and Tomas Brzobohaty and Alexandros Markopoulos and Lubomir Riha and Martin Cermak and Vaclav Hapla and David Horak and Lukas Pospisil and Alena Vasatova},
  Journal                  = {Perspectives in Science },
  Year                     = {2015},
  Pages                    = { - },

  Abstract                 = {Summary The team of Research Programme Supercomputing for Industry at \{IT4Innovations\} National Supercomputing Center is focused on development of highly scalable algorithms for solution of linear and non-linear problems arising from different engineering applications. As a main parallelisation technique, domain decomposition methods (DDM) of \{FETI\} type are used. These methods are combined with finite element (FEM) or boundary element (BEM) discretisation methods and quadratic programming (QP) algorithms. All these algorithms were implemented into our in-house software packages BEM4I, \{ESPRESO\} and PERMON, which demonstrate high scalability up to tens of thousands of cores. },
  Doi                      = {http://dx.doi.org/10.1016/j.pisc.2015.11.023},
  ISSN                     = {2213-0209},
  Keywords                 = {FETI},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S2213020915000683}
}

@Article{miller1976validity,
  Title                    = {Validity of disk galaxy simulations},
  Author                   = {Miller, RH},
  Journal                  = {Journal of Computational Physics},
  Year                     = {1976},
  Number                   = {4},
  Pages                    = {400--437},
  Volume                   = {21},

  Publisher                = {Elsevier}
}

@Article{Mininni2011316,
  Title                    = {A hybrid MPI–OpenMP scheme for scalable parallel pseudospectral computations for fluid turbulence },
  Author                   = {Mininni, Pablo D. and Duane Rosenberg and Raghu Reddy and Annick Pouquet},
  Journal                  = {Parallel Computing },
  Year                     = {2011},
  Number                   = {6–7},
  Pages                    = {316 - 326},
  Volume                   = {37},

}

@Article{Minoshima201381,
  Title                    = {Multi-moment advection scheme in three dimension for Vlasov simulations of magnetized plasma },
  Author                   = {Takashi Minoshima and Yosuke Matsumoto and Takanobu Amano},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2013},
  Pages                    = {81 - 95},
  Volume                   = {236},

  Abstract                 = {Abstract We present an extension of the multi-moment advection scheme [T. Minoshima, Y. Matsumoto, T. Amano, Multi-moment advection scheme for Vlasov simulations, Journal of Computational Physics 230 (2011) 6800–6823] to the three-dimensional case, for full electromagnetic Vlasov simulations of magnetized plasma. The scheme treats not only point values of a profile but also its zeroth to second order piecewise moments as dependent variables, and advances them on the basis of their governing equations. Similar to the two-dimensional scheme, the three-dimensional scheme can accurately solve the solid body rotation problem of a gaussian profile with little numerical dispersion or diffusion. This is a very important property for Vlasov simulations of magnetized plasma. We apply the scheme to electromagnetic Vlasov simulations. Propagation of linear waves and nonlinear evolution of the electron temperature anisotropy instability are successfully simulated with a good accuracy of the energy conservation. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2012.11.024},
  ISSN                     = {0021-9991},
  Keywords                 = {Advection equation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999112007048}
}

@Article{Mittal20161065,
  Title                    = {Computational modeling of cardiac hemodynamics: Current status and future outlook },
  Author                   = {Rajat Mittal and Jung Hee Seo and Vijay Vedula and Young J. Choi and Hang Liu and H. Howie Huang and Saurabh Jain and Laurent Younes and Theodore Abraham and Richard T. George},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2016},
  Pages                    = {1065 - 1082},
  Volume                   = {305},

  Abstract                 = {Abstract The proliferation of four-dimensional imaging technologies, increasing computational speeds, improved simulation algorithms, and the widespread availability of powerful computing platforms is enabling simulations of cardiac hemodynamics with unprecedented speed and fidelity. Since cardiovascular disease is intimately linked to cardiovascular hemodynamics, accurate assessment of the patient's hemodynamic state is critical for the diagnosis and treatment of heart disease. Unfortunately, while a variety of invasive and non-invasive approaches for measuring cardiac hemodynamics are in widespread use, they still only provide an incomplete picture of the hemodynamic state of a patient. In this context, computational modeling of cardiac hemodynamics presents as a powerful non-invasive modality that can fill this information gap, and significantly impact the diagnosis as well as the treatment of cardiac disease. This article reviews the current status of this field as well as the emerging trends and challenges in cardiovascular health, computing, modeling and simulation and that are expected to play a key role in its future development. Some recent advances in modeling and simulations of cardiac flow are described by using examples from our own work as well as the research of other groups. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2015.11.022},
  ISSN                     = {0021-9991},
  Keywords                 = {Hemodynamics},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999115007627}
}

@Article{Möller20151433,
  Title                    = {A Case Study on Using a Proto-Application as a Proxy for Code Modernization },
  Author                   = {Nathalie Möller and Eric Petit and Loïc Thébault and Quang Dinh},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {1433 - 1442},
  Volume                   = {51},

  Abstract                 = {Abstract To take full advantage of future \{HPC\} systems, hybrid parallelization strategies are required. In a previous work, we demonstrated the Divide and Conquer, D&amp;C, approach for efficient parallelization of finite element methods on unstructured meshes. In this paper we experiment the concept of proto-application as a proxy between computer scientists and application de- velopers on a real industrial use-case. The D&amp;C library has been entirely developed on the proto-application and then validated on the original application. We also ported the D&amp;C library to another fluid dynamic application, AETHER, developed by Dassault Aviation. The results show that the speed-up validated on the proto-application can be reproduced on other full scale applications using similar computational patterns. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.333},
  ISSN                     = {1877-0509},
  Keywords                 = {Proto-application},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915011412}
}

@Article{Moore20112096,
  Title                    = {User-defined events for hardware performance monitoring },
  Author                   = {Shirley Moore and James Ralph},
  Journal                  = {Procedia Computer Science },
  Year                     = {2011},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2011 },
  Pages                    = {2096 - 2104},
  Volume                   = {4},

  Abstract                 = {\{PAPI\} is a widely used cross-platform interface to hardware performance counters. \{PAPI\} currently supports native events, which are those provided by a given platform, and preset events, which are pre-defined events thought to be common across platforms. Presets are currently mapped and defined at the time that \{PAPI\} is compiled and installed. The idea of user-defined events is to allow users to define their own metrics and to have those metrics mapped to events on a platform without the need to re-install PAPI. User-defined events can be defined in terms of native, preset, and previously defined user-defined events. The user can combine events and constants in an arbitrary expression to define a new metric and give a name to the new metric. This name can then be specified as a \{PAPI\} event in a \{PAPI\} library call the same way as native and preset events. End-user tools such as \{TAU\} and Scalasca that use \{PAPI\} can also use the user-defined metrics. Users can publish their metric definitions so that other users can use them as well. We present several examples of how user-defined events can be used for performance analysis and modeling. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2011.04.229},
  ISSN                     = {1877-0509},
  Keywords                 = {Hardware counters},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050911002870}
}

@Article{Mosby2016,
  Title                    = {Computational homogenization at extreme scales },
  Author                   = {Matthew Mosby and Karel Matouš},
  Journal                  = {Extreme Mechanics Letters },
  Year                     = {2016},
  Pages                    = {68 - 74},
  Volume                   = {6},

  Abstract                 = {Abstract Multi-scale simulations at extreme scales in terms of both physical length scales and computational resources are presented. In this letter, we introduce a hierarchically parallel computational homogenization solver that employs hundreds of thousands of computing cores and resolves O ( 10 5 ) in material length scales (from O ( cm ) to O ( 100 nm ) ). Simulations of this kind are important in understanding the multi-scale essence of many natural and synthetically made materials. Thus, we present a simulation consisting of 53.8 Billion finite elements with 28.1 Billion nonlinear equations that is solved on 393,216 computing cores (786,432 threads). The excellent parallel performance of the computational homogenization solver is demonstrated by a strong scaling test from 4,096 to 262,144 cores. A fully coupled multi-scale damage simulation shows a complex crack profile at the micro-scale and the macroscopic crack tunneling phenomenon. Such large and predictive simulations are an important step towards Virtual Materials Testing and can aid in development of new material formulations with extreme properties. Furthermore, the high computational efficiency of our computational homogenization solver holds great promise for utilizing the next generation of exascale parallel computing platforms that are expected to accelerate computations through orders of magnitude increase in parallelism rather than speed of each processor. },
  Doi                      = {http://dx.doi.org/10.1016/j.eml.2015.12.009},
  ISSN                     = {2352-4316},
  Keywords                 = {Computational homogenization},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S2352431615300134}
}

@Article{Mosby2016,
  Title                    = {Computational homogenization at extreme scales },
  Author                   = {Matthew Mosby and Karel Matouš},
  Journal                  = {Extreme Mechanics Letters },
  Year                     = {2016},
  Pages                    = {68 - 74},
  Volume                   = {6},

  Abstract                 = {Abstract Multi-scale simulations at extreme scales in terms of both physical length scales and computational resources are presented. In this letter, we introduce a hierarchically parallel computational homogenization solver that employs hundreds of thousands of computing cores and resolves O ( 10 5 ) in material length scales (from O ( cm ) to O ( 100 nm ) ). Simulations of this kind are important in understanding the multi-scale essence of many natural and synthetically made materials. Thus, we present a simulation consisting of 53.8 Billion finite elements with 28.1 Billion nonlinear equations that is solved on 393,216 computing cores (786,432 threads). The excellent parallel performance of the computational homogenization solver is demonstrated by a strong scaling test from 4,096 to 262,144 cores. A fully coupled multi-scale damage simulation shows a complex crack profile at the micro-scale and the macroscopic crack tunneling phenomenon. Such large and predictive simulations are an important step towards Virtual Materials Testing and can aid in development of new material formulations with extreme properties. Furthermore, the high computational efficiency of our computational homogenization solver holds great promise for utilizing the next generation of exascale parallel computing platforms that are expected to accelerate computations through orders of magnitude increase in parallelism rather than speed of each processor. },
  Doi                      = {http://dx.doi.org/10.1016/j.eml.2015.12.009},
  ISSN                     = {2352-4316},
  Keywords                 = {Computational homogenization},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S2352431615300134}
}

@Article{Muranushi20151303,
  Title                    = {Optimal Temporal Blocking for Stencil Computation },
  Author                   = {Takayuki Muranushi and Junichiro Makino},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {1303 - 1312},
  Volume                   = {51},

  Abstract                 = {Abstract Temporal blocking is a class of algorithms which reduces the required memory bandwidth (B/F ratio) of a given stencil computation, by “blocking” multiple time steps. In this paper, we prove that a lower limit exists for the reduction of the B/F attainable by temporal blocking, under certain conditions. We introduce the PiTCH tiling, an example of temporal blocking method that achieves the optimal B/F ratio. We estimate the performance of PiTCH tiling for various stencil applications on several modern CPUs. We show that PiTCH tiling achieves 1.5&lt;2 times better B/F reduction in three-dimensional applications, compared to other temporal blocking schemes. We also show that PiTCH tiling can remove the bandwidth bottleneck from most of the stencil applications considered. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.315},
  ISSN                     = {1877-0509},
  Keywords                 = {Parallel computation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915011230}
}

@Article{Murugan2013,
  Title                    = {On the interconnect energy efficiency of high end computing systems },
  Author                   = {Muthukumar Murugan and David Hung Chang Du and Krishna Kant},
  Journal                  = {Sustainable Computing: Informatics and Systems },
  Year                     = {2013},
  Number                   = {2},
  Pages                    = {49 - 57},
  Volume                   = {3},

  Abstract                 = {High performance computing systems are moving towards the exaflops era. The tremendous increase in computational speed is accompanied by enormous power consumption in these systems. It is necessary to harvest any potential opportunities to save power in these high end computing systems. The goal of this paper is to explore possibilities of power savings in the interconnects between the nodes. By careful scheduling of jobs in a 3D torus-connected cluster of nodes, we show that significant amounts of power can be saved by switching certain portions of the network elements to low power modes. We also present an estimation method that more accurately estimates the actual runtime of jobs from the user provided runtimes and enhances the performance of the scheduling scheme. We validate our results via detailed \{MATLAB\} simulations. },
  Doi                      = {http://dx.doi.org/10.1016/j.suscom.2012.03.002},
  ISSN                     = {2210-5379},
  Keywords                 = {Green HPC},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S2210537912000194}
}

@Article{Murugan201349,
  Title                    = {On the interconnect energy efficiency of high end computing systems },
  Author                   = {Muthukumar Murugan and David Hung Chang Du and Krishna Kant},
  Journal                  = {Sustainable Computing: Informatics and Systems },
  Year                     = {2013},
  Number                   = {2},
  Pages                    = {49 - 57},
  Volume                   = {3},

  Abstract                 = {High performance computing systems are moving towards the exaflops era. The tremendous increase in computational speed is accompanied by enormous power consumption in these systems. It is necessary to harvest any potential opportunities to save power in these high end computing systems. The goal of this paper is to explore possibilities of power savings in the interconnects between the nodes. By careful scheduling of jobs in a 3D torus-connected cluster of nodes, we show that significant amounts of power can be saved by switching certain portions of the network elements to low power modes. We also present an estimation method that more accurately estimates the actual runtime of jobs from the user provided runtimes and enhances the performance of the scheduling scheme. We validate our results via detailed \{MATLAB\} simulations. },
  Doi                      = {http://dx.doi.org/10.1016/j.suscom.2012.03.002},
  ISSN                     = {2210-5379},
  Keywords                 = {Green HPC},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S2210537912000194}
}

@Article{Nakajima20131265,
  Title                    = {Large-scale Simulations of 3D Groundwater Flow Using Parallel Geometric Multigrid Method },
  Author                   = {Kengo Nakajima},
  Journal                  = {Procedia Computer Science },
  Year                     = {2013},
  Note                     = {2013 International Conference on Computational Science },
  Pages                    = {1265 - 1274},
  Volume                   = {18},

  Abstract                 = {Abstract The multigrid method used with OpenMP/MPI hybrid parallel programming models is expected to play an important role in large-scale scientific computing on post-peta/exa-scale supercomputer systems. In the present work, the effect of sparse matrix storage formats on the performance of parallel geometric multigrid solvers was evaluated, and a new data structure for the Ellpack-Itpack (ELL) format is proposed. The proposed method is implemented for pGW3D-FVM, a parallel code for 3D groundwater flow simulations using the multigrid method, and the robustness and performance of the code was evaluated on up to 4,096 nodes (65,536 cores) of the Fujistu \{FX10\} supercomputer system at the University of Tokyo. The parallel multigrid solver using the \{ELL\} format with coarse grid aggregation provided excellent performance improvement in both weak scaling (13%–35%) and strong scaling (40%–70%) compared to the original code using the \{CRS\} format. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2013.05.293},
  ISSN                     = {1877-0509},
  Keywords                 = {Groudwater Simulations},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050913004365}
}

@Article{Nakashima2015,
  Title                    = {Manycore challenge in particle-in-cell simulation: How to exploit 1 \{TFlops\} peak performance for simulation codes with irregular computation },
  Author                   = {Hiroshi Nakashima},
  Journal                  = {Computers \& Electrical Engineering },
  Year                     = {2015},
  Pages                    = {81 - 94},
  Volume                   = {46},

  Abstract                 = {Abstract This paper discusses the challenge in post-Peta and Exascale era especially that brought by manycore processors of ordinary (i.e., non-GPU type) \{CPU\} cores. Though such a processor like Intel Xeon Phi gives us TFlops-class computational power and may lead us to Exascale computing, full exploitation of its potential is far from an easy job due to its source of high performance, namely a large scale multithreading and a wide \{SIMD\} mechanism. In fact, in the three-tier parallelism namely inter-node, intra-node and intra-core ones, we found their order does not represent the toughness in \{HPC\} programming but the order should be reversed to do that. Our case study with a particle-in-cell plasma simulation code supports our observation revealing that a simple porting of an existing code to Xeon Phi is infeasible from the viewpoint of performance and we have to make a significant change of the code structure so that it conforms with the features of the processor. However the study also confirms that the recoding effort is well rewarded achieving a good single-node performance higher than that obtained from an execution on four dual-socket nodes of Cray XE6. },
  Doi                      = {http://dx.doi.org/10.1016/j.compeleceng.2015.03.010},
  ISSN                     = {0045-7906},
  Keywords                 = {Manycore processors},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S004579061500097X}
}

@Article{Nakashim2015,
  Title                    = {Manycore challenge in particle-in-cell simulation: How to exploit 1 \{TFlops\} peak performance for simulation codes with irregular computation },
  Author                   = {Hiroshi Nakashima},
  Journal                  = {Computers \& Electrical Engineering },
  Year                     = {2015},
  Pages                    = {81 - 94},
  Volume                   = {46},

  Abstract                 = {Abstract This paper discusses the challenge in post-Peta and Exascale era especially that brought by manycore processors of ordinary (i.e., non-GPU type) \{CPU\} cores. Though such a processor like Intel Xeon Phi gives us TFlops-class computational power and may lead us to Exascale computing, full exploitation of its potential is far from an easy job due to its source of high performance, namely a large scale multithreading and a wide \{SIMD\} mechanism. In fact, in the three-tier parallelism namely inter-node, intra-node and intra-core ones, we found their order does not represent the toughness in \{HPC\} programming but the order should be reversed to do that. Our case study with a particle-in-cell plasma simulation code supports our observation revealing that a simple porting of an existing code to Xeon Phi is infeasible from the viewpoint of performance and we have to make a significant change of the code structure so that it conforms with the features of the processor. However the study also confirms that the recoding effort is well rewarded achieving a good single-node performance higher than that obtained from an execution on four dual-socket nodes of Cray XE6. },
  Doi                      = {http://dx.doi.org/10.1016/j.compeleceng.2015.03.010},
  ISSN                     = {0045-7906},
  Keywords                 = {Manycore processors},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S004579061500097X}
}

@Article{Narang20114212,
  Title                    = {Performance driven distributed scheduling of parallel hybrid computations },
  Author                   = {Ankur Narang and Rudrapatna K. Shyamasundar},
  Journal                  = {Theoretical Computer Science },
  Year                     = {2011},
  Note                     = {Algorithms and Computation },
  Number                   = {32},
  Pages                    = {4212 - 4225},
  Volume                   = {412},

  Abstract                 = {Exascale computing is fast becoming a mainstream research area. In order to realize exascale performance, it is necessary to have efficient scheduling of large parallel computations with scalable performance on a large number of cores/processors. The scheduler needs to execute in a pure distributed and online fashion, should follow affinity inherent in the computation and must have low time and message complexity. Further, it should also avoid physical deadlocks due to bounded resources including space/memory per core. Simultaneous consideration of these factors makes affinity driven distributed scheduling particularly challenging. We attempt to address this challenge for hybrid parallel computations which contain tasks that have pre-specified affinity to a place and also tasks that can be mapped to any place in the system. Specifically, we address two scheduling problems of the type P m | M j , p r e c | C max . This paper presents online distributed scheduling algorithms for hybrid parallel computations assuming both unconstrained and bounded space per place. We also present the time and message complexity for distributed scheduling of hybrid computations. To the best of our knowledge, this is the first time that distributed scheduling algorithms for hybrid parallel computations have been presented and analyzed for time and message bounds under both unconstrained space and bounded space. },
  Doi                      = {http://dx.doi.org/10.1016/j.tcs.2010.11.044},
  ISSN                     = {0304-3975},
  Keywords                 = {Distributed scheduling},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0304397510006821}
}

@Article{Neumann2015795,
  Title                    = {Dynamically adaptive Lattice Boltzmann simulation of shallow water flows with the Peano framework },
  Author                   = {Philipp Neumann and Hans-Joachim Bungartz},
  Journal                  = {Applied Mathematics and Computation },
  Year                     = {2015},
  Note                     = {The Fourth European Seminar on Computing (ESCO 2014) },
  Pages                    = {795 - 804},
  Volume                   = {267},

  Abstract                 = {Abstract We present a dynamically adaptive Lattice Boltzmann (LB) implementation for solving the shallow water equations (SWEs). Our implementation extends an existing \{LB\} component of the Peano framework. We revise the modular design with respect to the incorporation of new simulation aspects and \{LB\} models. The basic SWE-LB implementation is validated in different breaking dam scenarios. We further provide a numerical study on stability of the \{MRT\} collision operator used in our simulations. },
  Doi                      = {http://dx.doi.org/10.1016/j.amc.2014.10.049},
  ISSN                     = {0096-3003},
  Keywords                 = {Shallow water},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0096300314014155}
}

@Article{Newman20152086,
  Title                    = {High-Order/Low-Order Methods for Ocean Modeling },
  Author                   = {Christopher Newman and Geoff Womeldorff and Luis Chacón and Dana A. Knoll},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {2086 - 2096},
  Volume                   = {51},

  Abstract                 = {Abstract We examine a High Order/Low Order (HOLO) approach for a z-level ocean model and show that the traditional semi-implicit and split-explicit methods, as well as a recent preconditioning strategy, can easily be cast in the framework of \{HOLO\} methods. The \{HOLO\} formulation admits an implicit-explicit method that is algorithmically scalable and second-order accurate, allowing timesteps much larger than the barotropic time scale. We show how \{HOLO\} approaches, in particular the implicit-explicit method, can provide a solid route for ocean simulation to heterogeneous computing and exascale environments. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.477},
  ISSN                     = {1877-0509},
  Keywords                 = {\{HOLO\} methods},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915012855}
}

@Article{Newman2016877,
  Title                    = {A communication-avoiding implicit–explicit method for a free-surface ocean model },
  Author                   = {Christopher Newman and Geoffrey Womeldorff and Dana A. Knoll and Luis Chacón},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2016},
  Pages                    = {877 - 894},
  Volume                   = {305},

  Abstract                 = {Abstract We examine a nonlinear elimination method for the free-surface ocean equations based on barotropic–baroclinic decomposition. The two dimensional scalar continuity equation is treated implicitly with a preconditioned Jacobian-free Newton–Krylov method (JFNK). The remaining three dimensional equations are subcycled explicitly within the \{JFNK\} residual evaluation with a method known as nonlinear elimination. In this approach, the memory footprint of the underlying Krylov vector is greatly reduced over that required by fully coupled implicit methods. The method is second-order accurate and scales algorithmically, with allowed timesteps much larger than fully explicit methods. Moreover, the hierarchical nature of the algorithm lends itself readily to emerging architectures. In particular, we introduce a communication staging strategy for the three dimensional explicit system that greatly reduces the communication costs of the algorithm and provides a key advantage as communication costs continue to dominate relative to floating point costs in emerging architectures. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2015.11.008},
  ISSN                     = {0021-9991},
  Keywords                 = {Ocean modeling},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999115007482}
}

@Article{Nicolae2013698,
  Title                    = {BlobCR: Virtual disk based checkpoint-restart for \{HPC\} applications on IaaS clouds },
  Author                   = {Bogdan Nicolae and Franck Cappello},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2013},
  Number                   = {5},
  Pages                    = {698 - 711},
  Volume                   = {73},

  Abstract                 = {Infrastructure-as-a-Service (IaaS) cloud computing is gaining significant interest in industry and academia as an alternative platform for running \{HPC\} applications. Given the need to provide fault tolerance, support for suspend–resume and offline migration, an efficient Checkpoint-Restart mechanism becomes paramount in this context. We propose BlobCR, a dedicated checkpoint repository that is able to take live incremental snapshots of the whole disk attached to the virtual machine (VM) instances. BlobCR aims to minimize the performance overhead of checkpointing by persisting \{VM\} disk snapshots asynchronously in the background using a low overhead technique we call selective copy-on-write. It includes support for both application-level and process-level checkpointing, as well as support to roll back filesystem changes. Experiments at large scale demonstrate the benefits of our proposal both in synthetic settings and for a real-life \{HPC\} application. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2013.01.013},
  ISSN                     = {0743-7315},
  Keywords                 = {IaaS clouds},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731513000142}
}

@Article{Nicolae201667,
  Title                    = {Towards scalable on-demand collective data access in IaaS clouds: An adaptive collaborative content exchange proposal },
  Author                   = {Bogdan Nicolae and Andrzej Kochut and Alexei Karve},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2016},
  Pages                    = {67 - 79},
  Volume                   = {87},

  Abstract                 = {Abstract A critical feature of IaaS cloud computing is the ability to quickly disseminate the content of a shared dataset at large scale. In this context, a common pattern is collective read, i.e., accessing the same \{VM\} image or dataset from a large number of \{VM\} instances concurrently. Several approaches deal with this pattern either by means of pre-broadcast before access or on-demand concurrent access to the repository where the image or dataset is stored. We propose a different solution using a hybrid strategy that augments on-demand access with a collaborative scheme in which the \{VMs\} leverage similarities between their access pattern in order to anticipate future read accesses and exchange chunks between themselves in order to reduce contention to the remote repository. Large scale experiments show significant improvement over conventional approaches from multiple perspectives: completion time, sustained read throughput, fairness of I/O read operations and bandwidth utilization. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2015.09.006},
  ISSN                     = {0743-7315},
  Keywords                 = {IaaS},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731515001732}
}

@Article{Nikolaou20143085,
  Title                    = {Evaluation of a reduced mechanism for turbulent premixed combustion },
  Author                   = {Zacharias M. Nikolaou and Nedunchezhian Swaminathan and Jyh-Yuan Chen},
  Journal                  = {Combustion and Flame },
  Year                     = {2014},
  Number                   = {12},
  Pages                    = {3085 - 3099},
  Volume                   = {161},

  Abstract                 = {Abstract In this study, 3D direct numerical simulations of a multi-component fuel consisting of \{CO\} , H 2 , H 2 O , \{CO\} 2 and \{CH4\} reacting with air are performed. A freely propagating turbulent premixed stoichiometric flame is simulated for both low and high turbulence conditions i.e., the rms values of turbulent velocity fluctuations normalised by the laminar flame speed are of order 1 and 10. A skeletal mechanism involving 49 reactions and 15 species, and a 5-step reduced mechanism with 9 species, are used in order to evaluate the performance of the reduced mechanism under turbulent conditions. The 5-step mechanism incurs significantly lower computational expenses compared to the skeletal mechanism. The majority of species mean mass fractions and mean reaction rates computed using these two mechanisms are in good agreement with one another. The mean progress variable and heat release rate variations across the flame brush are also recovered by the reduced mechanism. No major differences are observed in flame response to curvature or strain effects induced by turbulence, although some differences are observed in instantaneous flame structure. These differences are studied using a correlation coefficient and detailed analysis suggests that this comes from the fluctuating heat release induced effects in the case with higher turbulence level. Further considerations based on instantaneous reaction rate and local displacement speed are discussed to evaluate the suitability of the reduced mechanism. },
  Doi                      = {http://dx.doi.org/10.1016/j.combustflame.2014.06.013},
  ISSN                     = {0010-2180},
  Keywords                 = {Direct numerical simulation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010218014001916}
}

@Article{Norman2015,
  Title                    = {Developing A Large Time Step, Robust, and Low Communication Multi-Moment \{PDE\} Integration Scheme for Exascale Applications },
  Author                   = {Matthew R. Norman},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {1848 - 1857},
  Volume                   = {51},

  Abstract                 = {Abstract The Boundary Averaged Multi-moment Constrained finite-Volume (BA-MCV) method is de- rived, explained, and evaluated for 1-D transport to assess accuracy, maximum stable time step (MSTS), oscillations for discontinuous data, and parallel communication burden. The BA-MCV scheme is altered from the original \{MCV\} scheme to compute the updates of point wise cell boundary derivatives entirely locally. Then it is altered such that boundary moments are replaced with the interface upwind value. The scheme is stable at a maximum stable \{CFL\} (MSCFL) value of one no matter how high-order the scheme is, giving significantly larger time steps than Galerkin methods, for which the \{MSCFL\} decreases nearly quadratically with in- creasing order. The BA-MCV method is compared against a \{SE\} method at varying order, both using the ADER-DT time discretization. BA-MCV error for a sine wave was comparable to the same order of accuracy for a \{SE\} method. The resulting large time step, multi-moment, low communication scheme is of great interest for exascale architectures. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.413},
  ISSN                     = {1877-0509},
  Keywords                 = {MCV},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915012211}
}

@Article{Norman20151848,
  Title                    = {Developing A Large Time Step, Robust, and Low Communication Multi-Moment \{PDE\} Integration Scheme for Exascale Applications },
  Author                   = {Matthew R. Norman},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {1848 - 1857},
  Volume                   = {51},

  Abstract                 = {Abstract The Boundary Averaged Multi-moment Constrained finite-Volume (BA-MCV) method is de- rived, explained, and evaluated for 1-D transport to assess accuracy, maximum stable time step (MSTS), oscillations for discontinuous data, and parallel communication burden. The BA-MCV scheme is altered from the original \{MCV\} scheme to compute the updates of point wise cell boundary derivatives entirely locally. Then it is altered such that boundary moments are replaced with the interface upwind value. The scheme is stable at a maximum stable \{CFL\} (MSCFL) value of one no matter how high-order the scheme is, giving significantly larger time steps than Galerkin methods, for which the \{MSCFL\} decreases nearly quadratically with in- creasing order. The BA-MCV method is compared against a \{SE\} method at varying order, both using the ADER-DT time discretization. BA-MCV error for a sine wave was comparable to the same order of accuracy for a \{SE\} method. The resulting large time step, multi-moment, low communication scheme is of great interest for exascale architectures. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.413},
  ISSN                     = {1877-0509},
  Keywords                 = {MCV},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915012211}
}

@Article{Notay2015237,
  Title                    = {A massively parallel solver for discrete Poisson-like problems },
  Author                   = {Yvan Notay and Artem Napov},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2015},
  Pages                    = {237 - 250},
  Volume                   = {281},

  Abstract                 = {Abstract The paper considers the parallel implementation of an algebraic multigrid method. The sequential version is well suited to solve linear systems arising from the discretization of scalar elliptic PDEs. It is scalable in the sense that the time needed to solve a system is (under known conditions) proportional to the number of unknowns. The associate software code is also robust and often significantly faster than other algebraic multigrid solvers. The present work addresses the challenge of porting it on massively parallel computers. In this view, some critical components are redesigned, in a relatively simple yet not straightforward way. Thanks to this, excellent weak scalability results are obtained on three petascale machines among the most powerful today available. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2014.10.043},
  ISSN                     = {0021-9991},
  Keywords                 = {Parallel computation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999114007256}
}

@Article{Novotny201290,
  Title                    = {Dynamics of a Single Spin-1/2 Coupled to x- and y-Spin Baths: Algorithm and Results },
  Author                   = {M.A. Novotny and Marta L. Guerra and Hans De Raedt and Kristel Michielsen and Fengping Jin},
  Journal                  = {Physics Procedia },
  Year                     = {2012},
  Note                     = {Proceedings of the 25th Workshop on Computer Simulation Studies in Condensed Matter Physics },
  Pages                    = {90 - 99},
  Volume                   = {34},

  Abstract                 = {The real-time dynamics of a single spin-1/2 particle, called the central spin, coupled to the x(y)-components of the spins of one or more baths is simulated. The bath Hamiltonians contain interactions of x(y)-components of the bath spins only but are general otherwise. An efficient algorithm is described which allows solving the time-dependent Schr’odinger equation for the central spin, even if the x(y) baths contain hundreds of spins. The algorithm requires storage for 2 × 2 matrices only, no matter how many spins are in the baths. We calculate the expectation value of the central spin, as well as its von Neumann entropy S(t), the quantum purity P(t), and the off-diagonal elements of the quantum density matrix. In the case of coupling the central spin to both x- and y- baths the relaxation of S(t) and P(t) with time is a power law, compared to an exponential if the central spin is only coupled to an x-bath. The effect of different initial states for the central spin and bath is studied. Comparison with more general spin baths is also presented. },
  Doi                      = {http://dx.doi.org/10.1016/j.phpro.2012.05.015},
  ISSN                     = {1875-3892},
  Keywords                 = {Quantum Dynamics},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1875389212013284}
}

@Article{Núñez201212,
  Title                    = {SIMCAN: A flexible, scalable and expandable simulation platform for modelling and simulating distributed architectures and applications },
  Author                   = {Alberto Núñez and Javier Fernández and Rosa Filgueira and Félix García and Jesús Carretero},
  Journal                  = {Simulation Modelling Practice and Theory },
  Year                     = {2012},
  Number                   = {1},
  Pages                    = {12 - 32},
  Volume                   = {20},

  Abstract                 = {In this paper we propose a new simulation platform called SIMCAN, for analyzing parallel and distributed systems. This platform is aimed to test parallel and distributed architectures and applications. The main characteristics of \{SIMCAN\} are flexibility, accuracy, performance, and scalability. Thence, the proposed platform has a modular design that eases the integration of different basic systems on a single architecture. Its design follows a hierarchical schema that includes simple modules, basic systems (computing, memory managing, I/O, and networking), physical components (nodes, switches, …), and aggregations of components. New modules may also be incorporated as well to include new strategies and components. Also, a graphical configuration tool has been developed to help untrained users with the task of modelling new architectures. Finally, a validation process and some evaluation tests have been performed to evaluate the \{SIMCAN\} platform. },
  Doi                      = {http://dx.doi.org/10.1016/j.simpat.2011.08.009},
  ISSN                     = {1569-190X},
  Keywords                 = {Distributed system simulation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1569190X11001432}
}

@Article{Ohno20142575,
  Title                    = {Petascale molecular dynamics simulation using the fast multipole method on K computer },
  Author                   = {Yousuke Ohno and Rio Yokota and Hiroshi Koyama and Gentaro Morimoto and Aki Hasegawa and Gen Masumoto and Noriaki Okimoto and Yoshinori Hirano and Huda Ibeid and Tetsu Narumi and Makoto Taiji},
  Journal                  = {Computer Physics Communications },
  Year                     = {2014},
  Number                   = {10},
  Pages                    = {2575 - 2585},
  Volume                   = {185},

  Abstract                 = {Abstract In this paper, we report all-atom simulations of molecular crowding — a result from the full node simulation on the “K computer”, which is a 10-PFLOPS supercomputer in Japan. The capability of this machine enables us to perform simulation of crowded cellular environments, which are more realistic compared to conventional \{MD\} simulations where proteins are simulated in isolation. Living cells are “crowded” because macromolecules comprise ∼30% of their molecular weight. Recently, the effects of crowded cellular environments on protein stability have been revealed through in-cell \{NMR\} spectroscopy. To measure the performance of the “K computer”, we performed all-atom classical molecular dynamics simulations of two systems: target proteins in a solvent, and target proteins in an environment of molecular crowders that mimic the conditions of a living cell. Using the full system, we achieved 4.4 \{PFLOPS\} during a 520 million-atom simulation with cutoff of 28 Å. Furthermore, we discuss the performance and scaling of fast multipole methods for molecular dynamics simulations on the “K computer”, as well as comparisons with Ewald summation methods. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2014.06.004},
  ISSN                     = {0010-4655},
  Keywords                 = {Molecular dynamics},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465514002082}
}

@Article{Oliker2011499,
  Title                    = {Emerging programming paradigms for large-scale scientific computing },
  Author                   = {Leonid Oliker and Rajesh Nishtala and Rupak Biswas},
  Journal                  = {Parallel Computing },
  Year                     = {2011},
  Note                     = {Emerging Programming Paradigms for Large-Scale Scientific Computing },
  Number                   = {9},
  Pages                    = {499 - 500},
  Volume                   = {37},

  Doi                      = {http://dx.doi.org/10.1016/j.parco.2011.07.002},
  ISSN                     = {0167-8191},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819111000883}
}

@InCollection{Onishi2014,
  Title                    = {Optimized preprocessing of tens of billions of grids in a full-vehicle aerodynamic simulation on the K-computer },
  Author                   = {K. Onishi and M. Tsubokura},
  Booktitle                = {The International Vehicle Aerodynamics Conference },
  Publisher                = {Woodhead Publishing},
  Year                     = {2014},

  Address                  = {Oxford},
  Editor                   = {Park, Holywell },
  Pages                    = {149 - 158},

  Abstract                 = {\{ABSTRACT\} A vehicle aerodynamics simulation was conducted using 2.3 billion elements of an unstructured grid and 19 billion elements of a Cartesian grid with dirty computeraided-design data on the supercomputer K-computer. This methodology allows the user to avoid a large amount of manual work in preparing computational grids was developed using a mesh refinement technique and immersed boundary method. This methodology was indispensable in conducting fine-resolution analysis in a massively parallel environment. The calculation results show that the method was successfully adopted for full-vehicle aerodynamics and that the accuracy of drag prediction can be improved using fine grid resolution. },
  Doi                      = {http://dx.doi.org/10.1533/9780081002452.4.149},
  ISBN                     = {978-0-08-100199-8},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780081001998500137}
}

@Article{Ono20142336,
  Title                    = {Data Centric Framework for Large-scale High-performance Parallel Computation },
  Author                   = {Kenji Ono and Yasuhiro Kawashima and Tomohiro Kawanabe},
  Journal                  = {Procedia Computer Science },
  Year                     = {2014},
  Note                     = {2014 International Conference on Computational Science },
  Pages                    = {2336 - 2350},
  Volume                   = {29},

  Abstract                 = {Abstract Supercomputer architectures are being upgraded using different level of parallelism to improve computing performance. This makes it difficult for scientists to develop high performance code in a short time. From the viewpoint of productivity and software life cycle, a concise yet effective infrastructure is required to achieve parallel processing. In this paper, we propose a usable building block framework to build parallel applications on large-scale Cartesian data structures. The proposed framework is designed such that each process in a simulation cycle can easily access the generated data files with usable functions. This framework enables us to describe parallel applications with fewer lines of source code, and hence, it contributes to the productivity of the software. Further, this framework was considered for improving performance, and it was confirmed that the developed flow simulator based on this framework demonstrated considerably excellent weak scaling performance on the K computer. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2014.05.218},
  ISSN                     = {1877-0509},
  Keywords                 = {Domain Decomposition},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050914003950}
}

@InCollection{Oriato2015105,
  Title                    = {Chapter Three - Dataflow Computing in Extreme Performance Conditions },
  Author                   = {Diego Oriato and Stephen Girdlestone and Oskar Mencer},
  Booktitle                = {Dataflow Processing},
  Publisher                = {Elsevier},
  Year                     = {2015},
  Editor                   = {Ali R. Hurson and Veljko Milutinovic},
  Pages                    = {105 - 137},
  Series                   = {Advances in Computers },
  Volume                   = {96},

  Abstract                 = {Abstract Reconfigurable computers, generally based on field programmable gate array technology, have been used successfully as a platform for performance critical applications in a variety of industries. Applications targeted at reconfigurable computers can exploit their fine-grained parallelism, predictable low latency performance and very high data throughput per watt. Traditional techniques for designing configurations are, however, generally considered time consuming and cumbersome and this has limited commercial reconfigurable computer usage. To solve this problem, Maxeler Technologies Ltd, working closely with Imperial College London, have developed powerful new tools and hardware based on the dataflow computing paradigm. In this chapter, we explore these tools and technologies and present a case study on how they have enabled a weather forecast application to be accelerated almost two orders of magnitude compared to conventional widespread technologies. },
  Doi                      = {http://dx.doi.org/10.1016/bs.adcom.2014.11.002},
  ISSN                     = {0065-2458},
  Keywords                 = {Dataflow},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0065245814000072}
}

@Article{Pan2012365,
  Title                    = {Development of Energy-Efficient Cryogenic Leads with High Temperature Superconducting Films on Ceramic Substrates },
  Author                   = {A.V. Pan and S.A. Fedoseev and O.V. Shcherbakova and I.A. Golovchanskiy and S. Zhou and S.X. Dou and R.J. Webber and O.A. Mukhanov and T. Yamashita and R. Taylor},
  Journal                  = {Physics Procedia },
  Year                     = {2012},
  Note                     = {\{SUPERCONDUCTIVITY\} \{CENTENNIAL\} Conference 2011 },
  Pages                    = {365 - 370},
  Volume                   = {36},

  Abstract                 = {High temperature superconductor (HTS) material can be used for the implementation of high-speed low-heat conduction data links to transport digital data from 4 K superconductor integrated circuits to higher-temperature parts of computing systems. In this work, we present a conceptual design of energy efficient interface and results in fabricating such \{HTS\} leads. Initial calculations have shown that the microstrip line cable geometry for typical materials employed in production of \{HTS\} thin films can be a two-layered film for which the two layers of about 10 cm long are separated by an insulation layer with as low permittivity as possible. With this architecture in mind, the pulsed laser deposition process has been designed in a 45 cm diameter vacuum chamber to incorporate an oscillating sample holder with homogeneous substrate heating up to 900°C, while the laser plume is fixed. This design has allowed us to produce 200 nm to 500 nm thick, 7 cm to 10 cm long \{YBa2Cu3O7\} thin films with the homogeneous critical temperature (Tc) of about 90 K. The critical current density (Jc) of the short samples obtained from the long sample is of (2 ± 1) × 1010 A/m2. Lines of 3-100 μm wide have been successfully patterned along the length of the samples in order to directly measure the Tc and Jc values over the entire length of the samples, as well as to attempt the structuring of multichannel data lead prototype. },
  Doi                      = {http://dx.doi.org/10.1016/j.phpro.2012.06.246},
  ISSN                     = {1875-3892},
  Keywords                 = {\{YBCO\} films},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1875389212021839}
}

@Article{Parsani201588,
  Title                    = {Entropy stable wall boundary conditions for the three-dimensional compressible Navier–Stokes equations },
  Author                   = {Matteo Parsani and Mark H. Carpenter and Eric J. Nielsen},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2015},
  Pages                    = {88 - 113},
  Volume                   = {292},

  Abstract                 = {Abstract Non-linear entropy stability and a summation-by-parts framework are used to derive entropy stable wall boundary conditions for the three-dimensional compressible Navier–Stokes equations. A semi-discrete entropy estimate for the entire domain is achieved when the new boundary conditions are coupled with an entropy stable discrete interior operator. The data at the boundary are weakly imposed using a penalty flux approach and a simultaneous-approximation-term penalty technique. Although discontinuous spectral collocation operators on unstructured grids are used herein for the purpose of demonstrating their robustness and efficacy, the new boundary conditions are compatible with any diagonal norm summation-by-parts spatial operator, including finite element, finite difference, finite volume, discontinuous Galerkin, and flux reconstruction/correction procedure via reconstruction schemes. The proposed boundary treatment is tested for three-dimensional subsonic and supersonic flows. The numerical computations corroborate the non-linear stability (entropy stability) and accuracy of the boundary conditions. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2015.03.026},
  ISSN                     = {0021-9991},
  Keywords                 = {Entropy},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999115001734}
}

@Article{Patterson201697,
  Title                    = {A framework for an integrated nuclear digital environment },
  Author                   = {Eann A. Patterson and Richard J. Taylor and Mark Bankhead},
  Journal                  = {Progress in Nuclear Energy },
  Year                     = {2016},
  Pages                    = {97 - 103},
  Volume                   = {87},

  Abstract                 = {Abstract A conceptual framework is proposed for a digital environment extending from the prototype design of nuclear plants through operations and decommissioning to storage and waste disposal. The environment consists of a series of interconnected multi-scale, multi-physics computational models linked to the real-world by data acquired during validation of prototypes, in-service monitoring and inspections of plant, post-shut-down inspections of plant and in-situ monitoring of stored waste. The technology gaps for the implementation of the integrated nuclear digital environment (INDE) are identified and discussed together with the advantages to be gained from its implementation. Implementation of \{INDE\} will be dependent on future advances in High Performance Computing systems approaching the exascale and parallel advances in the development of algorithms for processing large amounts of data. The data itself will be acquired through innovations in measurement, analysis and uncertainty and will be applied through projects relating to lifetime extension, decommissioning and resurgent national science programmes. It is postulated that the existence of this type of framework might be inevitable given both nuclear-specific and non-nuclear drivers and may be essential for the nuclear industry to deliver current and future challenges from the clean-up of legacy waste sites to time and budget, future generation nuclear reactors and small-scale mass-production of modular nuclear power plants. It is proposed that implementation of \{INDE\} will lead to shorten development times, reduced costs and increased credibility, operability, reliability and safety. },
  Doi                      = {http://dx.doi.org/10.1016/j.pnucene.2015.11.009},
  ISSN                     = {0149-1970},
  Keywords                 = {Modelling},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0149197015301104}
}

@Article{Pauli201524,
  Title                    = {Intrinsic fault tolerance of multilevel Monte Carlo methods },
  Author                   = {Stefan Pauli and Peter Arbenz and Christoph Schwab},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2015},
  Pages                    = {24 - 36},
  Volume                   = {84},

  Abstract                 = {Abstract Monte Carlo (MC) and multilevel Monte Carlo (MLMC) methods applied to solvers for Partial Differential Equations with random input data are proved to exhibit intrinsic failure resilience. Sufficient conditions are provided for non-recoverable loss of a random fraction of \{MC\} samples not to fatally damage the asymptotic accuracy versus work of a \{MC\} simulation. Specifically, the convergence behavior of \{MLMC\} methods on massively parallel hardware with runtime faults is analyzed mathematically and investigated computationally. Our mathematical model assumes node failures which occur uncorrelated of \{MC\} sampling and with general sample failure statistics on the different levels and which also assume absence of checkpointing, i.e., we assume irrecoverable sample failures with complete loss of data. Modifications of the \{MLMC\} with enhanced resilience are proposed. The theoretical results are obtained under general statistical models of \{CPU\} failure at runtime. Particular attention is paid to node failures with so-called Weibull failure models on massively parallel stochastic finite volume computational fluid dynamics simulations are discussed. We discuss the resilience of massively parallel stochastic Finite Volume computational fluid dynamics simulations. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2015.07.005},
  ISSN                     = {0743-7315},
  Keywords                 = {Multilevel Monte Carlo},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731515001239}
}

@Article{Peng20131469,
  Title                    = {Scalability study of molecular dynamics simulation on Godson-T many-core architecture },
  Author                   = {Liu Peng and Guangming Tan and Rajiv K. Kalia and Aiichiro Nakano and Priya Vashishta and Dongrui Fan and Hao Zhang and Fenglong Song},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2013},
  Note                     = {Novel architectures for high-performance computing },
  Number                   = {11},
  Pages                    = {1469 - 1482},
  Volume                   = {73},

  Abstract                 = {Molecular dynamics (MD) simulation has broad applications, and an increasing amount of computing power is needed to satisfy the large scale of the real world simulation. The advent of the many-core paradigm brings unprecedented computing power, but it remains a great challenge to harvest the computing power due to MD’s irregular memory-access pattern. To address this challenge, this paper presents a joint application/architecture study to enhance the scalability of \{MD\} on Godson-T-like many-core architecture. First, a preprocessing approach leveraging an adaptive divide-and-conquer framework is designed to exploit locality through memory hierarchy with software controlled memory. Then three incremental optimization strategies–a novel data-layout to improve data locality, an on-chip locality-aware parallel algorithm to enhance data reuse, and a pipelining algorithm to hide latency to shared memory–are proposed to enhance on-chip parallelism for Godson-T many-core processor. Experiments on Godson-T simulator exhibit strong-scaling parallel efficiency of 0.99 on 64 cores, which is confirmed by a field-programmable gate array emulator. Also the performance per watt of \{MD\} on Godson-T is much higher than \{MD\} on a 16-cores Intel core i7 symmetric multiprocessor (SMP) and 26 times higher than \{MD\} on an 8-core 64-thread Sun \{T2\} processor. Detailed analysis shows that optimizations utilizing architectural features to maximize data locality and to enhance data reuse benefit scalability most. Furthermore, a hierarchical parallelization scheme is designed to map the \{MD\} algorithm to Godson-T many-core cluster and a simple performance model is derived, which suggests that the optimization scheme is likely to scale well toward exascale. Certain architectural features are found essential for these optimizations, which could guide future hardware developments. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2012.07.007},
  ISSN                     = {0743-7315},
  Keywords                 = {Molecular dynamics},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731512001682}
}

@Article{Peterson1989,
  Title                    = {Computational challenges in aerospace },
  Author                   = {Victor L. Peterson},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {1989},
  Note                     = {Grand Challenges to Computational Science },
  Number                   = {2–3},
  Pages                    = {243 - 258},
  Volume                   = {5},

  Abstract                 = {Computer speed and memory requirements needed for meeting various computational challenges in human vision modeling, chemistry, turbulence physics research and aerodynamics are discussed and compared with the capabilities of various existing computers and those projected to be available before the mid 1990s. Example results for problems illustrative of those currently being solved in each of the disciplines are also presented. Meeting some of the challenges using currently available solution algorithms is shown to require computer speeds in excess of exaFLOPs (1018 FLOPs) and memories in excess of petawords (1015 words), if problems are to be solved in periods of time currently believed to be acceptable. Even without these levels of computer power, it is shown how work can proceed towards meeting the ultimate challenges by treating stepping-stone problems with complexity increasing to match the computational power available at any point in time. Finally, it is speculated that improvements in algorithms ultimately will reduce these requirements to levels that can be met with computers projected to be available beyond the year 2000. },
  Doi                      = {http://dx.doi.org/10.1016/0167-739X(89)90044-7},
  ISSN                     = {0167-739X},
  Url                      = {http://www.sciencedirect.com/science/article/pii/0167739X89900447}
}

@InCollection{Peukert20151,
  Title                    = {Chapter One - Unified Design Strategies for Particulate Products },
  Author                   = {Wolfgang Peukert and Doris Segets and Lukas Pflug and Günter Leugering},
  Booktitle                = {Mesoscale Modeling in Chemical Engineering Part I},
  Publisher                = {Academic Press},
  Year                     = {2015},
  Editor                   = {Guy B. Marin and Jinghai Li},
  Pages                    = {1 - 81},
  Series                   = {Advances in Chemical Engineering },
  Volume                   = {46},

  Abstract                 = {Abstract Unit operations and product design are the two most important pillars of chemical engineering. Product design is the formation, formulation, handling, manufacturing, and characterization of complex multiphase products with specific properties and is thus at the core of mesoscale science and engineering. The applications define the required product properties which cover both classical fields of process technology in the chemical industry as well as new emerging fields of electronics, energy and environmental technologies, life sciences, materials science and engineering, nanotechnology, and photonic technologies highlighting the broad relevance of mesoscale science. Unifying principles of product design are proposed which are widely applicable to many different kinds of products including solid, liquid, and even gaseous particles. Results from the Erlangen Cluster of Excellence “Engineering of Advanced Materials” show that the joint venture of chemical engineering with materials science in concert with the basic sciences opens new prospects for all involved disciplines. In particular, chemical and biochemical engineering expands through particle technologies also in physics-related fields of technology such as electronics, photonics, or 3D printing. Rigorous mathematical optimization methods based on predictive models for products, structures, and processes catalyze new possibilities for true design of particulate products which is at the core of mesoscale science and technology. },
  Doi                      = {http://dx.doi.org/10.1016/bs.ache.2015.10.004},
  ISSN                     = {0065-2377},
  Keywords                 = {Hierarchical systems},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0065237715000058}
}

@Article{Piątek201540,
  Title                    = {Energy and thermal models for simulation of workload and resource management in computing systems },
  Author                   = {Wojciech Piątek and Ariel Oleksiak and Georges Da Costa},
  Journal                  = {Simulation Modelling Practice and Theory },
  Year                     = {2015},
  Note                     = {Special Issue on \{TECHNIQUES\} \{AND\} \{APPLICATIONS\} \{FOR\} \{SUSTAINABLE\} \{ULTRASCALE\} \{COMPUTING\} \{SYSTEMS\} },
  Pages                    = {40 - 54},
  Volume                   = {58, Part 1},

  Abstract                 = {Abstract In the recent years, we have faced the evolution of high-performance computing (HPC) systems towards higher scale, density and heterogeneity. In particular, hardware vendors along with software providers, \{HPC\} centers, and scientists are struggling with the exascale computing challenge. As the density of both computing power and heat is growing, proper energy and thermal management becomes crucial in terms of overall system efficiency. Moreover, an accurate and relatively fast method to evaluate such large scale computing systems is needed. In this paper we present a way to model energy and thermal behavior of computing system. The proposed model can be used to effectively estimate system performance, energy consumption, and energy-efficiency metrics. We evaluate their accuracy by comparing the values calculated based on these models against the measurements obtained on real hardware. Finally, we show how the proposed models can be applied to workload scheduling and resource management in large scale computing systems by integrating them in the \{DCworms\} simulation framework. },
  Doi                      = {http://dx.doi.org/10.1016/j.simpat.2015.04.008},
  ISSN                     = {1569-190X},
  Keywords                 = {Simulations},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1569190X15000684}
}

@Article{Pilla2014191,
  Title                    = {A topology-aware load balancing algorithm for clustered hierarchical multi-core machines },
  Author                   = {Laércio L. Pilla and Christiane P. Ribeiro and Pierre Coucheney and François Broquedis and Bruno Gaujal and Philippe O.A. Navaux and Jean-François Méhaut},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2014},
  Note                     = {Special Issue on Extreme Scale Parallel Architectures and Systems, Cryptography in Cloud Computing and Recent Advances in Parallel and Distributed Systems, \{ICPADS\} 2012 Selected Papers },
  Pages                    = {191 - 201},
  Volume                   = {30},

  Abstract                 = {Abstract In this paper, we present a topology-aware load balancing algorithm for parallel multi-core machines and its proof of asymptotic convergence to an optimal solution. The algorithm, named HwTopoLB, aims to improve the application performance by reducing core idleness and communication delays. HwTopoLB was designed taking into account the properties of current parallel systems composed of multi-core compute nodes, namely their network interconnection, and their complex and hierarchical core topology. The latter comprises multiple levels of cache, and a memory subsystem with \{NUMA\} design. These systems provide high processing power at the expense of asymmetric communication costs, which can hamper the performance of parallel applications depending on their communication patterns if ignored. Our load balancing algorithm models asymmetries in terms of latencies and bandwidths, representing the distances and communication costs among hardware components. We have implemented HwTopoLB using the Charm++ Parallel Runtime System and evaluated its performance with two different benchmarks and one application. Our experimental results with HwTopoLB exhibit scalability over clustered multi-core compute nodes, and average performance improvements of 23% over execution without load balancers and 19% over the existing load balancing strategies on different multi-core systems. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2013.06.023},
  ISSN                     = {0167-739X},
  Keywords                 = {Load balancing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X13001374}
}

@Article{Planas2015130,
  Title                    = {AMA: Asynchronous Management of Accelerators for Task-based Programming Models },
  Author                   = {Judit Planas and Rosa M. Badia and Eduard Ayguade and Jesus Labarta},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {130 - 139},
  Volume                   = {51},

  Abstract                 = {Abstract Computational science has benefited in the last years from emerging accelerators that increase the performance of scientific simulations, but using these devices hinders the programming task. This paper presents AMA: a set of optimization techniques to efficiently manage multi-accelerator systems. \{AMA\} maximizes the overlap of computation and communication in a blocking-free way. Then, we can use such spare time to do other work while waiting for device operations. Implemented on top of a task-based framework, the experimental evaluation of \{AMA\} on a quad-GPU node shows that we reach the performance of a hand-tuned native \{CUDA\} code, with the advantage of fully hiding the device management. In addition, we obtain up to more than 2x performance speed-up with respect to the original framework implementation. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.212},
  ISSN                     = {1877-0509},
  Keywords                 = {Accelerator management},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915010200}
}

@InProceedings{podkorytov2012agent,
  Title                    = {Agent-based simulation system AGNES* for networks modeling: review and researching},
  Author                   = {Podkorytov, Dmitry and Rodionov, Alexey and Choo, Hyunseung},
  Booktitle                = {Proceedings of the 6th International Conference on Ubiquitous Information Management and Communication},
  Year                     = {2012},
  Organization             = {ACM},
  Pages                    = {115}
}

@Article{Poghosyan2015167,
  Title                    = {Architecture, implementation and parallelization of the software to search for periodic gravitational wave signals },
  Author                   = {G. Poghosyan and S. Matta and A. Streit and M. Bejger and A. Królak},
  Journal                  = {Computer Physics Communications },
  Year                     = {2015},
  Pages                    = {167 - 176},
  Volume                   = {188},

  Abstract                 = {Abstract The parallelization, design and scalability of the PolGrawAllSky code to search for periodic gravitational waves from rotating neutron stars is discussed. The code is based on an efficient implementation of the F -statistic using the Fast Fourier Transform algorithm. To perform an analysis of data from the advanced \{LIGO\} and Virgo gravitational wave detectors’ network, which will start operating in 2015, hundreds of millions of \{CPU\} hours will be required—the code utilizing the potential of massively parallel supercomputers is therefore mandatory. We have parallelized the code using the Message Passing Interface standard, implemented a mechanism for combining the searches at different sky-positions and frequency bands into one extremely scalable program. The parallel I/O interface is used to escape bottlenecks, when writing the generated data into file system. This allowed to develop a highly scalable computation code, which would enable the data analysis at large scales on acceptable time scales. Benchmarking of the code on a Cray \{XE6\} system was performed to show efficiency of our parallelization concept and to demonstrate scaling up to 50 thousand cores in parallel. Program summary Program title: parallel PolGrawAllSky Catalogue identifier: AEUX_v1_0 Program summary URL:http://cpc.cs.qub.ac.uk/summaries/AEUX_v1_0.html Program obtainable from: \{CPC\} Program Library, Queen’s University, Belfast, N. Ireland Licensing provisions: Standard \{CPC\} licence, http://cpc.cs.qub.ac.uk/licence/licence.html No. of lines in distributed program, including test data, etc.: 163747 No. of bytes in distributed program, including test data, etc.: 28989030 Distribution format: tar.gz Programming language: C. Computer: Any parallel computing platform supporting \{MPI\} standard. Operating system: Linux as well any other supporting \{MPI\} standard. Has the code been vectorized or parallelized?: Yes, using MPI. Tested with up to 50208 processors RAM: 1 Gigabyte per parallel task Classification: 1.5. External routines: \{MPI\} v.2 or newer, \{FFTW\} v.3 or newer Nature of problem: Search for periodic gravitational waves from rotating neutron stars. Solution method: The F -statistic method using the Fast Fourier Transform algorithm. Running time: The example provided takes approximately 30 mins with 256 processors. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2014.10.025},
  ISSN                     = {0010-4655},
  Keywords                 = {Parallelization},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465514003774}
}

@Article{Pratapa201643,
  Title                    = {Anderson acceleration of the Jacobi iterative method: An efficient alternative to Krylov methods for large, sparse linear systems },
  Author                   = {Phanisri P. Pratapa and Phanish Suryanarayana and John E. Pask},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2016},
  Pages                    = {43 - 54},
  Volume                   = {306},

  Abstract                 = {Abstract We employ Anderson extrapolation to accelerate the classical Jacobi iterative method for large, sparse linear systems. Specifically, we utilize extrapolation at periodic intervals within the Jacobi iteration to develop the Alternating Anderson–Jacobi (AAJ) method. We verify the accuracy and efficacy of \{AAJ\} in a range of test cases, including nonsymmetric systems of equations. We demonstrate that \{AAJ\} possesses a favorable scaling with system size that is accompanied by a small prefactor, even in the absence of a preconditioner. In particular, we show that \{AAJ\} is able to accelerate the classical Jacobi iteration by over four orders of magnitude, with speed-ups that increase as the system gets larger. Moreover, we find that \{AAJ\} significantly outperforms the Generalized Minimal Residual (GMRES) method in the range of problems considered here, with the relative performance again improving with size of the system. Overall, the proposed method represents a simple yet efficient technique that is particularly attractive for large-scale parallel solutions of linear systems of equations. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2015.11.018},
  ISSN                     = {0021-9991},
  Keywords                 = {Linear systems of equations},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999115007585}
}

@Article{Pratapa201696,
  Title                    = {Spectral Quadrature method for accurate electronic structure calculations of metals and insulators },
  Author                   = {Phanisri P. Pratapa and Phanish Suryanarayana and John E. Pask},
  Journal                  = {Computer Physics Communications },
  Year                     = {2016},
  Pages                    = {96 - 107},
  Volume                   = {200},

  Abstract                 = {Abstract We present the Clenshaw–Curtis Spectral Quadrature (SQ) method for real-space O ( N ) Density Functional Theory (DFT) calculations. In this approach, all quantities of interest are expressed as bilinear forms or sums over bilinear forms, which are then approximated by spatially localized Clenshaw–Curtis quadrature rules. This technique is identically applicable to both insulating and metallic systems, and in conjunction with local reformulation of the electrostatics, enables the O ( N ) evaluation of the electronic density, energy, and atomic forces. The \{SQ\} approach also permits infinite-cell calculations without recourse to Brillouin zone integration or large supercells. We employ a finite difference representation in order to exploit the locality of electronic interactions in real space, enable systematic convergence, and facilitate large-scale parallel implementation. In particular, we derive expressions for the electronic density, total energy, and atomic forces that can be evaluated in O ( N ) operations. We demonstrate the systematic convergence of energies and forces with respect to quadrature order as well as truncation radius to the exact diagonalization result. In addition, we show convergence with respect to mesh size to established O ( N 3 ) planewave results. Finally, we establish the efficiency of the proposed approach for high temperature calculations and discuss its particular suitability for large-scale parallel computation. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2015.11.005},
  ISSN                     = {0010-4655},
  Keywords                 = {Density Functional Theory},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465515004166}
}

@Article{Rajovic2014,
  Title                    = {Tibidabo1: Making the case for an ARM-based \{HPC\} system },
  Author                   = {Nikola Rajovic and Alejandro Rico and Nikola Puzovic and Chris Adeniyi-Jones and Alex Ramirez},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2014},
  Note                     = {Special Section: Intelligent Big Data ProcessingSpecial Section: Behavior Data Security Issues in Network Information PropagationSpecial Section: Energy-efficiency in Large Distributed Computing ArchitecturesSpecial Section: eScience Infrastructure and Applications },
  Pages                    = {322 - 334},
  Volume                   = {36},

  Abstract                 = {Abstract It is widely accepted that future \{HPC\} systems will be limited by their power consumption. Current \{HPC\} systems are built from commodity server processors, designed over years to achieve maximum performance, with energy efficiency being an after-thought. In this paper we advocate a different approach: building \{HPC\} systems from low-power embedded and mobile technology parts, over time designed for maximum energy efficiency, which now show promise for competitive performance. We introduce the architecture of Tibidabo, the first large-scale \{HPC\} cluster built from \{ARM\} multicore chips, and a detailed performance and energy efficiency evaluation. We present the lessons learned for the design and improvement in energy efficiency of future \{HPC\} systems based on such low-power cores. Based on our experience with the prototype, we perform simulations to show that a theoretical cluster of 16-core \{ARM\} Cortex-A15 chips would increase the energy efficiency of our cluster by 8.7×, reaching an energy efficiency of 1046 MFLOPS/W. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2013.07.013},
  ISSN                     = {0167-739X},
  Keywords                 = {High-performance computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X13001581}
}

@Article{Rajovic2014,
  Title                    = {Tibidabo1: Making the case for an ARM-based \{HPC\} system },
  Author                   = {Nikola Rajovic and Alejandro Rico and Nikola Puzovic and Chris Adeniyi-Jones and Alex Ramirez},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2014},
  Note                     = {Special Section: Intelligent Big Data ProcessingSpecial Section: Behavior Data Security Issues in Network Information PropagationSpecial Section: Energy-efficiency in Large Distributed Computing ArchitecturesSpecial Section: eScience Infrastructure and Applications },
  Pages                    = {322 - 334},
  Volume                   = {36},

  Abstract                 = {Abstract It is widely accepted that future \{HPC\} systems will be limited by their power consumption. Current \{HPC\} systems are built from commodity server processors, designed over years to achieve maximum performance, with energy efficiency being an after-thought. In this paper we advocate a different approach: building \{HPC\} systems from low-power embedded and mobile technology parts, over time designed for maximum energy efficiency, which now show promise for competitive performance. We introduce the architecture of Tibidabo, the first large-scale \{HPC\} cluster built from \{ARM\} multicore chips, and a detailed performance and energy efficiency evaluation. We present the lessons learned for the design and improvement in energy efficiency of future \{HPC\} systems based on such low-power cores. Based on our experience with the prototype, we perform simulations to show that a theoretical cluster of 16-core \{ARM\} Cortex-A15 chips would increase the energy efficiency of our cluster by 8.7×, reaching an energy efficiency of 1046 MFLOPS/W. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2013.07.013},
  ISSN                     = {0167-739X},
  Keywords                 = {High-performance computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X13001581}
}

@Article{Rajovic2013439,
  Title                    = {The low power architecture approach towards exascale computing },
  Author                   = {Nikola Rajovic and Lluis Vilanova and Carlos Villavieja and Nikola Puzovic and Alex Ramirez},
  Journal                  = {Journal of Computational Science },
  Year                     = {2013},
  Note                     = {Scalable Algorithms for Large-Scale Systems Workshop (ScalA2011), Supercomputing 2011 },
  Number                   = {6},
  Pages                    = {439 - 443},
  Volume                   = {4},

  Abstract                 = {Energy efficiency is a first-order concern when deploying any computer system. From battery-operated mobile devices, to data centers and supercomputers, energy consumption limits the performance that can be offered. We are exploring an alternative to current supercomputers that builds on low power mobile processors. We present initial results from our prototype system based on \{ARM\} Cortex-A9, which achieves 120 MFLOPS/W, and discuss the possibilities to increase its energy efficiency. },
  Doi                      = {http://dx.doi.org/10.1016/j.jocs.2013.01.002},
  ISSN                     = {1877-7503},
  Keywords                 = {Exascale},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877750313000148}
}

@Article{Rashti2016265,
  Title                    = {Long-haul secure data transfer using hardware-assisted GridFTP },
  Author                   = {Mohammad Javad Rashti and Gerald Sabin and Rajkumar Kettimuthu},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2016},
  Pages                    = {265 - 276},
  Volume                   = {56},

  Abstract                 = {Abstract Extreme-scale scientific collaborations require high-performance wide-area end-to-end data transports to enable fast and secure transfer of high data volumes among collaborating institutions. GridFTP is the de facto protocol for large-scale data transfer in science environments. Existing predominant network transport protocols such as \{TCP\} have serious limitations that consume significant \{CPU\} power and prevent GridFTP from achieving high throughput on long-haul networks with high latency and potential packet loss, reordering and jitter. On the other hand, protocols such as \{UDT\} that address some of the \{TCP\} shortcomings demand high computing resources on data transfer nodes. These limitations have caused underutilization of existing high-bandwidth links in scientific and collaborative grids. To address this situation, we have enhanced Globus GridFTP, the most widely used GridFTP implementation, by developing transport offload engines such as \{UDT\} and iWARP on SmartNIC, a programmable 10GbE network interface card (NIC). Our results show significant reduction in server utilization and full line-rate sustained bandwidth in high-latency networks, as measured for up to 100 ms of network latency. In our work, we also offload OpenSSL on SmartNIC to reduce host utilization for secure file transfers. The offload engine can provide line-rate data channel encryption/decryption on top of \{UDT\} offload without consuming additional host \{CPU\} resources. Lower \{CPU\} utilization leads to increased server capacity, which allows data transfer nodes to support higher network and data-processing rates. Alternatively, smaller or fewer \{DTNs\} can be used for a particular data rate requirement. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2015.09.014},
  ISSN                     = {0167-739X},
  Keywords                 = {GridFTP},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X15002940}
}

@InCollection{Ratković20151,
  Title                    = {Chapter One - An Overview of Architecture-Level Power- and Energy-Efficient Design Techniques },
  Author                   = {Ivan Ratković and Nikola Bežanić and Osman S. Ünsal and Adrian Cristal and Veljko Milutinović},
  Publisher                = {Elsevier},
  Year                     = {2015},
  Editor                   = {Ali R. Hurson},
  Pages                    = {1 - 57},
  Series                   = {Advances in Computers },
  Volume                   = {98},

  Abstract                 = {Abstract Power dissipation and energy consumption became the primary design constraint for almost all computer systems in the last 15 years. Both computer architects and circuit designers intent to reduce power and energy (without a performance degradation) at all design levels, as it is currently the main obstacle to continue with further scaling according to Moore's law. The aim of this survey is to provide a comprehensive overview of power- and energy-efficient “state-of-the-art” techniques. We classify techniques by component where they apply to, which is the most natural way from a designer point of view. We further divide the techniques by the component of power/energy they optimize (static or dynamic), covering in that way complete low-power design flow at the architectural level. At the end, we conclude that only a holistic approach that assumes optimizations at all design levels can lead to significant savings. },
  Doi                      = {http://dx.doi.org/10.1016/bs.adcom.2015.04.001},
  ISSN                     = {0065-2458},
  Keywords                 = {Low-power techniques},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0065245815000303}
}

@Article{Reed2015,
  Title                    = {Exascale Computing and Big Data},
  Author                   = {Reed, Daniel A., and Dongarra J.},
  Journal                  = {Communications of the ACM},
  Year                     = {2015},
  Number                   = {7},
  Pages                    = {56-68},
  Volume                   = {58}
}

@Article{Reed20131,
  Title                    = {Visual analytics clarify the scalability and effectiveness of massively parallel many-objective optimization: A groundwater monitoring design example },
  Author                   = {Patrick M. Reed and Joshua B. Kollat},
  Journal                  = {Advances in Water Resources },
  Year                     = {2013},
  Pages                    = {1 - 13},
  Volume                   = {56},

  Abstract                 = {Abstract In this study, we contribute a comprehensive framework for simultaneously assessing solution quality and scalability for massively parallel multiobjective evolutionary algorithm (MOEA)-based search using a highly challenging optimization—assimilation application. Visual analytics are used to evaluate how changes in search metric performance relate to actual decision relevant changes in the Pareto approximate set. The application focuses on a four objective groundwater monitoring application in which parallel scalability is tested across compute core counts ranging from 64 to a maximum of 8192. This study demonstrates that parallel search performance must be assessed in terms of how well speedup is exploited to improve the quality of search results and that solely focusing on differences in computational time can be deceptive. Our results demonstrate how visualization can clarify when an MOEA’s search shifts from “translating” the approximation set to “diversifying” its coverage over the extent of the objectives. This is an important observation. If shorter parallel run durations are required, the rapid early translation of the set may yield a reasonable approximation of the Pareto approximate set where further search is unnecessary. Although a groundwater application is used to demonstrate our parallelization, the visual analytics and metrics utilized to characterize the parallel scalability of MOEA-based search are broadly applicable in water resources and beyond. },
  Doi                      = {http://dx.doi.org/10.1016/j.advwatres.2013.01.011},
  ISSN                     = {0309-1708},
  Keywords                 = {Multiobjective optimization},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S030917081300033X}
}

@Article{Reuter2015325,
  Title                    = {A multi-platform scaling study for an OpenMP parallelization of a discontinuous Galerkin ocean model },
  Author                   = {Balthasar Reuter and Vadym Aizinger and Harald Köstler},
  Journal                  = {Computers \& Fluids },
  Year                     = {2015},
  Pages                    = {325 - 335},
  Volume                   = {117},

  Abstract                 = {Abstract We present a cross-platform scaling investigation for an OpenMP parallelization of \{UTBEST3D\} – a coastal and regional ocean code based on the discontinuous Galerkin finite element method. The study is conducted for a real life application on an unstructured computational mesh of the Northwest Atlantic with realistic topography and well resolved coast line on a broad selection of current computing platforms. Four numerical setups of increasing physical and computational complexity are used for comparison: barotropic with no vertical eddy viscosity, barotropic with an algebraic eddy viscosity parametrization, baroclinic with an algebraic eddy viscosity, and baroclinic with k– ∊ vertical turbulence closure. In addition to Intel Xeon and \{IBM\} Power6/PowerPC architectures, we also include Intel’s new \{MIC\} processor Xeon Phi in the evaluation. Good scalability is found across all platforms with Intel Xeon \{CPUs\} producing the best runtime results and Xeon Phi demonstrating the best parallel efficiency. },
  Doi                      = {http://dx.doi.org/10.1016/j.compfluid.2015.05.020},
  ISSN                     = {0045-7930},
  Keywords                 = {Discontinuous Galerkin finite element method},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045793015001759}
}

@Article{Rezazadeh2015875,
  Title                    = {Flattening: An efficient approach to improving the performance of conventional \{MINs\} },
  Author                   = {Majid Rezazadeh and Farshad Safaei and Mahsa Moazez},
  Journal                  = {Microelectronics Journal },
  Year                     = {2015},
  Number                   = {10},
  Pages                    = {875 - 892},
  Volume                   = {46},

  Abstract                 = {Abstract Numerous conventional interconnection networks have been designed in a way in which they use indirect or multistage topologies. The reason behind this idea is the fact that such topologies can minimize the network hop count. However, the constraints of technology and packaging have given impetus for fundamental changes in the approach to designing topologies. Increasing the radix of the network׳s routers lowers the total cost of the network, which is related to the number of routers׳ pins and connectors. This increase also results in lowering the power consumption, which plays a crucial role in the performance. Kim, Dally and Abts have provided a cost-efficient topology for high-radix networks, named the flattened Butterfly. They have shown that this approach is comparable to the conventional Butterfly networks with regard to cost. It is much the same as a Folded-Clos topology in terms of the performance per cost ratio under adversarial traffic, whilst under benign traffic, the flattened Butterfly has approximately twice this ratio. In this paper, we have generalized the idea of flattening to all Delta networks, in addition to some non-Delta ones such as Beneš and Clos. Moreover, the conditions on which multistage networks can be converted to the flattened ones have been generally provided. All the mentioned networks have also been compared with another cost-efficient topology, named the HyperX, in order to gain deep insight into the key facets of the microarchitecture of high-radix networks. On the other hand, advances in designing digital circuits and reduction in their size rely upon knowledge in nano-electronics for refinements of the standard copper interconnect technology. This copper interconnects have become a major performance bottleneck in Multistage Interconnection Network (MIN) platforms. Consequently, a minor contribution of this paper is the performance assessment of the aforementioned networks using the Carbon NanoTube (CNT) technology under trace-driven and synthetic traffic patterns; inasmuch as this technology has been introduced as one of the six most important architectures in future digital systems. \{CNT\} is considered to be a promising technology in the design and fabrication of the next-generation chips since it is capable of handling extremely high current densities for a long time without considerable performance degradation. Although the comparative study of different networks with various parameters is the main goal, it should be taken into consideration that in some situations, these parameters provide similar conditions in different networks. As such, they can be combined with an efficient method to present a simple model. Finally, we have used data mining in order to reach a unified and meaningful performance parameter. },
  Doi                      = {http://dx.doi.org/10.1016/j.mejo.2015.07.003},
  ISSN                     = {0026-2692},
  Keywords                 = {Multistage Interconnection Networks},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0026269215001718}
}

@Article{Richie201594,
  Title                    = {Threaded \{MPI\} programming model for the Epiphany \{RISC\} array processor },
  Author                   = {David Richie and James Ross and Song Park and Dale Shires},
  Journal                  = {Journal of Computational Science },
  Year                     = {2015},
  Note                     = {Computational Science at the Gates of Nature },
  Pages                    = {94 - 100},
  Volume                   = {9},

  Abstract                 = {Abstract The low-power Adapteva Epiphany \{RISC\} array processor offers high computational energy-efficiency and parallel scalability. However, extracting performance with a standard parallel programming model remains a great challenge. We present an effective programming model for the Epiphany architecture based on the Message Passing Interface (MPI) standard adapted for coprocessor offload. Using \{MPI\} exploits the similarities between the Epiphany architecture and a networked parallel distributed cluster. Furthermore, our approach enables codes written with \{MPI\} to execute on the \{RISC\} array processor with little modification. We present experimental results for matrix–matrix multiplication using \{MPI\} and highlight the importance of fast inter-core data transfers. Using \{MPI\} we demonstrate an on-chip performance of 9.1 \{GFLOPS\} with an efficiency of 15.3 GFLOPS/W. Threaded \{MPI\} exhibits the highest performance reported for the Epiphany architecture using a standard parallel programming model. },
  Doi                      = {http://dx.doi.org/10.1016/j.jocs.2015.04.023},
  ISSN                     = {1877-7503},
  Keywords                 = {2D \{RISC\} array},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877750315000617}
}

@Article{Roberts20141581,
  Title                    = {Camellia: A software framework for discontinuous Petrov–Galerkin methods },
  Author                   = {Nathan V. Roberts},
  Journal                  = {Computers \& Mathematics with Applications },
  Year                     = {2014},
  Note                     = {Minimum Residual and Least Squares Finite Element Methods },
  Number                   = {11},
  Pages                    = {1581 - 1604},
  Volume                   = {68},

  Abstract                 = {Abstract The discontinuous Petrov–Galerkin (DPG) methodology of Demkowicz and Gopalakrishnan minimizes the solution residual in a user-determinable energy norm and offers a built-in mechanism for evaluating error in the energy norm, among other desirable features. However, the methodology also brings with it some additional complexity for researchers who wish to experiment with \{DPG\} in their computations. In this paper, we introduce Camellia, a software framework whose central design goal is to enable developers to create efficient h p -adaptive \{DPG\} solvers with minimal effort. },
  Doi                      = {http://dx.doi.org/10.1016/j.camwa.2014.08.010},
  ISSN                     = {0898-1221},
  Keywords                 = {Discontinuous Petrov–Galerkin},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0898122114004027}
}

@Article{Roberts2015456,
  Title                    = {A discontinuous Petrov–Galerkin methodology for adaptive solutions to the incompressible Navier–Stokes equations },
  Author                   = {Nathan V. Roberts and Leszek Demkowicz and Robert Moser},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2015},
  Pages                    = {456 - 483},
  Volume                   = {301},

  Abstract                 = {Abstract The discontinuous Petrov–Galerkin methodology with optimal test functions (DPG) of Demkowicz and Gopalakrishnan [18,20] guarantees the optimality of the solution in an energy norm, and provides several features facilitating adaptive schemes. Whereas Bubnov–Galerkin methods use identical trial and test spaces, Petrov–Galerkin methods allow these function spaces to differ. In DPG, test functions are computed on the fly and are chosen to realize the supremum in the inf–sup condition; the method is equivalent to a minimum residual method. For well-posed problems with sufficiently regular solutions, \{DPG\} can be shown to converge at optimal rates—the inf–sup constants governing the convergence are mesh-independent, and of the same order as those governing the continuous problem [48]. \{DPG\} also provides an accurate mechanism for measuring the error, and this can be used to drive adaptive mesh refinements. We employ \{DPG\} to solve the steady incompressible Navier–Stokes equations in two dimensions, building on previous work on the Stokes equations, and focusing particularly on the usefulness of the approach for automatic adaptivity starting from a coarse mesh. We apply our approach to a manufactured solution due to Kovasznay as well as the lid-driven cavity flow, backward-facing step, and flow past a cylinder problems. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2015.07.014},
  ISSN                     = {0021-9991},
  Keywords                 = {Discontinuous Petrov Galerkin},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999115004593}
}

@Article{Rodero201347,
  Title                    = {Introduction to special section on Green High Performance Computing (Green HPC) },
  Author                   = {Ivan Rodero and Manish Parashar},
  Journal                  = {Sustainable Computing: Informatics and Systems },
  Year                     = {2013},
  Number                   = {2},
  Pages                    = {47 - 48},
  Volume                   = {3},

  Doi                      = {http://dx.doi.org/10.1016/j.suscom.2013.03.001},
  ISSN                     = {2210-5379},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S2210537913000218}
}

@Article{Roehm2015138,
  Title                    = {Distributed Database Kriging for Adaptive Sampling () },
  Author                   = {Dominic Roehm and Robert S. Pavel and Kipton Barros and Bertrand Rouet-Leduc and Allen L. McPherson and Timothy C. Germann and Christoph Junghans},
  Journal                  = {Computer Physics Communications },
  Year                     = {2015},
  Pages                    = {138 - 147},
  Volume                   = {192},

  Abstract                 = {Abstract We present an adaptive sampling method supplemented by a distributed database and a prediction method for multiscale simulations using the Heterogeneous Multiscale Method. A finite-volume scheme integrates the macro-scale conservation laws for elastodynamics, which are closed by momentum and energy fluxes evaluated at the micro-scale. In the original approach, molecular dynamics (MD) simulations are launched for every macro-scale volume element. Our adaptive sampling scheme replaces a large fraction of costly micro-scale \{MD\} simulations with fast table lookup and prediction. The cloud database Redis provides the plain table lookup, and with locality aware hashing we gather input data for our prediction scheme. For the latter we use kriging, which estimates an unknown value and its uncertainty (error) at a specific location in parameter space by using weighted averages of the neighboring points. We find that our adaptive scheme significantly improves simulation performance by a factor of 2.5–25, while retaining high accuracy for various choices of the algorithm parameters. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2015.03.006},
  ISSN                     = {0010-4655},
  Keywords                 = {Adaptive sampling},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465515001058}
}

@Article{Romano2013274,
  Title                    = {The OpenMC Monte Carlo particle transport code },
  Author                   = {Paul K. Romano and Benoit Forget},
  Journal                  = {Annals of Nuclear Energy },
  Year                     = {2013},
  Pages                    = {274 - 281},
  Volume                   = {51},

  Abstract                 = {A new Monte Carlo code called OpenMC is currently under development at the Massachusetts Institute of Technology as a tool for simulation on high-performance computing platforms. Given that many legacy codes do not scale well on existing and future parallel computer architectures, OpenMC has been developed from scratch with a focus on high performance scalable algorithms as well as modern software design practices. The present work describes the methods used in the OpenMC code and demonstrates the performance and accuracy of the code on a variety of problems. },
  Doi                      = {http://dx.doi.org/10.1016/j.anucene.2012.06.040},
  ISSN                     = {0306-4549},
  Keywords                 = {Monte Carlo},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0306454912003283}
}

@Article{Romano201590,
  Title                    = {OpenMC: A state-of-the-art Monte Carlo code for research and development },
  Author                   = {Paul K. Romano and Nicholas E. Horelik and Bryan R. Herman and Adam G. Nelson and Benoit Forget and Kord Smith},
  Journal                  = {Annals of Nuclear Energy },
  Year                     = {2015},
  Note                     = {Joint International Conference on Supercomputing in Nuclear Applications and Monte Carlo 2013, \{SNA\} + \{MC\} 2013. Pluri- and Trans-disciplinarity, Towards New Modeling and Numerical Simulation Paradigms },
  Pages                    = {90 - 97},
  Volume                   = {82},

  Abstract                 = {Abstract This paper gives an overview of OpenMC, an open source Monte Carlo particle transport code recently developed at the Massachusetts Institute of Technology. OpenMC uses continuous-energy cross sections and a constructive solid geometry representation, enabling high-fidelity modeling of nuclear reactors and other systems. Modern, portable input/output file formats are used in OpenMC: \{XML\} for input, and \{HDF5\} for output. High performance parallel algorithms in OpenMC have demonstrated near-linear scaling to over 100,000 processors on modern supercomputers. Other topics discussed in this paper include plotting, \{CMFD\} acceleration, variance reduction, eigenvalue calculations, and software development processes. },
  Doi                      = {http://dx.doi.org/10.1016/j.anucene.2014.07.048},
  ISSN                     = {0306-4549},
  Keywords                 = {Monte Carlo},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S030645491400379X}
}

@Article{Romano201320,
  Title                    = {Data decomposition of Monte Carlo particle transport simulations via tally servers },
  Author                   = {Paul K. Romano and Andrew R. Siegel and Benoit Forget and Kord Smith},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2013},
  Pages                    = {20 - 36},
  Volume                   = {252},

  Abstract                 = {Abstract An algorithm for decomposing large tally data in Monte Carlo particle transport simulations is developed, analyzed, and implemented in a continuous-energy Monte Carlo code, OpenMC. The algorithm is based on a non-overlapping decomposition of compute nodes into tracking processors and tally servers. The former are used to simulate the movement of particles through the domain while the latter continuously receive and update tally data. A performance model for this approach is developed, suggesting that, for a range of parameters relevant to \{LWR\} analysis, the tally server algorithm should perform with minimal overhead on contemporary supercomputers. An implementation of the algorithm in OpenMC is then tested on the Intrepid and Titan supercomputers, supporting the key predictions of the model over a wide range of parameters. We thus conclude that the tally server algorithm is a successful approach to circumventing classical on-node memory constraints en route to unprecedentedly detailed Monte Carlo reactor simulations. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2013.06.011},
  ISSN                     = {0021-9991},
  Keywords                 = {Monte Carlo},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S002199911300435X}
}

@Article{RouetLeduc20141857,
  Title                    = {Spatial adaptive sampling in multiscale simulation },
  Author                   = {Bertrand Rouet-Leduc and Kipton Barros and Emmanuel Cieren and Venmugil Elango and Christoph Junghans and Turab Lookman and Jamaludin Mohd-Yusof and Robert S. Pavel and Axel Y. Rivera and Dominic Roehm and Allen L. McPherson and Timothy C. Germann},
  Journal                  = {Computer Physics Communications },
  Year                     = {2014},
  Number                   = {7},
  Pages                    = {1857 - 1864},
  Volume                   = {185},

  Abstract                 = {Abstract In a common approach to multiscale simulation, an incomplete set of macroscale equations must be supplemented with constitutive data provided by fine-scale simulation. Collecting statistics from these fine-scale simulations is typically the overwhelming computational cost. We reduce this cost by interpolating the results of fine-scale simulation over the spatial domain of the macro-solver. Unlike previous adaptive sampling strategies, we do not interpolate on the potentially very high dimensional space of inputs to the fine-scale simulation. Our approach is local in space and time, avoids the need for a central database, and is designed to parallelize well on large computer clusters. To demonstrate our method, we simulate one-dimensional elastodynamic shock propagation using the Heterogeneous Multiscale Method (HMM); we find that spatial adaptive sampling requires only ≈ 50 × N 0.14 fine-scale simulations to reconstruct the stress field at all N grid points. Related multiscale approaches, such as Equation Free methods, may also benefit from spatial adaptive sampling. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2014.03.011},
  ISSN                     = {0010-4655},
  Keywords                 = {Multiscale},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465514000915}
}

@Article{Ryazanov201235,
  Title                    = {Magnetic Josephson Junction Technology for Digital and Memory Applications },
  Author                   = {Valery V. Ryazanov and Vitaly V. Bol’ginov and Danila S. Sobanin and Igor V. Vernik and Sergey K. Tolpygo and Alan M. Kadin and Oleg A. Mukhanov},
  Journal                  = {Physics Procedia },
  Year                     = {2012},
  Note                     = {\{SUPERCONDUCTIVITY\} \{CENTENNIAL\} Conference 2011 },
  Pages                    = {35 - 41},
  Volume                   = {36},

  Abstract                 = {The lack of dense, fast, energy efficient memory has been the main detractor for multiple superconducting digital projects in the past. Recently, fundamental physics research in superconductor-ferromagnet thin-film tunnel structures created a new opportunity to solve this long-standing problem. Superconductivity and ferromagnetism, two deeply antagonistic electronic properties, can co-exist in form of Magnetic Josephson Junctions (MJJs). The superconducting-ferromagnetic \{MJJs\} are electrically compatible with traditional superconductor-insulator-superconductor (SIS) Josephson junctions (JJs) used for digital energy-efficient single flux quantum (eSFQ/ERSFQ) circuits. Both \{MJJ\} and \{JJ\} circuits have similar fabrication process and can be integrated on a single chip. As a result, a combination of \{MJJs\} and \{JJs\} can be used to form addressable memory cells, energy-efficient memory periphery circuits and programmable logic elements. In this paper, we present the test results of superconductor-insulator-ferromagnet-superconductor (SIFS) \{MJJs\} showing their applicability for superconducting spintronic memory and digital circuits. },
  Doi                      = {http://dx.doi.org/10.1016/j.phpro.2012.06.126},
  ISSN                     = {1875-3892},
  Keywords                 = {Cryogenic electronics},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1875389212020639}
}

@Article{Rycerz20131116,
  Title                    = {Support for Multiscale Simulations with Molecular Dynamics },
  Author                   = {Katarzyna Rycerz and Eryk Ciepiela and Grzegorz Dyk and Derek Groen and Tomasz Gubala and Daniel Harezlak and Maciej Pawlik and James Suter and Stefan Zasada and Peter Coveney and Marian Bubak},
  Journal                  = {Procedia Computer Science },
  Year                     = {2013},
  Note                     = {2013 International Conference on Computational Science },
  Pages                    = {1116 - 1125},
  Volume                   = {18},

  Abstract                 = {Abstract We present a reusable solution that supports users in combining single-scale models to create a multiscale application. Our approach applies several multiscale programming tools to allow users to compose multiscale applications using a graphical interface, and provides an easy way to execute these multiscale applications on international production infrastructures. Our solution extends the general purpose scripting approach of the GridSpace platform with simple mechanisms for accessing production resources, provided by the Application Hosting Environment (AHE). We apply our support solution to construct and execute a multiscale simulation of clay-polymer nanocomposite materials, and showcase its benefit in reducing the effort required to do a number of time-intensive user tasks. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2013.05.277},
  ISSN                     = {1877-0509},
  Keywords                 = {distributed multiscale simulations},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050913004201}
}

@Article{Safi2016170,
  Title                    = {GPGPU-based rising bubble simulations using a \{MRT\} lattice Boltzmann method coupled with level set interface capturing },
  Author                   = {Mohammad Amin Safi and Stefan Turek},
  Journal                  = {Computers \& Fluids },
  Year                     = {2016},
  Note                     = {Special Issue for ICMMES-2014 },
  Pages                    = {170 - 184},
  Volume                   = {124},

  Abstract                 = {Abstract A multiphase Lattice Boltzmann (LB) scheme coupled with a level set interface capturing model is used for the simulation of multiphase flows, and in particular, rising bubbles under moderate and high density and viscosity ratios. We make use of consistent time integration and force discretization schemes in particular for pressure forces along with using multiple relaxation time (MRT) form of the collision in the \{LB\} equation which enables us to preserve stability and accuracy for high density and critical Eo numbers. We first present the solution for the standard test of a static bubble in order to show the accuracy of the solution with respect to the Laplace law for pressure and also the spurious velocity level. We present quantitative benchmark computations and error analysis for the 2D rising bubble test cases being further validated against high precision finite element solutions in Hysing et al. (2009). Furthermore, by applying efficient multi-core and many core general purpose \{GPU\} (GPGPU) implementations outlines, we demonstrate that the desired parallel scaling characteristics of general \{LBM\} solutions are well preserved for the proposed coupled computations. The presented implementations are shown to outperform the available GPU-based phase-field \{LBM\} solvers in terms of computational time, turning the scheme into a desirable choice for massive multiphase simulations in three dimensions. },
  Doi                      = {http://dx.doi.org/10.1016/j.compfluid.2015.06.001},
  ISSN                     = {0045-7930},
  Keywords                 = {Rising bubbles},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S004579301500184X}
}

@Article{Safi20151290,
  Title                    = {Efficient computations for high density ratio rising bubble flows using a diffused interface, coupled lattice Boltzmann-level set scheme },
  Author                   = {Mohammad Amin Safi and Stefan Turek},
  Journal                  = {Computers \& Mathematics with Applications },
  Year                     = {2015},
  Number                   = {6},
  Pages                    = {1290 - 1305},
  Volume                   = {70},

  Abstract                 = {Abstract A mass conserving, diffused interface, coupled Lattice Boltzmann-level set scheme is proposed and numerically studied for the simulation of high density and viscosity ratio multiphase flows. The approach is based on the pressure evolution formulation of the lattice Boltzmann equation, which is then coupled with the level set equation to capture a diffused level set function. Multiple relaxation time collision and isotropic force discretization techniques are employed to further reinforce the stability and accuracy of the \{LBM\} solver and a monolithic approach is employed to convect the level set function with minimal computations to preserve a smooth density profile. We present extensive investigations for numerical accuracy through performing benchmark simulations for rising bubble problems. It is observed that the proposed scheme is successful in producing accurate results as compared to those from high precision 2D finite element solutions in Hysing et al. (2009), offering a remarkable improvement in mass conservation and characteristic benchmark quantities upon our previous sharp interface coupled model described in Safi and Turek (2014). Moreover, parallel scalability of the coupled \{LB\} scheme is shown to be preserved through performing efficient CPU- and GPGPU-based computations. },
  Doi                      = {http://dx.doi.org/10.1016/j.camwa.2015.07.007},
  ISSN                     = {0898-1221},
  Keywords                 = {Rising bubbles},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0898122115003429}
}

@Article{Sancho2015,
  Title                    = {\{BSC\} Best Practices in Professional Training and Teaching for the \{HPC\} Ecosystem },
  Author                   = {Maria-Ribera Sancho},
  Journal                  = {Journal of Computational Science },
  Year                     = {2015},
  Pages                    = { - },

  Abstract                 = {Abstract This paper outlines the key components of the European \{HPC\} ecosystems, analyses the major challenges as well as corresponding specific technical focus areas which needs to be addressed in European strategic research agenda for \{HPC\} leadership. Further the need for education and training is clearly identified and the \{BSC\} approach, \{BSC\} model and best practices are presented and analyzed. Further a generalization and analysis of the approach are given. },
  Doi                      = {http://dx.doi.org/10.1016/j.jocs.2015.12.004},
  ISSN                     = {1877-7503},
  Keywords                 = {\{HPC\} Ecosystem},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877750315300508}
}

@Article{Santoli2013257,
  Title                    = {An innovative nanophotonic information processing concept implementing cogent micro/nanosensors for space robotics },
  Author                   = {Salvatore Santoli},
  Journal                  = {Acta Astronautica },
  Year                     = {2013},
  Note                     = {7th \{IAA\} Symposium on Realistic Advanced Scientific Space MissionsAosta, Italy, July 2011 },
  Number                   = {2},
  Pages                    = {257 - 262},
  Volume                   = {82},

  Abstract                 = {Cogent sensors, defined as sensors that are capable of performing the transformation of raw data into information, are shown to be of the essence for realization of the long sought-after autonomous robots for space applications. A strongly miniaturized integration of sensing and information processing systems is needed for cogent sensors designed for autonomous sensing—information processing (IP)—actuating behavior. It is shown that the recently developed field of quantum holography (QH), stemming from geometric quantization of any holographic processes through the Heisenberg Group (G) and deeply different, as stressed in detail, from other meanings of “quantum holography” in the literature, supplies the nanophotonic tools for designing and assembling an associative memory (AM) as the brain implementing such strong cogency. An \{AM\} is designed through a free-space interconnected large planar multilayer architecture of quantum well-based two-port neurons implementing a shift register on the manifold of G, and whose input consists of photonic holograms from high frequency pulsed microlasers in the infrared band of em or em-transduced outside signals. The optoelectronics as relative, integrated into a hybrid chip involving photonic detectors, microlasers and electronic components for the clock control system, would allow cycle times as short as 30 ns with the large spatial bandwidth available in photonics. \{IP\} through \{QH\} concerns the encoding and decoding of holographic interference patterns, not of mere binary digital logical (syntactic) information. Accordingly, \{QH\} defines on the G's manifold an \{IP\} paradigm where information as experimental knowledge is processed; i.e., \{IP\} concerns both syntax and semantics. It is shown that such QH–neural brain would cogently deal with spurious signals as random noise that would be caused to die out on the way to the intended target through parallel massive and real-time IP. },
  Doi                      = {http://dx.doi.org/10.1016/j.actaastro.2012.07.033},
  ISSN                     = {0094-5765},
  Keywords                 = {Sensors},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0094576512002974}
}

@Article{Saraladevi2015596,
  Title                    = {Big Data and Hadoop-a Study in Security Perspective },
  Author                   = {B. Saraladevi and N. Pazhaniraja and P. Victer Paul and M.S. Saleem Basha and P. Dhavachelvan},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {Big Data, Cloud and Computing Challenges },
  Pages                    = {596 - 601},
  Volume                   = {50},

  Abstract                 = {Abstract Big data is the collection and analysis of large set of data which holds many intelligence and raw information based on user data, Sensor data, Medical and Enterprise data. The Hadoop platform is used to Store, Manage, and Distribute Big data across several server nodes. This paper shows the Big data issues and focused more on security issue arises in Hadoop Architecture base layer called Hadoop Distributed File System (HDFS). The \{HDFS\} security is enhanced by using three approaches like Kerberos, Algorithm and Name node. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.04.091},
  ISSN                     = {1877-0509},
  Keywords                 = {Big data ;Hadoop ;HDFS ;Security },
  Url                      = {http://www.sciencedirect.com/science/article/pii/S187705091500592X}
}

@Article{Savage2012140,
  Title                    = {Nuclear physics from lattice \{QCD\} },
  Author                   = {M.J. Savage},
  Journal                  = {Progress in Particle and Nuclear Physics },
  Year                     = {2012},
  Note                     = {From Quarks and Gluons to Hadrons and NucleiInternational Workshop on Nuclear Physics, 33rd Course },
  Number                   = {2},
  Pages                    = {140 - 152},
  Volume                   = {67},

  Abstract                 = {I review recent progress in the development of Lattice \{QCD\} into a calculational tool for nuclear physics. Lattice \{QCD\} is currently the only known way of “solving” \{QCD\} in the low-energy regime, and it promises to provide a solid foundation for the structure and interactions of nuclei directly from QCD. },
  Doi                      = {http://dx.doi.org/10.1016/j.ppnp.2011.12.008},
  ISSN                     = {0146-6410},
  Keywords                 = {Nuclear forces},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0146641011001256}
}

@Article{Saviankou20151343,
  Title                    = {Cube v4: From Performance Report Explorer to Performance Analysis Tool },
  Author                   = {Pavel Saviankou and Michael Knobloch and Anke Visser and Bernd Mohr},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {1343 - 1352},
  Volume                   = {51},

  Abstract                 = {Abstract Cube v3 has been a powerful tool to examine reports of the parallel performance tool Scalasca, but was basically unable to perform analyses on its own. With Cube v4, we addressed several shortcomings of Cube v3. We generalized the Cube data model, extended the list of supported data types, and allow operations with nontrivial algebras, e.g. for performance models or statistical data. Additionally, we introduced two major new features that greatly enhance the performance analysis features of Cube: Derived metrics and \{GUI\} plugins. Derived metrics can be used to create and manipulate metrics directly within the GUI, using a powerful domain-specific language called CubePL. Cube \{GUI\} plugins allow the development of novel performance analysis techniques and visualizations based on Cube data without changing the source code of the Cube GUI. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.320},
  ISSN                     = {1877-0509},
  Keywords                 = {Performance analysis},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S187705091501128X}
}

@Article{Schiffers2016,
  Title                    = {I have a DRIHM: A case study in lifting computational science services up to the scientific mainstream },
  Author                   = {Michael Schiffers and Nils gentschen Felde and Dieter Kranzlmüller},
  Journal                  = {Journal of Computational Science },
  Year                     = {2016},
  Pages                    = { - },

  Abstract                 = {Abstract While we are witnessing a transition from petascale to exascale computing, we experience, when teaching students and scientists to adopt distributed computing infrastructures for computational science, what Geoffrey A. Moore once coined “the chasm” between the visionaries in computational science and the early majority of scientific pragmatists. Using the EU-funded \{DRIHM\} project (Distributed Research Infrastructure for Hydro-Meteorology) as a case study, we observe that innovative research infrastructures have difficulties to be accepted by the scientific pragmatists because the infrastructure and scientific services are not “mainstream” enough. Excellence in workforce, however, can only be achieved if the tools are not only available but also used. In this paper we report on how “this chasm” is exhibited in the \{DRIHM\} case, how it was (partially) crossed, and what can be learned from this experience for more general cases. },
  Doi                      = {http://dx.doi.org/10.1016/j.jocs.2015.12.008},
  ISSN                     = {1877-7503},
  Keywords                 = {Research infrastructure},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877750315300533}
}

@Article{Schiffers20152663,
  Title                    = {I have a DRIHM: A Case Study in Lifting Computational Science Services Up to the Scientific Mainstream },
  Author                   = {Michael Schiffers and Nils gentschen Felde and Dieter Kranzlmüller},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {2663 - 2667},
  Volume                   = {51},

  Abstract                 = {Abstract While we are witnessing a transition from petascale to exascale computing, we experience, when teaching students and scientists to adopt distributed computing infrastructures for computational sciences, what Geoffrey A. Moore once coined the chasm between the visionaries in computational sciences and the early majority of scientific pragmatists. Using the EU-funded \{DRIHM\} project (Distributed Research Infrastructure for Hydro-Meteorology) as a case study, we see that innovative research infrastructures have difficulties to be accepted by the scientific pragmatists: The infrastructure services are not yet “mainstream”. Excellence in workforces in computational sciences, however, can only be achieved if the tools are not only available but also used. In this paper we show for \{DRIHM\} how the chasm exhibits and how it can be crossed. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.375},
  ISSN                     = {1877-0509},
  Keywords                 = {Research Infrastructure},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915011837}
}

@Article{Schmidt2012344,
  Title                    = {Investigation into scaling I/O bound streaming applications productively with an all-FPGA cluster },
  Author                   = {Andrew G. Schmidt and Siddhartha Datta and Ashwin A. Mendon and Ron Sass},
  Journal                  = {Parallel Computing },
  Year                     = {2012},
  Note                     = {\{APPLICATION\} \{ACCELERATORS\} \{IN\} \{HPC\} },
  Number                   = {8},
  Pages                    = {344 - 364},
  Volume                   = {38},

  Abstract                 = {The Reconfigurable Computing Cluster project is exploring novel parallel computing architectures in high performance computing with \{FPGA\} devices. Although there are no discrete microprocessors in the system, highly-integrated \{FPGAs\} (with embedded processors) are capable of hosting Linux-based systems and can run arbitrary \{MPI\} applications. This work present an investigation into accelerating I/O bound streaming applications through the coupling of custom computing cores, a hardware filesystem, and an integrated on-chip and off-chip network on the all-FPGA node cluster. Such an infrastructure enables productivity by minimizing hardware design while maintaining high performance. A hardware implementation of the \{BLASTn\} algorithm is used to demonstrate the performance gains and scalability of the custom computing cores across the Spirit cluster. Results show linear speedup across multiple nodes while supporting productivity by eliminating modifications to the original hardware core when scaling up to 512 parallel cores on the cluster. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2011.12.002},
  ISSN                     = {0167-8191},
  Keywords                 = {High performance computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819111001712}
}

@Article{Schreiber20142241,
  Title                    = {Cluster-based Communication and Load Balancing for Simulations on Dynamically Adaptive Grids },
  Author                   = {Martin Schreiber and Hans-Joachim Bungartz},
  Journal                  = {Procedia Computer Science },
  Year                     = {2014},
  Note                     = {2014 International Conference on Computational Science },
  Pages                    = {2241 - 2253},
  Volume                   = {29},

  Abstract                 = {Abstract The present paper introduces a new communication and load-balancing scheme based on a clustering of the grid which we use for the efficient parallelization of simulations on dynamically adaptive grids. With a partitioning based on space-filling curves (SFCs), this yields several advantageous properties regarding the memory requirements and load balancing. However, for such an SFC- based partitioning, additional connectivity information has to be stored and updated for dynamically changing grids. In this work, we present our approach to keep this connectivity information run-length encoded (RLE) only for the interfaces shared between partitions. Using special properties of the underlying grid traversal and used communication scheme, we update this connectivity information implicitly for dynamically changing grids and can represent the connectivity information as a sparse communication graph: graph nodes (partitions) represent bulks of connected grid cells and each graph edge (RLE connectivity information) a unique relation between adjacent partitions. This directly leads to an efficient shared-memory parallelization with graph nodes assigned to computing cores and an efficient en bloc data exchange via graph edges. We further refer to such a partitioning approach with \{RLE\} meta information as a cluster-based domain decomposition and to each partition as a cluster. With the sparse communication graph in mind, we then extend the connectivity information represented by the graph edges with \{MPI\} ranks, yielding an en bloc communication for distributed-memory systems and a hybrid parallelization. For data migration, the stack-based intra-cluster communication allows a very low memory footprint for data migration and the \{RLE\} leads to efficient updates of connectivity information. Our benchmark is based on a shallow water simulation on a dynamically adaptive grid. We conducted performance studies for MPI-only and hybrid parallelizations, yielding an efficiency of over 90% on 256 cores. Furthermore, we demonstrate the applicability of cluster-based optimizations on distributed-memory systems. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2014.05.209},
  ISSN                     = {1877-0509},
  Keywords                 = {dynamically adaptive grids},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S187705091400386X}
}

@Article{Schreiber2014,
  Title                    = {A few bad ideas on the way to the triumph of parallel computing },
  Author                   = {Robert Schreiber},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2014},
  Note                     = {Special Issue on Perspectives on Parallel and Distributed Processing },
  Number                   = {7},
  Pages                    = {2544 - 2547},
  Volume                   = {74},

  Abstract                 = {Abstract Parallelism has become mainstream, in the multicore chip, the GPU, and the internet datacenter running MapReduce. In my field, large-scale scientific computing, parallelism now reigns triumphant. It was no simple, direct route that led to this triumph. Along the way, we were confused by ideas that, in retrospect, turned out to be distractions and errors. The thinking behind them was reasonable, but wrong. One can learn from a dissection of mistakes, so I will retell part of the story here. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2013.10.006},
  ISSN                     = {0743-7315},
  Keywords                 = {Parallelism},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731513002177}
}

@Article{Schreiber20142544,
  Title                    = {A few bad ideas on the way to the triumph of parallel computing },
  Author                   = {Robert Schreiber},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2014},
  Note                     = {Special Issue on Perspectives on Parallel and Distributed Processing },
  Number                   = {7},
  Pages                    = {2544 - 2547},
  Volume                   = {74},

  Abstract                 = {Abstract Parallelism has become mainstream, in the multicore chip, the GPU, and the internet datacenter running MapReduce. In my field, large-scale scientific computing, parallelism now reigns triumphant. It was no simple, direct route that led to this triumph. Along the way, we were confused by ideas that, in retrospect, turned out to be distractions and errors. The thinking behind them was reasonable, but wrong. One can learn from a dissection of mistakes, so I will retell part of the story here. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2013.10.006},
  ISSN                     = {0743-7315},
  Keywords                 = {Parallelism},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731513002177}
}

@Article{Schröder20141390,
  Title                    = {Two-scale Modeling of \{DP\} Steel Incorporating Distributed Properties Inside Micro-constituents },
  Author                   = {Jörg Schröder and Ashutosh Gandhi and Daniel Balzani},
  Journal                  = {Procedia Engineering },
  Year                     = {2014},
  Note                     = {11th International Conference on Technology of Plasticity, \{ICTP\} 2014, 19-24 October 2014, Nagoya Congress Center, Nagoya, Japan },
  Pages                    = {1390 - 1395},
  Volume                   = {81},

  Abstract                 = {Abstract Advanced High Strength Steels (AHSS) are increasingly used in the industry due to their excellent strength and formability properties enabling weight savings. In this wide class of steel we restrict ourselves to the modeling of Dual Phase (DP) steels which are, at the microscale, characterized by a hard martensitic inclusion phase embedded in a soft ferritic matrix phase. During the production process the martensite transforms from austenite by rapidly cooling down the material and thereby causing a volume jump leading to initial plastic strains associated with eigenstresses of higher order. A technique to incorporate theses distributed properties in the ferrite matrix is proposed and implemented using the direct micro-macro transition approach. },
  Doi                      = {http://dx.doi.org/10.1016/j.proeng.2014.10.162},
  ISSN                     = {1877-7058},
  Keywords                 = {\{FE2\} scheme},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877705814014416}
}

@Article{Shang2013381,
  Title                    = {Performance analysis of large scale parallel \{CFD\} computing based on Code_Saturne },
  Author                   = {Zhi Shang},
  Journal                  = {Computer Physics Communications },
  Year                     = {2013},
  Number                   = {2},
  Pages                    = {381 - 386},
  Volume                   = {184},

  Abstract                 = {In order to run computational fluid dynamics (CFD) codes on large scales, parallel computing has to be employed. For instance, on Petascale computing, general parallel computing without any optimization is not enough, especially for complex industrial issues that employ a large number of mesh cells to capture the details of the geometry. How to distribute these mesh cells among the multi-processors for Terascale and Petascale systems to obtain a good performance on parallel computing is really a challenge. Some mesh partitioning software packages, such as Metis, ParMetis, PT-Scotch and Zoltan, were chosen as the candidates ported into Code_Saturne to test if they can lead Code_Saturne towards Petascale and Exascale parallel \{CFD\} computing. Through the studies, it was found that mesh partitioning optimization software packages based on the graph mesh partitioning method can help the \{CFD\} code obtain good mesh distributions for high performance computing (HPC). },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2012.09.026},
  ISSN                     = {0010-4655},
  Keywords                 = {CFD},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S001046551200313X}
}

@Article{Shestak20121186,
  Title                    = {Probabilistic resource allocation in heterogeneous distributed systems with random failures },
  Author                   = {Vladimir Shestak and Edwin K.P. Chong and Anthony A. Maciejewski and Howard Jay Siegel},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2012},
  Number                   = {10},
  Pages                    = {1186 - 1194},
  Volume                   = {72},

  Abstract                 = {The problem of finding efficient workload distribution techniques is becoming increasingly important today for heterogeneous distributed systems where the availability of compute nodes may change spontaneously over time. Resource-allocation policies designed for such systems should maximize the performance and, at the same time, be robust against failure and recovery of compute nodes. Such a policy, based on the concepts of the Derman–Lieberman–Ross theorem, is proposed in this work, and is applied to a simulated model of a dedicated system composed of a set of heterogeneous image processing servers. Assuming that each image results in a “reward” if its processing is completed before a certain deadline, the goal for the resource allocation policy is to maximize the expected cumulative reward. An extensive analysis was done to study the performance of the proposed policy and compare it with the performance of some existing policies adapted to this environment. Our experiments conducted for various types of task-machine heterogeneity illustrate the potential of our method for solving resource allocation problems in a broad spectrum of distributed systems that experience high failure rates. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2012.03.003},
  ISSN                     = {0743-7315},
  Keywords                 = {Resource allocation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731512000688}
}

@Article{Shet20112287,
  Title                    = {Strategies for Fault Tolerance in Multicomponent Applications },
  Author                   = {Aniruddha G. Shet and Wael R. Elwasif and Samantha S. Foley and Byung H. Park and David E. Bernholdt and Randall Bramley},
  Journal                  = {Procedia Computer Science },
  Year                     = {2011},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2011 },
  Pages                    = {2287 - 2296},
  Volume                   = {4},

  Abstract                 = {This paper discusses on-going work with the Integrated Plasma Simulator (IPS), a framework for coupled multiphysics simulations of plasmas, to allow simulations to run through the loss of nodes on which the simulation is executing. While many different techniques are available to improve the fault tolerance of computational science applications on high-performance computer systems, checkpoint/restart (C/R) remains virtually the only one that see widespread use in practice. Our focus here is to augment the traditional C/R approach with additional techniques that can provide a more localized and tailored response to faults based on the ability to restart failed tasks on an individual basis, and the use of information external to the application itself in order to guide decision-making, in many cases avoiding the need to stop and restart the entire simulation. This capability involves several features within the \{IPS\} framework, and leverages the Fault Tolerance Backplane, a publish/subscribe event service to disseminate fault-related information throughout \{HPC\} systems, to obtain information from the Reliability, Availability and Serviceability (RAS) subsystem of the \{HPC\} system. This work is described in the context of Cray XT-series computer systems for concreteness, but is applicable to other environments as well. As part of the analysis of this work, we discuss the requirements to generalize this approach to other complex simulation applications beyond the Integrated Plasma Simulator. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2011.04.249},
  ISSN                     = {1877-0509},
  Keywords                 = {Application fault tolerance},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050911003073}
}

@Article{Shoji2015172,
  Title                    = {QM/MM study of the \{S2\} to \{S3\} transition reaction in the oxygen-evolving complex of photosystem \{II\} },
  Author                   = {Mitsuo Shoji and Hiroshi Isobe and Kizashi Yamaguchi},
  Journal                  = {Chemical Physics Letters },
  Year                     = {2015},
  Pages                    = {172 - 179},
  Volume                   = {636},

  Abstract                 = {Abstract Catalytic reactions of the proton and electron transfers occurring at the oxygen-evolving complex (OEC) of photosystem \{II\} during the S2–S3 transition were investigated by the quantum mechanics/molecular mechanics (QM/MM) methodology. Two favorable reaction pathways were elucidated. Both reactions start by moving the Ca-bound water (W3) to the vacant Mn(III) coordination at the left-opened (L) or right-opened (R) form. The former reaction pathway, in which \{W3\} coordinates to the Mn4 at the S2-L form, has lower activation barriers than the latter. Thus, easier proton transfers from \{W3\} to the Tyr161 phenol anion can be performed. },
  Doi                      = {http://dx.doi.org/10.1016/j.cplett.2015.07.039},
  ISSN                     = {0009-2614},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0009261415005527}
}

@Article{Shoukourian201413,
  Title                    = {Monitoring Power Data: A first step towards a unified energy efficiency evaluation toolset for \{HPC\} data centers },
  Author                   = {Hayk Shoukourian and Torsten Wilde and Axel Auweter and Arndt Bode},
  Journal                  = {Environmental Modelling \& Software },
  Year                     = {2014},
  Note                     = {Thematic issue on Modelling and evaluating the sustainability of smart solutions },
  Pages                    = {13 - 26},
  Volume                   = {56},

  Abstract                 = {Abstract The energy consumption of High Performance Computing (HPC) systems, which are the key technology for many modern computation-intensive applications, is rapidly increasing in parallel with their performance improvements. This increase leads \{HPC\} data centers to focus on three major challenges: the reduction of overall environmental impacts, which is driven by policy makers; the reduction of operating costs, which are increasing due to rising system density and electrical energy costs; and the 20 MW power consumption boundary for Exascale computing systems, which represent the next thousandfold increase in computing capability beyond the currently existing petascale systems. Energy efficiency improvements will play a major part in addressing these challenges. This paper presents a toolset, called Power Data Aggregation Monitor (PowerDAM), which collects and evaluates data from all aspects of the \{HPC\} data center (e.g. environmental information, site infrastructure, information technology systems, resource management systems, and applications). The aim of PowerDAM is not to improve the \{HPC\} data center's energy efficiency, but is to collect energy relevant data for analysis without which energy efficiency improvements would be non-trivial and incomplete. Thus, PowerDAM represents a first step towards a truly unified energy efficiency evaluation toolset needed for improving the overall energy efficiency of \{HPC\} data centers. },
  Doi                      = {http://dx.doi.org/10.1016/j.envsoft.2013.11.011},
  ISSN                     = {1364-8152},
  Keywords                 = {Energy consumption},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1364815213002934}
}

@Article{Sibai201441,
  Title                    = {Performance modeling and analysis of parallel Gaussian elimination on multi-core computers },
  Author                   = {Fadi N. Sibai},
  Journal                  = {Journal of King Saud University - Computer and Information Sciences },
  Year                     = {2014},
  Number                   = {1},
  Pages                    = {41 - 54},
  Volume                   = {26},

  Abstract                 = {Abstract Gaussian elimination is used in many applications and in particular in the solution of systems of linear equations. This paper presents mathematical performance models and analysis of four parallel Gaussian Elimination methods (precisely the Original method and the new Meet in the Middle –MiM– algorithms and their variants with \{SIMD\} vectorization) on multi-core systems. Analytical performance models of the four methods are formulated and presented followed by evaluations of these models with modern multi-core systems’ operation latencies. Our results reveal that the four methods generally exhibit good performance scaling with increasing matrix size and number of cores. \{SIMD\} vectorization only makes a large difference in performance for low number of cores. For a large matrix size (n ⩾ 16 K), the performance difference between the MiM and Original methods falls from 16× with four cores to 4× with 16 K cores. The efficiencies of all four methods are low with 1 K cores or more stressing a major problem of multi-core systems where the network-on-chip and memory latencies are too high in relation to basic arithmetic operations. Thus Gaussian Elimination can greatly benefit from the resources of multi-core systems, but higher performance gains can be achieved if multi-core systems can be designed with lower memory operation, synchronization, and interconnect communication latencies, requirements of utmost importance and challenge in the exascale computing age. },
  Doi                      = {http://dx.doi.org/10.1016/j.jksuci.2013.03.002},
  ISSN                     = {1319-1578},
  Keywords                 = {Gaussian elimination},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1319157813000086}
}

@Article{Siegel20123119,
  Title                    = {Analysis of communication costs for domain decomposed Monte Carlo methods in nuclear reactor analysis },
  Author                   = {A. Siegel and K. Smith and P. Fischer and V. Mahadevan},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2012},
  Number                   = {8},
  Pages                    = {3119 - 3125},
  Volume                   = {231},

  Abstract                 = {A domain decomposed Monte Carlo communication kernel is used to carry out performance tests to establish the feasibility of using Monte Carlo techniques for practical Light Water Reactor (LWR) core analyses. The results of the prototype code are interpreted in the context of simplified performance models which elucidate key scaling regimes of the parallel algorithm. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2011.12.014},
  ISSN                     = {0021-9991},
  Keywords                 = {Monte Carlo},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999111007261}
}

@Article{Siegel2013901,
  Title                    = {The effect of load imbalances on the performance of Monte Carlo algorithms in \{LWR\} analysis },
  Author                   = {A.R. Siegel and K. Smith and P.K. Romano and B. Forget and K. Felker},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2013},
  Pages                    = {901 - 911},
  Volume                   = {235},

  Abstract                 = {A model is developed to predict the impact of particle load imbalances on the performance of domain-decomposed Monte Carlo neutron transport algorithms. Expressions for upper bound performance “penalties” are derived in terms of simple machine characteristics, material characterizations and initial particle distributions. The hope is that these relations can be used to evaluate tradeoffs among different memory decomposition strategies in next generation Monte Carlo codes, and perhaps as a metric for triggering particle redistribution in production codes. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2012.06.012},
  ISSN                     = {0021-9991},
  Keywords                 = {Monte Carlo},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999112003191}
}

@Article{Silva2014229,
  Title                    = {Summary of \{WG6\} and WG6+1: Theory and simulations of plasma based accelerators },
  Author                   = {Luís O. Silva},
  Journal                  = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment },
  Year                     = {2014},
  Note                     = {Proceedings of the first European Advanced Accelerator Concepts Workshop 2013 },
  Pages                    = {229 - 230},
  Volume                   = {740},

  Abstract                 = {Abstract The summary of the main topics covered by the contributed talks of the working group on Theory and Simulations (WG6) and of the joint session between \{WG6\} and \{WG1\} are presented. The conclusions of the \{WG6\} discussion sessions are also outlined. },
  Doi                      = {http://dx.doi.org/10.1016/j.nima.2014.01.037},
  ISSN                     = {0168-9002},
  Keywords                 = {Theory and numerical simulations},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0168900214000758}
}

@InCollection{Singh2016,
  Title                    = {Nanoscale Memristor },
  Author                   = {T. Singh},
  Booktitle                = {Reference Module in Materials Science and Materials Engineering },
  Publisher                = {Elsevier},
  Year                     = {2016},
  Note                     = {Current as of 28 October 2015},
  Pages                    = { - },

  Abstract                 = {Abstract The memristor; a portmanteau of ‘memory resistor’ was a term coined by circuit theorist Chua as a missing two-terminal nonlinear passive electrical component relating electric charge and magnetic flux linkage Chua. The operation of \{RRAM\} devices was recently connected to the memristor concept Strukov et al. Theoretical postulation of memristor is well described in Section 2 followed by the characterization of memristor as a device model. Behavior of memristor for different input signals like sinusoidal, pulses, triangular wave, and constant \{DC\} is documented in Section 4. The variation is reported as per resistance change with time and the effect of voltage of its operation that demonstrates the memristive effect. Various types of memristors has been documented in Section 5. Memristor can be implemented in many applications like as from nonvolatile memory to signal processing and everything in-between, including remote sensing, high-speed computing architectures, and neuromorphic and biological systems. Applications of this nanoscale device is given in Section 6 followed by summary. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-803581-8.04068-6},
  ISBN                     = {978-0-12-803581-8},
  Keywords                 = {Memristor},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780128035818040686}
}

@InCollection{Sitaram2012389,
  Title                    = {Chapter 10 - Future Trends and Research Directions },
  Author                   = {Dinkar Sitaram and Geetha Manjunath},
  Booktitle                = {Moving To The Cloud },
  Publisher                = {Syngress},
  Year                     = {2012},

  Address                  = {Boston},
  Editor                   = {Sitaram, Dinkar and Manjunath, Geetha },
  Pages                    = {389 - 425},

  Abstract                 = {This chapter describes future trends and research directions in cloud computing. The first few sections describe upcoming standards for cloud platform vendors and benchmarks that enable a cloud user to compare multiple cloud platforms. OpenCirrus, an open cloud research testbed, is described along with some of the details of novel tools developed for cloud-scale management. Since this book is developer oriented, the future of cloud application development leading towards end user programming is also covered in this chapter. Finally, the chapter concludes with a list of open research problems in cloud computing. Publisher Summary Since cloud computing is a rapidly evolving technology, this chapter describes some future developments that are likely to become important. A Gartner survey has shown that one of the major inhibitors to cloud computing is the lack of standardization leading to vendor lock-in. This is partly due to the fact that cloud computing is rapidly evolving, making standardization difficult. The chapter begins with the surveys of new standards that have the potential to address this concern. Another problem with vendor lock-in is that even if standards were to emerge, currently there is no accepted method for a cloud user to compare different cloud vendors and select the best for a particular application. This is in contrast to the situation in, say, databases, where there are benchmarks such as TPC-C that allow different database vendors to be compared. Following this, the chapter describes efforts underway to develop benchmarks that can help in assessing the suitability of a particular cloud system for an application. Open Cirrus, a large research testbed for research in cloud-computing technology, which may be very useful for readers interested in experimenting with novel cloud solutions or algorithms, is described. Finally, the chapter discusses research efforts that would make it possible for users who are not programmers to develop personal applications with simple scripts and programs. },
  Doi                      = {http://dx.doi.org/10.1016/B978-1-59749-725-1.00010-X},
  ISBN                     = {978-1-59749-725-1},
  Keywords                 = {Cloud computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B978159749725100010X}
}

@Article{Sitaraman2016,
  Title                    = {Balancing conflicting requirements for grid and particle decomposition in continuum-Lagrangian solvers },
  Author                   = {Hariswaran Sitaraman and Ray Grout},
  Journal                  = {Parallel Computing },
  Year                     = {2016},
  Pages                    = {1 - 21},
  Volume                   = {52},

  Abstract                 = {Abstract Load balancing strategies for hybrid solvers that involve grid based partial differential equation solution coupled with particle tracking are presented in this paper. A typical Message Passing Interface (MPI) based parallelization of grid based solves are done using a spatial domain decomposition while particle tracking is primarily done using either of the two techniques. One of the techniques is to distribute the particles to \{MPI\} ranks to whose grid they belong to while the other is to share the particles equally among all ranks, irrespective of their spatial location. The former technique provides spatial locality for field interpolation but cannot assure load balance in terms of number of particles, which is achieved by the latter. The two techniques are compared for a case of particle tracking in a homogeneous isotropic turbulence box as well as a turbulent jet case. A strong scaling study is performed to more than 32,000 cores, which results in particle densities representative of anticipated exascale machines. The use of alternative implementations of \{MPI\} collectives and efficient load equalization strategies are studied to reduce data communication overheads. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2015.10.010},
  ISSN                     = {0167-8191},
  Keywords                 = {Load balancing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819115001428}
}

@Article{Sitaraman20161,
  Title                    = {Balancing conflicting requirements for grid and particle decomposition in continuum-Lagrangian solvers },
  Author                   = {Hariswaran Sitaraman and Ray Grout},
  Journal                  = {Parallel Computing },
  Year                     = {2016},
  Pages                    = {1 - 21},
  Volume                   = {52},

  Abstract                 = {Abstract Load balancing strategies for hybrid solvers that involve grid based partial differential equation solution coupled with particle tracking are presented in this paper. A typical Message Passing Interface (MPI) based parallelization of grid based solves are done using a spatial domain decomposition while particle tracking is primarily done using either of the two techniques. One of the techniques is to distribute the particles to \{MPI\} ranks to whose grid they belong to while the other is to share the particles equally among all ranks, irrespective of their spatial location. The former technique provides spatial locality for field interpolation but cannot assure load balance in terms of number of particles, which is achieved by the latter. The two techniques are compared for a case of particle tracking in a homogeneous isotropic turbulence box as well as a turbulent jet case. A strong scaling study is performed to more than 32,000 cores, which results in particle densities representative of anticipated exascale machines. The use of alternative implementations of \{MPI\} collectives and efficient load equalization strategies are studied to reduce data communication overheads. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2015.10.010},
  ISSN                     = {0167-8191},
  Keywords                 = {Load balancing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819115001428}
}

@Article{Smith20132102,
  Title                    = {Eppur Si Muove! The 2013 Nobel Prize in Chemistry },
  Author                   = {Jeremy C. Smith and Benoît Roux},
  Journal                  = {Structure },
  Year                     = {2013},
  Number                   = {12},
  Pages                    = {2102 - 2105},
  Volume                   = {21},

  Abstract                 = {The 2013 Nobel Prize in Chemistry has been awarded to Martin Karplus, Michael Levitt, and Arieh Warshel for their work on developing computational methods to study complex chemical systems. Their work has led to mechanistic critical insights into chemical systems both large and small and has enabled progress in a number of different fields, including structural biology. },
  Doi                      = {http://dx.doi.org/10.1016/j.str.2013.11.005},
  ISSN                     = {0969-2126},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0969212613004395}
}

@InProceedings{SnytnkovTechnology2015,
  Title                    = {A technology for the design of hybrid supercomputer simulation codes for relativistic particle electrodynamics},
  Author                   = {Snytnkov, AV and Boronina, MA and Mesyats, EA and Romanenko, AA},
  Booktitle                = {Суперкомпьютерные дни в России: Труды международной конференции},
  Year                     = {2015},
  Pages                    = {17-25},
  Publisher                = {М.: Изд-во МГУ}
}

@Article{Sosonkina201321,
  Title                    = {Adjusting process count on demand for petascale global optimization },
  Author                   = {Masha Sosonkina and Layne T. Watson and Nicholas R. Radcliffe and Rafael T. Haftka and Michael W. Trosset},
  Journal                  = {Parallel Computing },
  Year                     = {2013},
  Number                   = {1},
  Pages                    = {21 - 35},
  Volume                   = {39},

  Abstract                 = {There are many challenges that need to be met before efficient and reliable computation at the petascale is possible. Many scientific and engineering codes running at the petascale are likely to be memory intensive, which makes thrashing a serious problem for many petascale applications. One way to overcome this challenge is to use a dynamic number of processes, so that the total amount of memory available for the computation can be increased on demand. This paper describes modifications made to the massively parallel global optimization code pVTdirect in order to allow for a dynamic number of processes. In particular, the modified version of the code monitors memory use and spawns new processes if the amount of available memory is determined to be insufficient. The primary design challenges are discussed, and performance results are presented and analyzed. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2012.11.001},
  ISSN                     = {0167-8191},
  Keywords                 = {Petascale},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819112000890}
}

@Article{Spotz20152097,
  Title                    = {Aeras: A Next Generation Global Atmosphere Model },
  Author                   = {William F. Spotz and Thomas M. Smith and Irina P. Demeshko and Jeffrey A. Fike},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {2097 - 2106},
  Volume                   = {51},

  Abstract                 = {Abstract Sandia National Laboratories is developing a new global atmosphere model named Aeras that is performance portable and supports the quantification of uncertainties. These next-generation capabilities are enabled by building Aeras on top of Albany, a code base that supports the rapid development of scientific application codes while leveraging Sandia's foundational mathematics and computer science packages in Trilinos and Dakota. Embedded uncertainty quantification (UQ) is an original design capability of Albany, and performance portability is a recent upgrade. Other required features, such as shell-type elements, spectral elements, efficient explicit and semi-implicit time-stepping, transient sensitivity analysis, and concurrent ensembles, were not components of Albany as the project began, and have been (or are being) added by the Aeras team. We present early \{UQ\} and performance portability results for the shallow water equations. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.478},
  ISSN                     = {1877-0509},
  Keywords                 = {Global atmosphere model},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915012867}
}

@Article{Srinivasa2012256,
  Title                    = {Effcient Shared-array Accesses in Ab Initio Nuclear Structure Calculations on Multicore Architectures },
  Author                   = {Avinash Srinivasa and Masha Sosonkina and Pieter Maris and James P. Vary},
  Journal                  = {Procedia Computer Science },
  Year                     = {2012},
  Note                     = {Proceedings of the International Conference on Computational Science, \{ICCS\} 2012 },
  Pages                    = {256 - 265},
  Volume                   = {9},

  Abstract                 = {With the increase in the processing core counts on modern computing platforms, the main memory accesses present a considerable execution bottleneck, leading to poor scalability in multithreaded applications. Even when the memory is physically divided into separate banks, each associated with a set of cores, i.e., exhibiting the so called nonuniform memory access (NUMA) architecture, the access time to the shared data structures may be detrimental to the scalability. Hence, it is imperative to carefully map large shared arrays to speciﬁc memory banks based on the nature of the computation and the multithreaded parallelism characteristics. This paper describes memory-pinning strategies pertinent to sparse matrix-vector multiplication and vector orthogonalization phases of an ab initio nuclear structure computation performed by the \{MFDn\} package. Several nuclei and nuclear interactions were considered in the large-scale test cases with the dimensions of the sparse symmetric matrices ranging from 32 million to 320 million. Performance gains of up to 25% were observed with the proposed strategies as compared to the default memory placement policy. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2012.04.027},
  ISSN                     = {1877-0509},
  Keywords                 = {Nonuniform memory access (NUMA) node},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050912001482}
}

@Article{Stan200920,
  Title                    = {Discovery and design of nuclear fuels },
  Author                   = {Marius Stan},
  Journal                  = {Materials Today },
  Year                     = {2009},
  Number                   = {11},
  Pages                    = {20 - 28},
  Volume                   = {12},

  Abstract                 = {To facilitate the discovery and design of innovative nuclear fuels, multi-scale models and simulations are used to predict irradiation effects on properties such as thermal conductivity, oxygen diffusivity, and thermal expansion. The multi-scale approach is illustrated using results on ceramic fuels, with a focus on predictions of point defect concentration, stoichiometry, and phase stability. The high performance computer simulations include coupled heat transport, diffusion, and thermal expansion, and gas bubble formation and evolution in a fuel element consisting of \{UO2\} fuel and metallic cladding. The second part of the paper is dedicated to a discussion of an international strategy for developing advanced, innovative nuclear fuels. Four initiatives are proposed to accelerate the discovery and design of new materials: (a) Create Institutes for Materials Discovery and Design, (b) Create an International Knowledgebase for experimental data, models (mathematical expressions), and simulations (codes), (c) Improve education and (d) Set up international collaborations. },
  Doi                      = {http://dx.doi.org/10.1016/S1369-7021(09)70295-0},
  ISSN                     = {1369-7021},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1369702109702950}
}

@Article{Stantchev20081339,
  Title                    = {Fast parallel Particle-To-Grid interpolation for plasma \{PIC\} simulations on the \{GPU\} },
  Author                   = {George Stantchev and William Dorland and Nail Gumerov},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2008},
  Note                     = {General-Purpose Processing using Graphics Processing Units },
  Number                   = {10},
  Pages                    = {1339 - 1349},
  Volume                   = {68},

  Abstract                 = {Particle-In-Cell (PIC) methods have been widely used for plasma physics simulations in the past three decades. To ensure an acceptable level of statistical accuracy relatively large numbers of particles are needed. State-of-the-art Graphics Processing Units (GPUs), with their high memory bandwidth, hundreds of \{SPMD\} processors, and half-a-teraflop performance potential, offer a viable alternative to distributed memory parallel computers for running medium-scale \{PIC\} plasma simulations on inexpensive commodity hardware. In this paper, we present an overview of a typical plasma \{PIC\} code and discuss its \{GPU\} implementation. In particular we focus on fast algorithms for the performance bottleneck operation of Particle-To-Grid interpolation. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2008.05.009},
  ISSN                     = {0743-7315},
  Keywords                 = {\{GPU\} computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731508000944}
}

@Article{Steer20129,
  Title                    = {Decision tree ensembles for online operation of large smart grids },
  Author                   = {Kent C.B. Steer and Andrew Wirth and Saman K. Halgamuge},
  Journal                  = {Energy Conversion and Management },
  Year                     = {2012},
  Pages                    = {9 - 18},
  Volume                   = {59},

  Abstract                 = {Smart grids utilise omnidirectional data transfer to operate a network of energy resources. Associated technologies present operators with greater control over system elements and more detailed information on the system state. While these features may improve the theoretical optimal operating performance, determining the optimal operating strategy becomes more difficult. In this paper, we show how a decision tree ensemble or ‘forest’ can produce a near-optimal control strategy in real time. The approach substitutes the decision forest for the simulation–optimisation sub-routine commonly employed in receding horizon controllers. The method is demonstrated on a small and a large network, and compared to controllers employing particle swarm optimisation and evolutionary strategies. For the smaller network the proposed method performs comparably in terms of total energy usage, but delivers a greater demand deficit. On the larger network the proposed method is superior with respect to all measures. We conclude that the method is useful when the time required to evaluate possible strategies via simulation is high. },
  Doi                      = {http://dx.doi.org/10.1016/j.enconman.2012.01.010},
  ISSN                     = {0196-8904},
  Keywords                 = {Smart grids},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S019689041200026X}
}

@Article{Stefanov2015625,
  Title                    = {Dynamically Reconfigurable Distributed Modular Monitoring System for Supercomputers (DiMMon) },
  Author                   = {Konstantin Stefanov and Vladimir Voevodin and Sergey Zhumatiy and Vadim Voevodin},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {4th International Young Scientist Conference on Computational Science },
  Pages                    = {625 - 634},
  Volume                   = {66},

  Abstract                 = {Abstract A design for a new dynamically reconfigurable distributed modular monitoring system framework is proposed in this paper. The proposed design allows combining both monitoring tasks (supercomputer ‘health’ monitoring and performance monitoring) in one monitoring system. Our approach allows different parts of the monitoring system process only the data needed for the task assigned to these parts. This helps to process a lot of performance data and to get information about dynamic features of heavy parallel tasks. Another feature of our framework is the ability to calculate performance metrics on-the-fly, dynamically creating processing modules for every job or other objects of interest. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.11.071},
  ISSN                     = {1877-0509},
  Keywords                 = {monitoring},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915034201}
}

@Article{STERN20151,
  Title                    = {Recent progress in \{CFD\} for naval architecture and ocean engineering },
  Author                   = {Frederick Stern and Zhaoyuan Wang and Jianming Yang and Hamid Sadat-Hosseini and Maysam Mousaviraad and Shanti Bhushan and Matteo Diez and Sung-Hwan Yoon and Ping-Chen Wu and Seong Mo Yeon and Timur Dogan and Dong-Hwan Kim and Silvia Volpi and Michael Conger and Thad Michael and Tao Xing and Robert S. Thodal and Joachim L. Grenestedt},
  Journal                  = {Journal of Hydrodynamics, Ser. B },
  Year                     = {2015},
  Number                   = {1},
  Pages                    = {1 - 23},
  Volume                   = {27},

  Abstract                 = {Abstract An overview is provided of CFDShip-Iowa modeling, numerical methods and high performance computing (HPC), including both current V4.5 and V5.5 and next generation V6. Examples for naval architecture highlight capability and needs. High fidelity \{V6\} simulations for ocean engineering and fundamental physics describe increased resolution for analysis of physics of fluids. Uncertainty quantification research is overviewed as the first step towards development stochastic optimization. },
  Doi                      = {http://dx.doi.org/10.1016/S1001-6058(15)60452-8},
  ISSN                     = {1001-6058},
  Keywords                 = {CFD},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1001605815604528}
}

@Article{Stone2015,
  Title                    = {Atomic detail visualization of photosynthetic membranes with GPU-accelerated ray tracing },
  Author                   = {John E. Stone and Melih Sener and Kirby L. Vandivort and Angela Barragan and Abhishek Singharoy and Ivan Teo and João V. Ribeiro and Barry Isralewitz and Bo Liu and Boon Chong Goh and James C. Phillips and Craig MacGregor-Chatwin and Matthew P. Johnson and Lena F. Kourkoutis and C. Neil Hunter and Klaus Schulten},
  Journal                  = {Parallel Computing },
  Year                     = {2015},
  Pages                    = { - },

  Abstract                 = {Abstract The cellular process responsible for providing energy for most life on Earth, namely, photosynthetic light-harvesting, requires the cooperation of hundreds of proteins across an organelle, involving length and time scales spanning several orders of magnitude over quantum and classical regimes. Simulation and visualization of this fundamental energy conversion process pose many unique methodological and computational challenges. We present, in two accompanying movies, light-harvesting in the photosynthetic apparatus found in purple bacteria, the so-called chromatophore. The movies are the culmination of three decades of modeling efforts, featuring the collaboration of theoretical, experimental, and computational scientists. We describe the techniques that were used to build, simulate, analyze, and visualize the structures shown in the movies, and we highlight cases where scientific needs spurred the development of new parallel algorithms that efficiently harness \{GPU\} accelerators and petascale computers. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2015.10.015},
  ISSN                     = {0167-8191},
  Keywords                 = {Photosynthesis},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819115001593}
}

@Article{Straatsma2013,
  Title                    = {On eliminating synchronous communication in molecular simulations to improve scalability },
  Author                   = {T.P. Straatsma and Daniel G. Chavarría-Miranda},
  Journal                  = {Computer Physics Communications },
  Year                     = {2013},
  Number                   = {12},
  Pages                    = {2634 - 2640},
  Volume                   = {184},

  Abstract                 = {Molecular dynamics simulation, as a complementary tool to experimentation, has become an important methodology for the understanding and design of molecular systems as it provides access to properties that are difficult, impossible or prohibitively expensive to obtain experimentally. Many of the available software packages have been parallelized to take advantage of modern massively concurrent processing resources. The challenge in achieving parallel efficiency is commonly attributed to the fact that molecular dynamics algorithms are communication intensive. This paper illustrates how an appropriately chosen data distribution and asynchronous one-sided communication approach can be used to effectively deal with the data movement within the Global Arrays/ARMCI programming model framework. A new put_notify capability is presented here, allowing the implementation of the molecular dynamics algorithm without any explicit global or local synchronization or global data reduction operations. In addition, this push-data model is shown to very effectively allow hiding data communication behind computation. Rather than data movement or explicit global reductions, the implicit synchronization of the algorithm becomes the primary challenge for scalability. Without any explicit synchronous operations, the scalability of molecular simulations is shown to depend only on the ability to evenly balance computational load. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2013.01.009},
  ISSN                     = {0010-4655},
  Keywords                 = {One-sided communication},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S001046551300026X}
}

@Article{Straßburg20141580,
  Title                    = {Enhancing Monte Carlo Preconditioning Methods for Matrix Computations },
  Author                   = {Janko Straßburg and Vassil Alexandrov},
  Journal                  = {Procedia Computer Science },
  Year                     = {2014},
  Note                     = {2014 International Conference on Computational Science },
  Pages                    = {1580 - 1589},
  Volume                   = {29},

  Abstract                 = {Abstract An enhanced version of a stochastic \{SParse\} Approximate Inverse (SPAI) preconditioner for general matrices is presented. This method is used in contrast to the standard deterministic preconditioners computed by the deterministic SPAI, and its further optimized parallel variant- Modified \{SParse\} Approximate Inverse Preconditioner (MSPAI). Thus we present a Monte Carlo preconditioner that relies on the use of Markov Chain Monte Carlo (MCMC) methods to com- pute a rough matrix inverse first, which is further optimized by an iterative filter process and a parallel refinement, to enhance the accuracy of the preconditioner. Monte Carlo methods quantify the uncertainties by enabling us to estimate the non-zero elements of the inverse ma- trix with a given precision and certain probability. The advantage of this approach is that we use sparse Monte Carlo matrix inversion whose computational complexity is linear of the size of the matrix. The behaviour of the proposed algorithm is studied, its performance measured and compared with MSPAI. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2014.05.143},
  ISSN                     = {1877-0509},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050914003202}
}

@Article{Straßburg2013473,
  Title                    = {Facilitating analysis of Monte Carlo dense matrix inversion algorithm scaling behaviour through simulation },
  Author                   = {Janko Straßburg and Vassil N. Alexandrov},
  Journal                  = {Journal of Computational Science },
  Year                     = {2013},
  Note                     = {Scalable Algorithms for Large-Scale Systems Workshop (ScalA2011), Supercomputing 2011 },
  Number                   = {6},
  Pages                    = {473 - 479},
  Volume                   = {4},

  Abstract                 = {With the latest developments in the area of advanced computer architectures, we are already seeing large-scale machines at petascale level and are faced with the exascale computing challenge. All these require scalability at system, algorithmic and mathematical model levels. In particular, efficient scalable algorithms are required to bridge the performance gap. Being able to predict application demeanour, performance and scalability of currently used software on new supercomputers of different architectures, varying sizes, and utilising distinct ways of intercommunication, can be of great benefit for researchers as well as application developers. This paper is concerned with scaling characteristics of Monte Carlo based algorithms for matrix inversion. The algorithmic behaviour on both, a shared memory and a large-scale cluster system will be predicted with the help of an extreme-scale high-performance computing (HPC) simulator. },
  Doi                      = {http://dx.doi.org/10.1016/j.jocs.2013.01.003},
  ISSN                     = {1877-7503},
  Keywords                 = {Performance evaluation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S187775031300015X}
}

@Article{Subotic2013,
  Title                    = {Programmability and portability for exascale: Top down programming methodology and tools with StarSs },
  Author                   = {Vladimir Subotić and Steffen Brinkmann and Vladimir Marjanović and Rosa M. Badia and Jose Gracia and Christoph Niethammer and Eduard Ayguade and Jesus Labarta and Mateo Valero},
  Journal                  = {Journal of Computational Science },
  Year                     = {2013},
  Note                     = {Scalable Algorithms for Large-Scale Systems Workshop (ScalA2011), Supercomputing 2011 },
  Number                   = {6},
  Pages                    = {450 - 456},
  Volume                   = {4},

  Abstract                 = {StarSs is a task-based programming model that allows to parallelize sequential applications by means of annotating the code with compiler directives. The model further supports transparent execution of designated tasks on heterogeneous platforms, including clusters of GPUs. This paper focuses on the methodology and tools that complements the programming model forming a consistent development environment with the objective of simplifying the live of application developers. The programming environment includes the tools \{TAREADOR\} and TEMANEJO, which have been designed specifically for StarSs. TAREADOR, a Valgrind-based tool, allows a top-down development approach by assisting the programmer in identifying tasks and their data-dependencies across all concurrency levels of an application. \{TEMANEJO\} is a graphical debugger supporting the programmer by visualizing the task dependency tree on one hand, but also allowing to manipulate task scheduling or dependencies. These tools are complemented with a set of performance analysis tools (Scalasca, Cube and Paraver) that enable to fine tune StarSs application. },
  Doi                      = {http://dx.doi.org/10.1016/j.jocs.2013.01.008},
  ISSN                     = {1877-7503},
  Keywords                 = {Parallel programming models},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877750313000203}
}

@Article{Subotic2013450,
  Title                    = {Programmability and portability for exascale: Top down programming methodology and tools with StarSs },
  Author                   = {Vladimir Subotić and Steffen Brinkmann and Vladimir Marjanović and Rosa M. Badia and Jose Gracia and Christoph Niethammer and Eduard Ayguade and Jesus Labarta and Mateo Valero},
  Journal                  = {Journal of Computational Science },
  Year                     = {2013},
  Note                     = {Scalable Algorithms for Large-Scale Systems Workshop (ScalA2011), Supercomputing 2011 },
  Number                   = {6},
  Pages                    = {450 - 456},
  Volume                   = {4},

  Abstract                 = {StarSs is a task-based programming model that allows to parallelize sequential applications by means of annotating the code with compiler directives. The model further supports transparent execution of designated tasks on heterogeneous platforms, including clusters of GPUs. This paper focuses on the methodology and tools that complements the programming model forming a consistent development environment with the objective of simplifying the live of application developers. The programming environment includes the tools \{TAREADOR\} and TEMANEJO, which have been designed specifically for StarSs. TAREADOR, a Valgrind-based tool, allows a top-down development approach by assisting the programmer in identifying tasks and their data-dependencies across all concurrency levels of an application. \{TEMANEJO\} is a graphical debugger supporting the programmer by visualizing the task dependency tree on one hand, but also allowing to manipulate task scheduling or dependencies. These tools are complemented with a set of performance analysis tools (Scalasca, Cube and Paraver) that enable to fine tune StarSs application. },
  Doi                      = {http://dx.doi.org/10.1016/j.jocs.2013.01.008},
  ISSN                     = {1877-7503},
  Keywords                 = {Parallel programming models},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877750313000203}
}

@Article{Sugii2015226,
  Title                    = {Low-power-consumption fully depleted silicon-on-insulator technology },
  Author                   = {Nobuyuki Sugii},
  Journal                  = {Microelectronic Engineering },
  Year                     = {2015},
  Note                     = {Micro and Nanofabrication Breakthroughs for Electronics, \{MEMS\} and Life Sciences },
  Pages                    = {226 - 235},
  Volume                   = {132},

  Abstract                 = {Abstract Scaling the \{CMOS\} device has continuously improved its functionality and performance while lowering its power consumption and price. However, the current “scaled CMOS” technology faces several problems regarding power consumption, and a migration to new transistor structures is proceeding. “Fully depleted silicon on insulator” (FDSOI) technology can lower power consumption and improve performance of \{CMOS\} circuits with a capability of low-voltage operation. This article reviews advances in \{FDSOI\} technology: device structure, back-bias control function, fabrication process, demonstration of small variability of transistors, reliability including soft error, low voltage circuit design and silicon verification, and improvement in the energy efficiency of \{CMOS\} logic circuits. The strong requirement of further improvement in energy in the near future is finally pointed out. },
  Doi                      = {http://dx.doi.org/10.1016/j.mee.2014.08.004},
  ISSN                     = {0167-9317},
  Keywords                 = {\{FDSOI\} CMOS},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167931714003360}
}

@Article{Sundriyal20131157,
  Title                    = {Energy saving strategies for parallel applications with point-to-point communication phases },
  Author                   = {Vaibhav Sundriyal and Masha Sosonkina and Alexander Gaenko and Zhao Zhang},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2013},
  Number                   = {8},
  Pages                    = {1157 - 1169},
  Volume                   = {73},

  Abstract                 = {Abstract Although high-performance computing traditionally focuses on the efficient execution of large-scale applications, both energy and power have become critical concerns when approaching exascale. Drastic increases in the power consumption of supercomputers affect significantly their operating costs and failure rates. In modern microprocessor architectures, equipped with dynamic voltage and frequency scaling (DVFS) and \{CPU\} clock modulation (throttling), the power consumption may be controlled in software. Additionally, network interconnect, such as Infiniband, may be exploited to maximize energy savings while the application performance loss and frequency switching overheads must be carefully balanced. This paper advocates for a runtime assessment of such overheads by means of characterizing point-to-point communications into phases followed by analyzing the time gaps between the communication calls. Certain communication and architectural parameters are taken into consideration in the three proposed frequency scaling strategies, which differ with respect to their treatment of the time gaps. The experimental results are presented for \{NAS\} parallel benchmark problems as well as for the realistic parallel electronic structure calculations performed by the widely used quantum chemistry package GAMESS. For the latter, three different process-to-core mappings were studied as to their energy savings under the proposed frequency scaling strategies and under the existing state-of-the-art techniques. Close to the maximum energy savings were obtained with a low performance loss of 2% on the given platform. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2013.03.006},
  ISSN                     = {0743-7315},
  Keywords                 = {Dynamic voltage and frequency scaling},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731513000506}
}

@Article{Suryanarayanan2013671,
  Title                    = {PDES-MAS: Distributed Simulation of Multi-agent Systems },
  Author                   = {Vinoth Suryanarayanan and Georgios Theodoropoulos and Michael Lees},
  Journal                  = {Procedia Computer Science },
  Year                     = {2013},
  Note                     = {2013 International Conference on Computational Science },
  Pages                    = {671 - 681},
  Volume                   = {18},

  Abstract                 = {Abstract Multi-agent systems (MAS) are increasingly being acknowledged as a modelling paradigm for capturing the dynamics of complex systems in a wide range of domains, from system biology to adaptive socio-technical system of systems. The execution of such \{MAS\} simulations on parallel machines is a challenging problem due to their dynamic, non-deterministic, data-centric behaviour and nature. These problems are exacerbated as the scale of such \{MAS\} models increases. PDES-MAS is a distributed simulation kernel developed specifically to support \{MAS\} models addressing the problems of partitioning, load balancing and interest management in an integrated, transparent and adaptive manner. This paper presents an overview of PDES-MAS and for the first time it provides a quantitative evaluation of the system. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2013.05.231},
  ISSN                     = {1877-0509},
  Keywords                 = {Agent-based systems},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050913003748}
}

@InCollection{Talia2016,
  Title                    = {Chapter 5 - Research Trends in Big Data Analysis },
  Author                   = {Domenico Talia and Paolo Trunfio and Fabrizio Marozzo},
  Booktitle                = {Data Analysis in the Cloud },
  Publisher                = {Elsevier},
  Year                     = {2016},

  Address                  = {Boston},
  Editor                   = {Marozzo, Domenico TaliaPaolo TrunfioFabrizio },
  Pages                    = {123 - 138},
  Series                   = {Computer Science Reviews and Trends},

  Abstract                 = {Abstract Big data analysis is a very active research area with significant impact on industrial and scientific domains where is important to analyze very large and complex data repositories. In particular, in many cases data to be analyzed are stored in cloud platforms and elastic computing clouds facilities are exploited to speedup the analysis. This chapter outlines and discusses main research trends in big data analytics and cloud systems for managing and mining large-scale data repositories. Topics and trends in the areas of exascale computing and social data analysis are reported. Section 5.1 discusses issues and challenges for implementing massively parallel and/or distributed applications in the area of big data analysis on exascale systems. Section 5.2 discusses recent trends in social data analysis, with a focus on mining mobility patterns from large volumes of trajectory data from online social network data. Finally, Section 5.3 discusses key research areas for the implementation of scalable data analytics dealing with huge, distributed data sources. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-802881-0.00005-6},
  ISBN                     = {978-0-12-802881-0},
  Keywords                 = {Data-intensive exascale computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780128028810000056}
}

@InCollection{Talia2016123,
  Title                    = {Chapter 5 - Research Trends in Big Data Analysis },
  Author                   = {Domenico Talia and Paolo Trunfio and Fabrizio Marozzo},
  Booktitle                = {Data Analysis in the Cloud },
  Publisher                = {Elsevier},
  Year                     = {2016},

  Address                  = {Boston},
  Editor                   = {Marozzo, Domenico TaliaPaolo TrunfioFabrizio },
  Pages                    = {123 - 138},
  Series                   = {Computer Science Reviews and Trends},

  Abstract                 = {Abstract Big data analysis is a very active research area with significant impact on industrial and scientific domains where is important to analyze very large and complex data repositories. In particular, in many cases data to be analyzed are stored in cloud platforms and elastic computing clouds facilities are exploited to speedup the analysis. This chapter outlines and discusses main research trends in big data analytics and cloud systems for managing and mining large-scale data repositories. Topics and trends in the areas of exascale computing and social data analysis are reported. Section 5.1 discusses issues and challenges for implementing massively parallel and/or distributed applications in the area of big data analysis on exascale systems. Section 5.2 discusses recent trends in social data analysis, with a focus on mining mobility patterns from large volumes of trajectory data from online social network data. Finally, Section 5.3 discusses key research areas for the implementation of scalable data analytics dealing with huge, distributed data sources. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-802881-0.00005-6},
  ISBN                     = {978-0-12-802881-0},
  Keywords                 = {Data-intensive exascale computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780128028810000056}
}

@InCollection{Talia201677,
  Title                    = {Chapter 4 - Designing and Supporting Scalable Data Analytics },
  Author                   = {Domenico Talia and Paolo Trunfio and Fabrizio Marozzo},
  Booktitle                = {Data Analysis in the Cloud },
  Publisher                = {Elsevier},
  Year                     = {2016},

  Address                  = {Boston},
  Editor                   = {Marozzo, Domenico TaliaPaolo TrunfioFabrizio },
  Pages                    = {77 - 122},
  Series                   = {Computer Science Reviews and Trends},

  Abstract                 = {Abstract This chapter presents innovative systems existing on clouds for designing and implementing scalable data analytics applications. Methods for application development based on some of the discussed systems are reported and explained on real application cases. Section 4.1 introduces a series of software frameworks designed and used for implementing data analysis application on clouds systems. Section 4.2 discusses a workflow-based scalable framework and how it can be used for designing scalable data analytics applications on clouds. Section 4.3 presents a workflow-based paradigm and two associated languages for programming data analysis applications on clouds. Finally, Section 4.4 describes a set of data analysis case studies that have been implemented with the programming languages discussed in the previous sections. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-802881-0.00004-4},
  ISBN                     = {978-0-12-802881-0},
  Keywords                 = {Swift},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780128028810000044}
}

@InCollection{Talia2016xi,
  Title                    = {Preface },
  Author                   = {Domenico Talia and Paolo Trunfio and Fabrizio Marozzo},
  Booktitle                = {Data Analysis in the Cloud },
  Publisher                = {Elsevier},
  Year                     = {2016},

  Address                  = {Boston},
  Editor                   = {Marozzo, Domenico TaliaPaolo TrunfioFabrizio },
  Pages                    = {xi - xii},
  Series                   = {Computer Science Reviews and Trends},

  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-802881-0.00009-3},
  ISBN                     = {978-0-12-802881-0},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780128028810000093}
}

@Article{Tanaka2016216,
  Title                    = {Implementation of incremental variational formulations based on the numerical calculation of derivatives using hyper dual numbers },
  Author                   = {Masato Tanaka and Daniel Balzani and Jörg Schröder},
  Journal                  = {Computer Methods in Applied Mechanics and Engineering },
  Year                     = {2016},
  Pages                    = {216 - 241},
  Volume                   = {301},

  Abstract                 = {Abstract In this paper, novel implementation schemes for the automatic calculation of internal variables, stresses and consistent tangent moduli for incremental variational formulations (IVFs) describing inelastic material behavior are proposed. \{IVFs\} recast inelasticity theory as an equivalent optimization problem where the incremental stress potential within a discrete time interval is minimized in order to obtain the values of internal variables. In the so-called Multilevel Newton–Raphson method for the inelasticity theory, this minimization problem is typically solved by using second derivatives with respect to the internal variables. In addition to that, to calculate the stresses and moduli further second derivatives with respect to deformation tensors are required. Compared with classical formulations such as the return mapping method, the \{IVFs\} are relatively new and their implementation is much less documented. Furthermore, higher order derivatives are required in the algorithms demanding increased implementation efforts. Therefore, even though \{IVFs\} are mathematically and physically elegant, their application is not standard. Here, novel approaches for the implementation of \{IVFs\} using \{HDNs\} of second and higher order are presented to arrive at a fully automatic and robust scheme with computer accuracy. The proposed formulations are quite general and can be applied to a broad range of different constitutive models, which means that once the proposed schemes are implemented as a framework, any other dissipative material model can be implemented in a straightforward way by solely modifying the constitutive functions. These include the Helmholtz free energy function, the dissipation potential function and additional side constraints such as e.g. the yield function in the case of plasticity. Its uncomplicated implementation for associative finite strain elasto-plasticity and performance is illustrated by some representative numerical examples. },
  Doi                      = {http://dx.doi.org/10.1016/j.cma.2015.12.010},
  ISSN                     = {0045-7825},
  Keywords                 = {Inelasticity},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045782515004156}
}

@Article{Teukolsky2016,
  Title                    = {Formulation of discontinuous Galerkin methods for relativistic astrophysics },
  Author                   = {Saul A. Teukolsky},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2016},
  Pages                    = { - },

  Abstract                 = {Abstract The \{DG\} algorithm is a powerful method for solving pdes, especially for evolution equations in conservation form. Since the algorithm involves integration over volume elements, it is not immediately obvious that it will generalize easily to arbitrary time-dependent curved spacetimes. We show how to formulate the algorithm in such spacetimes for applications in relativistic astrophysics. We also show how to formulate the algorithm for equations in non-conservative form, such as Einstein's field equations themselves. We find two computationally distinct formulations in both cases, one of which has seldom been used before for flat space in curvilinear coordinates but which may be more efficient. We also give a new derivation of the \{ALE\} algorithm (Arbitrary Lagrangian–Eulerian) using 4-vector methods that is much simpler than the usual derivation and explains why the method preserves the conservation form of the equations. The various formulations are explored with some simple numerical experiments that also investigate the effect of the metric identities on the results. The results of this paper may also be of interest to practitioners of \{DG\} working with curvilinear elements in flat space. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2016.02.031},
  ISSN                     = {0021-9991},
  Keywords                 = {Discontinuous Galerkin},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999116000954}
}

@Article{Theodoropoulos201444,
  Title                    = {Editorial: Special Issue on Extreme Scale Parallel Architectures and Systems },
  Author                   = {Georgios Theodoropoulos and Kostas Katrinis and Rolf Riesen and Shoukat Ali},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2014},
  Note                     = {Special Issue on Extreme Scale Parallel Architectures and Systems, Cryptography in Cloud Computing and Recent Advances in Parallel and Distributed Systems, \{ICPADS\} 2012 Selected Papers },
  Pages                    = {44 - 45},
  Volume                   = {30},

  Doi                      = {http://dx.doi.org/10.1016/j.future.2013.10.010},
  ISSN                     = {0167-739X},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X13002203}
}

@Article{Tian20101681,
  Title                    = {A multiresolution continuum simulation of the ductile fracture process },
  Author                   = {Rong Tian and Stephanie Chan and Shan Tang and Adrian M. Kopacz and Jian-Sheng Wang and Herng-Jeng Jou and Larbi Siad and Lars-Erik Lindgren and Gregory B. Olson and Wing Kam Liu},
  Journal                  = {Journal of the Mechanics and Physics of Solids },
  Year                     = {2010},
  Number                   = {10},
  Pages                    = {1681 - 1700},
  Volume                   = {58},

  Abstract                 = {With the advancement in computational science that is stepping into the Exascale era and experimental techniques that enable rapid reconstruction of the 3D microstructure, quantitative microstructure simulations at an unprecedented fidelity level are giving rise to new possibilities for linking microstructure to property. This paper presents recent advances in 3D computational modeling of ductile fracture in high toughness steels. Ductile fracture involves several concurrent and mutually interactive mechanisms at multiple length scales of microstructure. With serial sectioning tomographic techniques, a digital dataset of microstructure features associated with the fracture process has been experimentally reconstructed. In this study, primary particles are accurately and explicitly modeled while the secondary particles are modeled by a two scale multiresolution continuum model. The present numerical simulation captures detailed characteristics of the fracture process, such as zigzag crack morphology, critical void growth ratios, local stress triaxiality variation, and intervoid ligament structure. For the first time, fracture toughness is linked to multiscale microstructures in a realistic large 3D model. },
  Doi                      = {http://dx.doi.org/10.1016/j.jmps.2010.07.002},
  ISSN                     = {0022-5096},
  Keywords                 = {Multiresolution microstructure mechanics},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0022509610001316}
}

@InCollection{Tomar2013153,
  Title                    = {5 - Multiscale modeling of the structure and properties of ceramic nanocomposites },
  Author                   = {V. Tomar},
  Booktitle                = {Ceramic Nanocomposites },
  Publisher                = {Woodhead Publishing},
  Year                     = {2013},
  Editor                   = {Banerjee, Rajat and Manna, Indranil },
  Pages                    = {153 - 182},
  Series                   = {Woodhead Publishing Series in Composites Science and Engineering},

  Abstract                 = {Abstract: One of the most recent developments in ceramics has been the distribution of multiple phases in a ceramic composite at the nanoscopic length scale. An advanced nanocomposite microstructure such as that of polycrystalline silicon carbide (SiC)–silicon nitride (Si3N4) nanocomposites contains multiple length scales with grain boundary thickness of the order of 50 nm, SiC particle sizes of the order of 200–300 nm and Si3N4 grain sizes of the order of 0.8–1.5 μm. Designing the microstructure of such a composite for a targeted set of material properties is, therefore, a daunting task. Since the microstructure involves multiple length scales, multiscale analyses based material design is an appropriate approach for such a task. With this view, this chapter presents an overview of the current state of the art and work performed in this area. },
  Doi                      = {http://dx.doi.org/10.1533/9780857093493.1.153},
  ISBN                     = {978-0-85709-338-7},
  Keywords                 = {ceramic nanocomposites},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780857093387500054}
}

@Article{Tonon2016,
  Title                    = {Contextualized ranking of entity types based on knowledge graphs },
  Author                   = {Alberto Tonon and Michele Catasta and Roman Prokofyev and Gianluca Demartini and Karl Aberer and Philippe Cudré-Mauroux},
  Journal                  = {Web Semantics: Science, Services and Agents on the World Wide Web },
  Year                     = {2016},
  Pages                    = { - },

  Abstract                 = {Abstract A large fraction of online queries targets entities. For this reason, Search Engine Result Pages (SERPs) increasingly contain information about the searched entities such as pictures, short summaries, related entities, and factual information. A key facet that is often displayed on the \{SERPs\} and that is instrumental for many applications is the entity type. However, an entity is usually not associated to a single generic type in the background knowledge graph but rather to a set of more specific types, which may be relevant or not given the document context. For example, one can find on the Linked Open Data cloud the fact that Tom Hanks is a person, an actor, and a person from Concord, California. All these types are correct but some may be too general to be interesting (e.g., person), while other may be interesting but already known to the user (e.g., actor), or may be irrelevant given the current browsing context (e.g., person from Concord, California). In this paper, we define the new task of ranking entity types given an entity and its context. We propose and evaluate new methods to find the most relevant entity type based on collection statistics and on the knowledge graph structure interconnecting entities and types. An extensive experimental evaluation over several document collections at different levels of granularity (e.g., sentences, paragraphs) and different type hierarchies (including DBpedia, Freebase, and schema.org) shows that hierarchy-based approaches provide more accurate results when picking entity types to be displayed to the end-user. },
  Doi                      = {http://dx.doi.org/10.1016/j.websem.2015.12.005},
  ISSN                     = {1570-8268},
  Keywords                 = {Entity typing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1570826815001468}
}

@Article{Tramm2016,
  Title                    = {A task-based parallelism and vectorized approach to 3D Method of Characteristics (MOC) reactor simulation for high performance computing architectures },
  Author                   = {John R. Tramm and Geoffrey Gunow and Tim He and Kord S. Smith and Benoit Forget and Andrew R. Siegel},
  Journal                  = {Computer Physics Communications },
  Year                     = {2016},
  Pages                    = { - },

  Abstract                 = {Abstract In this study we present and analyze a formulation of the 3D Method of Characteristics (MOC) technique applied to the simulation of full core nuclear reactors. Key features of the algorithm include a task-based parallelism model that allows independent \{MOC\} tracks to be assigned to threads dynamically, ensuring load balancing, and a wide vectorizable inner loop that takes advantage of modern \{SIMD\} computer architectures. The algorithm is implemented in a set of highly optimized proxy applications in order to investigate its performance characteristics on CPU, GPU, and Intel Xeon Phi architectures. Speed, power, and hardware cost efficiencies are compared. Additionally, performance bottlenecks are identified for each architecture in order to determine the prospects for continued scalability of the algorithm on next generation \{HPC\} architectures. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2016.01.007},
  ISSN                     = {0010-4655},
  Keywords                 = {Method of Characteristics},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465516000266}
}

@Article{Tramm2015195,
  Title                    = {Memory bottlenecks and memory contention in multi-core Monte Carlo transport codes },
  Author                   = {John R. Tramm and Andrew R. Siegel},
  Journal                  = {Annals of Nuclear Energy },
  Year                     = {2015},
  Note                     = {Joint International Conference on Supercomputing in Nuclear Applications and Monte Carlo 2013, \{SNA\} + \{MC\} 2013. Pluri- and Trans-disciplinarity, Towards New Modeling and Numerical Simulation Paradigms },
  Pages                    = {195 - 202},
  Volume                   = {82},

  Abstract                 = {Abstract We have extracted a kernel that executes only the most computationally expensive steps of the Monte Carlo particle transport algorithm – the calculation of macroscopic cross sections – in an effort to expose bottlenecks within multi-core, shared memory architectures. },
  Doi                      = {http://dx.doi.org/10.1016/j.anucene.2014.08.038},
  ISSN                     = {0306-4549},
  Keywords                 = {Monte Carlo},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0306454914004332}
}

@Article{Trefethen2013,
  Title                    = {Energy-aware software: Challenges, opportunities and strategies },
  Author                   = {Anne E. Trefethen and Jeyarajan Thiyagalingam},
  Journal                  = {Journal of Computational Science },
  Year                     = {2013},
  Note                     = {Scalable Algorithms for Large-Scale Systems Workshop (ScalA2011), Supercomputing 2011 },
  Number                   = {6},
  Pages                    = {444 - 449},
  Volume                   = {4},

  Abstract                 = {Energy consumption of computing systems has become a major concern. Constrained by cost, environmental concerns and policy, minimising the energy foot-print of computing systems is one of the primary goals of many initiatives. As we move towards exascale computing, energy constraints become very real and are a major driver in design decisions. The issue is also apparent at the scale of desk top machines, where many core and accelerator chips are common and offer a spectrum of opportunities for balancing energy and performance. Conventionally, approaches for reducing energy consumption have been either at the operational level (such as powering down all or part of systems) or at the hardware design level (such as utilising specialised low-energy components). In this paper, we are interested in a different approach; energy-aware software. By measuring the energy consumption of a computer application and understanding where the energy usage lies, may allow a change of the software to provide opportunities for energy savings. In order to understand the complexities of this approach, we specifically look at multithreaded algorithms and applications. By an evaluation of a benchmark suite on multiple architectures and multiple environments, we show how basic parameters, such as threading options, compilers and frequencies, can impact energy consumption. As such, we provide an overview of the challenges that face software developers in this regard. We then offer a view of the directions that need to be taken and possible strategies needed for building energy-aware software. },
  Doi                      = {http://dx.doi.org/10.1016/j.jocs.2013.01.005},
  ISSN                     = {1877-7503},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877750313000173}
}

@Article{Trefethen2013444,
  Title                    = {Energy-aware software: Challenges, opportunities and strategies },
  Author                   = {Anne E. Trefethen and Jeyarajan Thiyagalingam},
  Journal                  = {Journal of Computational Science },
  Year                     = {2013},
  Note                     = {Scalable Algorithms for Large-Scale Systems Workshop (ScalA2011), Supercomputing 2011 },
  Number                   = {6},
  Pages                    = {444 - 449},
  Volume                   = {4},

  Abstract                 = {Energy consumption of computing systems has become a major concern. Constrained by cost, environmental concerns and policy, minimising the energy foot-print of computing systems is one of the primary goals of many initiatives. As we move towards exascale computing, energy constraints become very real and are a major driver in design decisions. The issue is also apparent at the scale of desk top machines, where many core and accelerator chips are common and offer a spectrum of opportunities for balancing energy and performance. Conventionally, approaches for reducing energy consumption have been either at the operational level (such as powering down all or part of systems) or at the hardware design level (such as utilising specialised low-energy components). In this paper, we are interested in a different approach; energy-aware software. By measuring the energy consumption of a computer application and understanding where the energy usage lies, may allow a change of the software to provide opportunities for energy savings. In order to understand the complexities of this approach, we specifically look at multithreaded algorithms and applications. By an evaluation of a benchmark suite on multiple architectures and multiple environments, we show how basic parameters, such as threading options, compilers and frequencies, can impact energy consumption. As such, we provide an overview of the challenges that face software developers in this regard. We then offer a view of the directions that need to be taken and possible strategies needed for building energy-aware software. },
  Doi                      = {http://dx.doi.org/10.1016/j.jocs.2013.01.005},
  ISSN                     = {1877-7503},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877750313000173}
}

@InCollection{Tsujiand2012125,
  Title                    = {Chapter Five - Optical Interconnects for Green Computers and Data Centers },
  Author                   = {Shinji Tsuji and and Takashi Takemoto},
  Publisher                = {Elsevier},
  Year                     = {2012},
  Editor                   = {Ali Hurson and Atif Memon},
  Pages                    = {125 - 201},
  Series                   = {Advances in Computers },
  Volume                   = {87},

  Abstract                 = {In this chapter, state-of-the-art optical interconnect technologies for supercomputers and data centers (DCs) are presented with optical devices and \{CMOS\} circuits, which are going to be fundamental building blocks of computer networks. Performance of leading edge systems is approaching exascale; however, we are forced to confront the energy problem not only in terms of performance improvement limited by thermal burnout but also by increasing energy consumption, especially in DCs. In this situation, optical signal to electronic signal (O/E) and electrical signal to optical signal (E/O) conversion devices should be placed adjacent to or inside a processor chip or memory chip, and optical devices fully integrated with \{CMOS\} circuits will be a key technology. The discussion includes what optical interconnects are and the requirements for their components, the board-to-board optical interconnect technology, and the Silicon photonics as a newly-state-of-the-art component technology to achieve future on-board optical transmission. The chapter is concluded with a roadmap of optical interconnects technology for exascale computing. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-396528-8.00005-5},
  ISSN                     = {0065-2458},
  Keywords                 = {Supercomputer},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780123965288000055}
}

@Article{Tucker2016,
  Title                    = {Eddy resolving simulations in aerospace – Invited paper (Numerical Fluid 2014) },
  Author                   = {Paul G. Tucker and James C. Tyacke},
  Journal                  = {Applied Mathematics and Computation },
  Year                     = {2016},
  Note                     = {The 9th International Symposium on Numerical Analysis of Fluid Flow and Heat Transfer - Numerical Fluids 2014 },
  Pages                    = {582 - 592},
  Volume                   = {272, Part 3},

  Abstract                 = {Abstract The future use of eddy resolving simulations (ERS) such as Large Eddy Simulation (LES), Direct Numerical Simulation (DNS) and related approaches in aerospace is explored. The turbulence modeling requirements with respect to aeroengines and aircraft is contrasted. For the latter, higher Reynolds numbers are more prevalent and this especially gives rise to the need for the hybridization of \{ERS\} methods with Reynolds Averaged Navier–Stokes (RANS) approaches. Zones where future use of pure \{ERS\} methods is now possible and those where hybridizations with \{RANS\} will be needed is outlined. The major focus is the aeroengine for which the component scales are much smaller. This gives rise to generally more benign Reynolds numbers. The use of eddy resolving methods in a wide range of zones in an aeroengine is discussed and the potential benefits and also cost drawbacks with such approaches noted. The tension when using such computationally intensive calculations in an area where the coupling of components and even the airframe and engine is becoming increasingly important is explored. Also, the numerical methods and meshing requirements are considered and the implications of \{ERS\} methods for future numerical algorithms. It is postulated that such simulations are ready now for niche uses in industry. However, to perform the scale of simulations that industry requires, to meet pressing environmental needs, challenges remain. For example, there is the need to develop optimal numerical methods that both map to the accuracy requirements for \{ERS\} and also future computer architectures. },
  Doi                      = {http://dx.doi.org/10.1016/j.amc.2015.02.018},
  ISSN                     = {0096-3003},
  Keywords                 = {LES},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S009630031500171X}
}

@Article{Tucker2016582,
  Title                    = {Eddy resolving simulations in aerospace – Invited paper (Numerical Fluid 2014) },
  Author                   = {Paul G. Tucker and James C. Tyacke},
  Journal                  = {Applied Mathematics and Computation },
  Year                     = {2016},
  Note                     = {The 9th International Symposium on Numerical Analysis of Fluid Flow and Heat Transfer - Numerical Fluids 2014 },
  Pages                    = {582 - 592},
  Volume                   = {272, Part 3},

  Abstract                 = {Abstract The future use of eddy resolving simulations (ERS) such as Large Eddy Simulation (LES), Direct Numerical Simulation (DNS) and related approaches in aerospace is explored. The turbulence modeling requirements with respect to aeroengines and aircraft is contrasted. For the latter, higher Reynolds numbers are more prevalent and this especially gives rise to the need for the hybridization of \{ERS\} methods with Reynolds Averaged Navier–Stokes (RANS) approaches. Zones where future use of pure \{ERS\} methods is now possible and those where hybridizations with \{RANS\} will be needed is outlined. The major focus is the aeroengine for which the component scales are much smaller. This gives rise to generally more benign Reynolds numbers. The use of eddy resolving methods in a wide range of zones in an aeroengine is discussed and the potential benefits and also cost drawbacks with such approaches noted. The tension when using such computationally intensive calculations in an area where the coupling of components and even the airframe and engine is becoming increasingly important is explored. Also, the numerical methods and meshing requirements are considered and the implications of \{ERS\} methods for future numerical algorithms. It is postulated that such simulations are ready now for niche uses in industry. However, to perform the scale of simulations that industry requires, to meet pressing environmental needs, challenges remain. For example, there is the need to develop optimal numerical methods that both map to the accuracy requirements for \{ERS\} and also future computer architectures. },
  Doi                      = {http://dx.doi.org/10.1016/j.amc.2015.02.018},
  ISSN                     = {0096-3003},
  Keywords                 = {LES},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S009630031500171X}
}

@Article{Tudoran2016274,
  Title                    = {JetStream: Enabling high throughput live event streaming on multi-site clouds },
  Author                   = {Radu Tudoran and Alexandru Costan and Olivier Nano and Ivo Santos and Hakan Soncu and Gabriel Antoniu},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2016},
  Pages                    = {274 - 291},
  Volume                   = {54},

  Abstract                 = {Abstract Scientific and commercial applications operate nowadays on tens of cloud datacenters around the globe, following similar patterns: they aggregate monitoring or sensor data, assess the QoS or run global data mining queries based on inter-site event stream processing. Enabling fast data transfers across geographically distributed sites allows such applications to manage the continuous streams of events in real time and quickly react to changes. However, traditional event processing engines often consider data resources as second-class citizens and support access to data only as a side-effect of computation (i.e. they are not concerned by the transfer of events from their source to the processing site). This is an efficient approach as long as the processing is executed in a single cluster where nodes are interconnected by low latency networks. In a distributed environment, consisting of multiple datacenters, with orders of magnitude differences in capabilities and connected by a WAN, this will undoubtedly lead to significant latency and performance variations. This is namely the challenge we address in this paper, by proposing JetStream, a high performance batch-based streaming middleware for efficient transfers of events between cloud datacenters. JetStream is able to self-adapt to the streaming conditions by modeling and monitoring a set of context parameters. It further aggregates the available bandwidth by enabling multi-route streaming across cloud sites, while at the same time optimizing resource utilization and increasing cost efficiency. The prototype was validated on tens of nodes from \{US\} and Europe datacenters of the Windows Azure cloud with synthetic benchmarks and a real-life application monitoring the \{ALICE\} experiment at CERN. The results show a 3× increase of the transfer rate using the adaptive multi-route streaming, compared to state of the art solutions. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2015.01.016},
  ISSN                     = {0167-739X},
  Keywords                 = {Cloud computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X15000333}
}

@Article{Uta2016144,
  Title                    = {Overcoming data locality: An in-memory runtime file system with symmetrical data distribution },
  Author                   = {Alexandru Uta and Andreea Sandu and Thilo Kielmann},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2016},
  Pages                    = {144 - 158},
  Volume                   = {54},

  Abstract                 = {Abstract In many-task computing (MTC), applications such as scientific workflows or parameter sweeps communicate via intermediate files; application performance strongly depends on the file system in use. The state of the art uses runtime systems providing in-memory file storage that is designed for data locality: files are placed on those nodes that write or read them. With data locality, however, task distribution conflicts with data distribution, leading to application slowdown, and worse, to prohibitive storage imbalance. To overcome these limitations, we present MemFS, a fully symmetrical, in-memory runtime file system that stripes files across all compute nodes, based on a distributed hash function. Our cluster experiments with Montage and \{BLAST\} workflows, using up to 512 cores, show that MemFS has both better performance and better scalability than the state-of-the-art, locality-based file system, AMFS. Furthermore, our evaluation on a public commercial cloud validates our cluster results. On this platform MemFS shows excellent scalability up to 1024 cores and is able to saturate the 10G Ethernet bandwidth when running \{BLAST\} and Montage. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2015.01.013},
  ISSN                     = {0167-739X},
  Keywords                 = {Many-task computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X15000308}
}

@Article{Valiev20101477,
  Title                    = {NWChem: A comprehensive and scalable open-source solution for large scale molecular simulations },
  Author                   = {M. Valiev and E.J. Bylaska and N. Govind and K. Kowalski and T.P. Straatsma and H.J.J. Van Dam and D. Wang and J. Nieplocha and E. Apra and T.L. Windus and W.A. de Jong},
  Journal                  = {Computer Physics Communications },
  Year                     = {2010},
  Number                   = {9},
  Pages                    = {1477 - 1489},
  Volume                   = {181},

  Abstract                 = {The latest release of \{NWChem\} delivers an open-source computational chemistry package with extensive capabilities for large scale simulations of chemical and biological systems. Utilizing a common computational framework, diverse theoretical descriptions can be used to provide the best solution for a given scientific problem. Scalable parallel implementations and modular software design enable efficient utilization of current computational architectures. This paper provides an overview of \{NWChem\} focusing primarily on the core theoretical modules provided by the code and their parallel performance. Program summary Program title: \{NWChem\} Catalogue identifier: AEGI_v1_0 Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AEGI_v1_0.html Program obtainable from: \{CPC\} Program Library, Queen's University, Belfast, N. Ireland Licensing provisions: Open Source Educational Community License No. of lines in distributed program, including test data, etc.: 11 709 543 No. of bytes in distributed program, including test data, etc.: 680 696 106 Distribution format: tar.gz Programming language: Fortran 77, C Computer: all Linux based workstations and parallel supercomputers, Windows and Apple machines Operating system: Linux, \{OS\} X, Windows Has the code been vectorised or parallelized?: Code is parallelized Classification: 2.1, 2.2, 3, 7.3, 7.7, 16.1, 16.2, 16.3, 16.10, 16.13 Nature of problem: Large-scale atomistic simulations of chemical and biological systems require efficient and reliable methods for ground and excited solutions of many-electron Hamiltonian, analysis of the potential energy surface, and dynamics. Solution method: Ground and excited solutions of many-electron Hamiltonian are obtained utilizing density-functional theory, many-body perturbation approach, and coupled cluster expansion. These solutions or a combination thereof with classical descriptions are then used to analyze potential energy surface and perform dynamical simulations. Additional comments: Full documentation is provided in the distribution file. This includes an \{INSTALL\} file giving details of how to build the package. A set of test runs is provided in the examples directory. The distribution file for this program is over 90 Mbytes and therefore is not delivered directly when download or Email is requested. Instead a html file giving details of how the program can be obtained is sent. Running time: Running time depends on the size of the chemical system, complexity of the method, number of cpu's and the computational task. It ranges from several seconds for serial \{DFT\} energy calculations on a few atoms to several hours for parallel coupled cluster energy calculations on tens of atoms or ab-initio molecular dynamics simulation on hundreds of atoms. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2010.04.018},
  ISSN                     = {0010-4655},
  Keywords                 = {NWChem},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465510001438}
}

@InCollection{Valles201569,
  Title                    = {Chapter 4 - Optimizing for Reacting Navier-Stokes Equations },
  Author                   = {Antonio Valles and Weiqun Zhang},
  Booktitle                = {High Performance Parallelism Pearls },
  Publisher                = {Morgan Kaufmann},
  Year                     = {2015},

  Address                  = {Boston},
  Editor                   = {Jeffers, James ReindersJim },
  Pages                    = {69 - 85},

  Abstract                 = {Abstract The optimizations discussed in this chapter significantly improved concurrency on both Intel Xeon Phi coprocessors and Intel Xeon processors. OpenMP scaling of 240 threads vs. one thread is now 100x, was 38x in first version for coprocessors. Similarly, processor scaling improved to 16x from 10x. The chapter discusses source modifications to transform fine-grain thread parallel approach to be more coarse-grain, memory allocation considerations on Intel Xeon Phi coprocessors, and source transformations to improve vectorization. In addition, this chapter briefly demonstrates how new features in \{VTune\} Amplifier \{XE\} can be used for OpenMP analysis. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-802118-7.00004-2},
  ISBN                     = {978-0-12-802118-7},
  Keywords                 = {Threading},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780128021187000042}
}

@Article{Vazquez2016,
  Title                    = {Alya: Multiphysics engineering simulation toward exascale },
  Author                   = {Mariano Vázquez and Guillaume Houzeaux and Seid Koric and Antoni Artigues and Jazmin Aguado-Sierra and Ruth Arís and Daniel Mira and Hadrien Calmet and Fernando Cucchietti and Herbert Owen and Ahmed Taha and Evan Dering Burness and José María Cela and Mateo Valero},
  Journal                  = {Journal of Computational Science },
  Year                     = {2016},
  Pages                    = { - },

  Abstract                 = {Abstract Alya is a multi-physics simulation code developed at Barcelona Supercomputing Center (BSC). From its inception Alya code is designed using advanced High Performance Computing programming techniques to solve coupled problems on supercomputers efficiently. The target domain is engineering, with all its particular features: complex geometries and unstructured meshes, coupled multi-physics with exotic coupling schemes and physical models, ill-posed problems, flexibility needs for rapidly including new models, etc. Since its beginnings in 2004, Alya has scaled well in an increasing number of processors when solving single-physics problems such as fluid mechanics, solid mechanics, acoustics, etc. Over time, we have made a concerted effort to maintain and even improve scalability for multi-physics problems. This poses challenges on multiple fronts, including: numerical models, parallel implementation, physical coupling models, algorithms and solution schemes, meshing process, etc. In this paper, we introduce Alya's main features and focus particularly on its solvers. We present Alya's performance up to 100.000 processors in Blue Waters, the \{NCSA\} supercomputer with selected multi-physics tests that are representative of the engineering world. The tests are incompressible flow in a human respiratory system, low Mach combustion problem in a kiln furnace, and coupled electro-mechanical contraction of the heart. We show scalability plots for all cases and discuss all aspects of such simulations, including solver convergence. },
  Doi                      = {http://dx.doi.org/10.1016/j.jocs.2015.12.007},
  ISSN                     = {1877-7503},
  Keywords                 = {Multi-physics coupling},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877750315300521}
}

@InCollection{Vázquez–Mayagoitia20143,
  Title                    = {Chapter One - Quantum Chemistry Methods with Multiwavelet Bases on Massive Parallel Computers },
  Author                   = {Álvaro Vázquez–Mayagoitia and W. Scott Thornton and Jeff R. Hammond and Robert J. Harrison},
  Publisher                = {Elsevier},
  Year                     = {2014},
  Editor                   = {Ralph A. Wheeler},
  Pages                    = {3 - 24},
  Series                   = {Annual Reports in Computational Chemistry },
  Volume                   = {10},

  Abstract                 = {Abstract Multiresolution analysis (MRA) is a general-purpose numerical framework to solve integral and partial differential equations that has proven to be especially successful in applications in physics and chemistry. \{MRA\} allows construction of an orthonormal basis with dynamic adaptive resolution and systematic improvability, hence, providing guaranteed finite precision. Sparse representation of many kernels allows for efficient computation. Multiresolution Adaptive Numerical Environment for Scientific Simulation code uses \{MRA\} in a multiwavelet basis with low-rank separation of functions and operators for efficient computation in many dimensions. In this chapter, we describe some of the key elements of this approach, some of its applications in chemistry (including static and time-dependent problems) and examine some of its strengths and weaknesses. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-444-63378-1.00001-X},
  ISSN                     = {1574-1400},
  Keywords                 = {Wavelets},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B978044463378100001X}
}

@Article{Verleye201310,
  Title                    = {Implementation of a 2D electrostatic Particle-in-Cell algorithm in unified parallel C with dynamic load-balancing },
  Author                   = {B. Verleye and P. Henri and R. Wuyts and G. Lapenta and K. Meerbergen},
  Journal                  = {Computers \& Fluids },
  Year                     = {2013},
  Note                     = {Selected contributions of the 23rd International Conference on Parallel Fluid Dynamics ParCFD2011 },
  Pages                    = {10 - 16},
  Volume                   = {80},

  Abstract                 = {The Particle-in-Cell (PIC) method is a Particle-Mesh technique that allows to efficiently simulate kinetic models. Among others applications, space weather simulations could be tackled by massively parallel Particle-in-Cell codes, to model the dynamics of space plasma disturbances. However, realistic Particle-Mesh plasma simulations require huge data sets and are computationally expensive. This is why high scalability must be achieved in order to perform the massively parallel plasma simulations required for space weather purposes. In Particle-Mesh techniques such as \{PIC\} simulations, computational particles are free to move on a fixed grid mesh and can show important inhomogeneity during computation. This results in an imbalanced work load between different threads that must be tackled. This paper reports on a 2D electrostatic \{PIC\} code in Unified Parallel C, developed for both plasma and gravitational simulations. The algorithm includes dynamic load-balancing capabilities. We compare different load-balancing strategies: one based on the particle distribution, and one based on computation time. We also present results of the simulation of the classical two-stream instability, and a simulation of a gravitational clustering experiment triggered by the Jeans instability. It is shown that both dynamic load-balancing based on computation time or on the number of particles are efficient for Particle-Mesh simulations where high particle inhomogeneities occur. },
  Doi                      = {http://dx.doi.org/10.1016/j.compfluid.2012.08.020},
  ISSN                     = {0045-7930},
  Keywords                 = {PIC},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045793012003362}
}

@Article{Vilches2015140,
  Title                    = {Adaptive Partitioning for Irregular Applications on Heterogeneous CPU-GPU Chips },
  Author                   = {Antonio Vilches and Rafael Asenjo and Angeles Navarro and Francisco Corbera and Rub́en Gran and María Garzarán},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {140 - 149},
  Volume                   = {51},

  Abstract                 = {Abstract Commodity processors are comprised of several \{CPU\} cores and one integrated GPU. To fully exploit this type of architectures, one needs to automatically determine how to partition the workload between both devices. This is specially challenging for irregular workloads, where each iteration's work is data dependent and shows control and memory divergence. In this paper, we present a novel adaptive partitioning strategy specially designed for irregular applications running on heterogeneous CPU-GPU chips. The main novelty of this work is that the size of the workload assigned to the \{GPU\} and \{CPU\} adapts dynamically to maximize the \{GPU\} and \{CPU\} utilization while balancing the workload among the devices. Our experimental results on an Intel Haswell architecture using a set of irregular benchmarks show that our approach outperforms exhaustive static and adaptive state-of-the-art approaches in terms of performance and energy consumption. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.213},
  ISSN                     = {1877-0509},
  Keywords                 = {Heterogeneous CPU-GPU chips},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915010212}
}

@Article{vlad2001gridless,
  Title                    = {Gridless finite-size-particle plasma simulation},
  Author                   = {Vlad, G and Briguglio, S and Fogaccia, G and Di Martino, B},
  Journal                  = {Computer physics communications},
  Year                     = {2001},
  Number                   = {1},
  Pages                    = {58--77},
  Volume                   = {134},

  Publisher                = {Elsevier}
}

@InCollection{Voderhobli2015129,
  Title                    = {Chapter 8 - Achieving the Green Theme Through the Use of Traffic Characteristics in Data Centers },
  Author                   = {Kiran Voderhobli},
  Booktitle                = {Green Information Technology },
  Publisher                = {Morgan Kaufmann},
  Year                     = {2015},

  Address                  = {Boston},
  Editor                   = {Akhgar, Mohammad DastbazColin PattinsonBabak },
  Pages                    = {129 - 148},

  Abstract                 = {Abstract The phrase “sustainable computing” covers multiple areas of Green ICT, including architectures, infrastructure, software, hardware and computing processes. Creating a sustainable computing environment requires optimizing the above areas to adopt the “green” theme. Today’s network infrastructures give sustainability a serious consideration and reducing energy consumption is usually one of the deployment policies. Bringing down the carbon foot-print of computing, needs changes to the way \{IT\} is deployed, and this is not just in terms of design decisions. There is more to sustainability than just adding energy reduction remedies on an ad-hoc basis. Modern networks deal with high volumes of network data due to wide spread deployment of corporate networks and cloud based services. Computing architectures and software are evolving to accommodate resource sharing, light-weight processes, efficient task scheduling etc. to embrace the green theme. But often, the seemingly smaller background network processes are side-stepped when it comes to optimising for sustainability. This chapter explains the importance of studying network traffic patterns to look for any scope for energy saving in a virtualized environment. This is a “position chapter” that explains the need to gather network statistics from virtual entities to save energy. It takes a network management view towards achieving green cloud data centres. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-801379-3.00008-5},
  ISBN                     = {978-0-12-801379-3},
  Keywords                 = {Green Computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780128013793000085}
}

@Article{Walker2014287,
  Title                    = {Accurate prediction of the wall shear stress in rod bundles with the spectral element method at high Reynolds numbers },
  Author                   = {Justin Walker and Elia Merzari and Aleksandr Obabko and Paul Fischer and Andrew Siegel},
  Journal                  = {International Journal of Heat and Fluid Flow },
  Year                     = {2014},
  Pages                    = {287 - 299},
  Volume                   = {50},

  Abstract                 = {Abstract Resolving flow near walls is critical to reproducing the high rates of shear that generate turbulence in high Reynolds number, wall-bounded flows. In the present study, we examine the resolution requirements for correctly reproducing mean flow quantities and wall shear stress distribution in a large eddy simulation using the spectral element method. In this method, derivatives are only guaranteed in a weak sense, and the same is true of quantities composed of derivatives, such as the wall shear stress. We are interested in what is required to resolve the wall shear stress in problems that lack homogeneity in at least one direction. The problem of interest is that of parallel flow through a rod bundle configuration. Several meshes for this problem are systematically compared. In addition, we conduct a study of channel flow in order to examine the issues in a canonical flow that contains spanwise homogeneity missing in rod bundle flow. In the case of channel flow, we compare several meshes and subgrid scale models. We find that typical measures of accuracy, such as the law of the wall, are not sufficient for determining the resolution of quantities that vary along the wall. Spanwise variation of wall shear stress in underresolved flows is characterized by spikes—physical points without well-defined derivatives of the velocity—found at element boundaries. These spikes are not particular to any subgrid scale model and are the unavoidable consequence of underresolution. Accurately reproducing the wall shear stress distribution, while minimizing the computational costs, requires increasing the number of elements along the wall (local h-refinement) and using very high order ( N = 19 ) basis functions (p-refinement). We suggest that while these requirements are not easily generalized to grid spacing guidelines, one can apply a general process: construct a mesh that progressively increases elements along any walls, and increase the order of basis functions until the distribution of wall shear stress or any other quantity of interest is smooth. },
  Doi                      = {http://dx.doi.org/10.1016/j.ijheatfluidflow.2014.08.012},
  ISSN                     = {0142-727X},
  Keywords                 = {Wall shear stress},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0142727X14001052}
}

@Article{Waluga2016319,
  Title                    = {Mass-corrections for the conservative coupling of flow and transport on collocated meshes },
  Author                   = {Christian Waluga and Barbara Wohlmuth and Ulrich Rüde},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2016},
  Pages                    = {319 - 332},
  Volume                   = {305},

  Abstract                 = {Abstract Buoyancy-driven flow models demand a careful treatment of the mass-balance equation to avoid spurious source and sink terms in the non-linear coupling between flow and transport. In the context of finite-elements, it is therefore commonly proposed to employ sufficiently rich pressure spaces, containing piecewise constant shape functions to obtain local or even strong mass-conservation. In three-dimensional computations, this usually requires nonconforming approaches, special meshes or higher order velocities, which make these schemes prohibitively expensive for some applications and complicate the implementation into legacy code. In this paper, we therefore propose a lean and conservatively coupled scheme based on standard stabilized linear equal-order finite elements for the Stokes part and vertex-centered finite volumes for the energy equation. We show that in a weak mass-balance it is possible to recover exact conservation properties by a local flux-correction which can be computed efficiently on the control volume boundaries of the transport mesh. We discuss implementation aspects and demonstrate the effectiveness of the flux-correction by different two- and three-dimensional examples which are motivated by geophysical applications. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2015.10.044},
  ISSN                     = {0021-9991},
  Keywords                 = {Finite element method},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999115007214}
}

@Article{Wan2013638,
  Title                    = {Hybrid parallel computing of minimum action method },
  Author                   = {Xiaoliang Wan and Guang Lin},
  Journal                  = {Parallel Computing },
  Year                     = {2013},
  Number                   = {10},
  Pages                    = {638 - 651},
  Volume                   = {39},

  Abstract                 = {Abstract In this work, we report a hybrid (MPI/OpenMP) parallelization strategy for the minimum action method recently proposed in [17]. For nonlinear dynamical systems, the minimum action method is a useful numerical tool to study the transition behavior induced by small noise and the structure of the phase space. The crucial part of the minimum action method is to minimize the Freidlin–Wentzell action functional. Due to the fact that the corresponding Euler–Lagrange equation is, in general, highly nonlinear and of high order, we solve the optimization problem directly instead of discretizing the Euler–Lagrange equation to provide a general but equivalent numerical framework. To enhance the efficiency of the minimum action method for general dynamical systems we consider parallel computing. In particular, we present a hybrid parallelization strategy based on \{MPI\} and OpenMP. Numerical results are presented to demonstrate the efficiency of the proposed parallelization strategy. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2013.08.004},
  ISSN                     = {0167-8191},
  Keywords                 = {Random perturbation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819113000963}
}

@Article{Wang2012254,
  Title                    = {Proactive process-level live migration and back migration in \{HPC\} environments },
  Author                   = {Chao Wang and Frank Mueller and Christian Engelmann and Stephen L. Scott},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2012},
  Number                   = {2},
  Pages                    = {254 - 267},
  Volume                   = {72},

  Abstract                 = {As the number of nodes in high-performance computing environments keeps increasing, faults are becoming common place. Reactive fault tolerance (FT) often does not scale due to massive I/O requirements and relies on manual job resubmission. This work complements reactive with proactive \{FT\} at the process level. Through health monitoring, a subset of node failures can be anticipated when one’s health deteriorates. A novel process-level live migration mechanism supports continued execution of applications during much of process migration. This scheme is integrated into an \{MPI\} execution environment to transparently sustain health-inflicted node failures, which eradicates the need to restart and requeue \{MPI\} jobs. Experiments indicate that 1–6.5 s of prior warning are required to successfully trigger live process migration while similar operating system virtualization mechanisms require 13–24 s. This self-healing approach complements reactive \{FT\} by nearly cutting the number of checkpoints in half when 70% of the faults are handled proactively. The work also provides a novel back migration approach to eliminate load imbalance or bottlenecks caused by migrated tasks. Experiments indicate the larger the amount of outstanding execution, the higher the benefit due to back migration. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2011.10.009},
  ISSN                     = {0743-7315},
  Keywords                 = {Live migration},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731511002085}
}

@Article{Warne201495,
  Title                    = {Comparison of High Level \{FPGA\} Hardware Design for Solving Tri-diagonal Linear Systems },
  Author                   = {David J. Warne and Neil A. Kelson and Ross F. Hayward},
  Journal                  = {Procedia Computer Science },
  Year                     = {2014},
  Note                     = {2014 International Conference on Computational Science },
  Pages                    = {95 - 101},
  Volume                   = {29},

  Abstract                 = {Abstract Reconfigurable computing devices can increase the performance of compute intensive algorithms by implementing application specific co-processor architectures. The power cost for this performance gain is often an order of magnitude less than that of modern \{CPUs\} and GPUs. Exploiting the potential of reconfigurable devices such as Field-Programmable Gate Arrays (FPGAs) is typically a complex and tedious hardware engineering task. Recently the major \{FPGA\} vendors (Altera, and Xilinx) have released their own high-level design tools, which have great potential for rapid development of \{FPGA\} based custom accelerators. In this paper, we will evaluate Altera's OpenCL Software Development Kit, and Xilinx's Vivado High Level Sythesis tool. These tools will be compared for their performance, logic utilisation, and ease of development for the test case of a tri-diagonal linear system solver. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2014.05.009},
  ISSN                     = {1877-0509},
  Keywords                 = {Reconfigurable Computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050914001860}
}

@InBook{Watanobe2009,
  Title                    = {Parallel Computing Technologies: 10th International Conference, PaCT 2009, Novosibirsk, Russia, August 31-September 4, 2009. Proceedings},
  Author                   = {Watanobe, Yutaka and Malyshkin, Victor and Yoshioka, Rentaro and Mirenkov, Nikolay and Fujita, Hamido},
  Chapter                  = {Filmification of Methods: Representation of Particle-In-Cell Algorithms},
  Editor                   = {Malyshkin, Victor},
  Pages                    = {360--376},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2009},

  Address                  = {Berlin, Heidelberg},

  Doi                      = {10.1007/978-3-642-03275-2_36},
  ISBN                     = {978-3-642-03275-2},
  Url                      = {http://dx.doi.org/10.1007/978-3-642-03275-2_36}
}

@Article{Wei20141289,
  Title                    = {A Dataflow Programming Language and its Compiler for Streaming Systems },
  Author                   = {Haitao Wei and Stéphane Zuckerman and Xiaoming Li and Guang R. Gao},
  Journal                  = {Procedia Computer Science },
  Year                     = {2014},
  Note                     = {2014 International Conference on Computational Science },
  Pages                    = {1289 - 1298},
  Volume                   = {29},

  Abstract                 = {Abstract The dataflow programming paradigm shows an important way to improve programming productivity for streaming systems. In this paper we propose COStream, a programming language based on synchronous data flow execution model for data-driven application. We also propose a compiler framework for \{COStream\} on general-purpose multi-core architectures. It features an inter-thread software pipelining scheduler to exploit the parallelism among the cores. We implemented the \{COStream\} compiler framework on x86 multi-core architecture and performed experiments to evaluate the system. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2014.05.116},
  ISSN                     = {1877-0509},
  Keywords                 = {Dataflow Programming},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050914002932}
}

@Article{Wilson201679,
  Title                    = {A task-uncoordinated distributed dataflow model for scalable high performance parallel program execution },
  Author                   = {Lucas A. Wilson and Jeffery von Ronne},
  Journal                  = {Parallel Computing },
  Year                     = {2016},
  Note                     = {Special Issue on Parallel Programming Models and SystemsSoftware for High-End Computing },
  Pages                    = {79 - 87},
  Volume                   = {51},

  Abstract                 = {Abstract We propose a distributed dataflow execution model which utilizes a distributed dictionary for data memoization, allowing each parallel task to schedule instructions without direct inter-task coordination. We provide a description of the proposed model, including autonomous dataflow task selection. We also describe a set of optimization strategies which improve overall throughput of stencil programs executed using this model on modern multi-core and vectorized architectures. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2015.10.013},
  ISSN                     = {0167-8191},
  Keywords                 = {Distributed dataflow},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819115001453}
}

@Article{Winkel2012880,
  Title                    = {A massively parallel, multi-disciplinary Barnes–Hut tree code for extreme-scale N-body simulations },
  Author                   = {Mathias Winkel and Robert Speck and Helge Hübner and Lukas Arnold and Rolf Krause and Paul Gibbon},
  Journal                  = {Computer Physics Communications },
  Year                     = {2012},
  Number                   = {4},
  Pages                    = {880 - 889},
  Volume                   = {183},

  Abstract                 = {The efficient parallelization of fast multipole-based algorithms for the N-body problem is one of the most challenging topics in high performance scientific computing. The emergence of non-local, irregular communication patterns generated by these algorithms can easily create an insurmountable bottleneck on supercomputers with hundreds of thousands of cores. To overcome this obstacle we have developed an innovative parallelization strategy for Barnes–Hut tree codes on present and upcoming \{HPC\} multicore architectures. This scheme, based on a combined MPI–Pthreads approach, permits an efficient overlap of computation and data exchange. We highlight the capabilities of this method on the full \{IBM\} Blue Gene/P system \{JUGENE\} at Jülich Supercomputing Centre and demonstrate scaling across 294,912 cores with up to 2,048,000,000 particles. Applying our implementation pepc to laser–plasma interaction and vortex particle methods close to the continuum limit, we demonstrate its potential for ground-breaking advances in large-scale particle simulations. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2011.12.013},
  ISSN                     = {0010-4655},
  Keywords                 = {Parallel Barnes–Hut tree code},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465511004012}
}

@Article{Winkel2015456,
  Title                    = {A high-order Boris integrator },
  Author                   = {Mathias Winkel and Robert Speck and Daniel Ruprecht},
  Journal                  = {Journal of Computational Physics },
  Year                     = {2015},
  Pages                    = {456 - 474},
  Volume                   = {295},

  Abstract                 = {Abstract This work introduces the high-order Boris-SDC method for integrating the equations of motion for electrically charged particles in electric and magnetic fields. Boris-SDC relies on a combination of the Boris-integrator with spectral deferred corrections (SDC). \{SDC\} can be considered as preconditioned Picard iteration to compute the stages of a collocation method. In this interpretation, inverting the preconditioner corresponds to a sweep with a low-order method. In Boris-SDC, the Boris method, a second-order Lorentz force integrator based on velocity-Verlet, is used as a sweeper/preconditioner. The presented method provides a generic way to extend the classical Boris integrator, which is widely used in essentially all particle-based plasma physics simulations involving magnetic fields, to a high-order method. Stability, convergence order and conservation properties of the method are demonstrated for different simulation setups. Boris-SDC reproduces the expected high order of convergence for a single particle and for the center-of-mass of a particle cloud in a Penning trap and shows good long-term energy stability. },
  Doi                      = {http://dx.doi.org/10.1016/j.jcp.2015.04.022},
  ISSN                     = {0021-9991},
  Keywords                 = {Boris integrator},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0021999115002685}
}

@Article{Wittek2013198,
  Title                    = {Accelerating text mining workloads in a MapReduce-based distributed \{GPU\} environment },
  Author                   = {Peter Wittek and Sándor Darányi},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2013},
  Number                   = {2},
  Pages                    = {198 - 206},
  Volume                   = {73},

  Abstract                 = {Scientific computations have been using GPU-enabled computers successfully, often relying on distributed nodes to overcome the limitations of device memory. Only a handful of text mining applications benefit from such infrastructure. Since the initial steps of text mining are typically data intensive, and the ease of deployment of algorithms is an important factor in developing advanced applications, we introduce a flexible, distributed, MapReduce-based text mining workflow that performs I/O-bound operations on \{CPUs\} with industry-standard tools and then runs compute-bound operations on \{GPUs\} which are optimized to ensure coalesced memory access and effective use of shared memory. We have performed extensive tests of our algorithms on a cluster of eight nodes with two \{NVidia\} Tesla \{M2050s\} attached to each, and we achieve considerable speedups for random projection and self-organizing maps. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2012.10.001},
  ISSN                     = {0743-7315},
  Keywords                 = {\{GPU\} computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731512002353}
}

@Article{Wittmann2013924,
  Title                    = {Comparison of different propagation steps for lattice Boltzmann methods },
  Author                   = {Markus Wittmann and Thomas Zeiser and Georg Hager and Gerhard Wellein},
  Journal                  = {Computers \& Mathematics with Applications },
  Year                     = {2013},
  Note                     = {Mesoscopic Methods in Engineering and Science },
  Number                   = {6},
  Pages                    = {924 - 935},
  Volume                   = {65},

  Abstract                 = {Several possibilities exist to implement the propagation step of lattice Boltzmann methods. This paper describes common implementations and compares the number of memory transfer operations they require per lattice node update. A performance model based on the memory bandwidth is then used to obtain an estimation of the maximum achievable performance on different machines. A subset of the discussed implementations of the propagation step are benchmarked on different Intel- and AMD-based compute nodes using the framework of an existing flow solver that is specially adapted to simulate flow in porous media, and the model is validated against the measurements. Advanced approaches for the propagation step like “A–A pattern” or “Esoteric Twist” require more programming effort but often sustain significantly better performance than non-naïve but straightforward implementations. },
  Doi                      = {http://dx.doi.org/10.1016/j.camwa.2012.05.002},
  ISSN                     = {0898-1221},
  Keywords                 = {Lattice Boltzmann method},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0898122112003835}
}

@Article{Wu2013465,
  Title                    = {On-line soft error correction in matrix–matrix multiplication },
  Author                   = {Panruo Wu and Chong Ding and Longxiang Chen and Teresa Davies and Christer Karlsson and Zizhong Chen},
  Journal                  = {Journal of Computational Science },
  Year                     = {2013},
  Note                     = {Scalable Algorithms for Large-Scale Systems Workshop (ScalA2011), Supercomputing 2011 },
  Number                   = {6},
  Pages                    = {465 - 472},
  Volume                   = {4},

  Abstract                 = {Abstract Soft errors are one-time events that corrupt the state of a computing system but not its overall functionality. Soft errors normally do not interrupt the execution of the affected program, but the affected computation results cannot be trusted any more. A well known technique to correct soft errors in matrix–matrix multiplication is algorithm-based fault tolerance (ABFT). While \{ABFT\} achieves much better efficiency than triple modular redundancy (TMR) – a traditional general technique to correct soft errors, both \{ABFT\} and \{TMR\} detect errors off-line after the computation is finished. This paper extends the traditional \{ABFT\} technique from off-line to on-line so that soft errors in matrix–matrix multiplication can be detected in the middle of the computation during the program execution and higher efficiency can be achieved by correcting the corrupted computations in a timely manner. Experimental results demonstrate that the proposed technique can correct one error every ten seconds with negligible (i.e. less than 1%) performance penalty over the \{ATLAS\} dgemm(). },
  Doi                      = {http://dx.doi.org/10.1016/j.jocs.2013.05.002},
  ISSN                     = {1877-7503},
  Keywords                 = {Algorithm-based fault tolerance},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877750313000641}
}

@Article{Wuyts2015,
  Title                    = {Helsim: A Particle-in-cell Simulator for Highly Imbalanced Particle Distributions },
  Author                   = {Roel Wuyts and Tom Haber and Giovanni Lapenta},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {2923 - 2927},
  Volume                   = {51},

  Abstract                 = {Abstract Helsim is a 3D electro-magnetic particle-in-cell simulator used to simulate the behaviour of plasma in space. Particle-in-cell simulators track the movement of particles through space, with the particles generating and being subjected to various fields (electric, magnetic and or gravitational). Helsim dissociates the particles data structure from the fields, allowing them to be distributed and load- balanced independently and can simulate experiments with highly im-balanced particle distributions with ease. This paper shows weak scaling results of a highly im-balanced particle setup on up to 32 thousand cores. The results validate the basic claims for scal-ability for imbalanced particle distributions, but also highlights a problem with a workaround we had to implement to circumvent an OpenMPI bug we encountered. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.479},
  ISSN                     = {1877-0509},
  Keywords                 = {Particle-in-cell},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915012879}
}

@Article{Wuyts20152923,
  Title                    = {Helsim: A Particle-in-cell Simulator for Highly Imbalanced Particle Distributions },
  Author                   = {Roel Wuyts and Tom Haber and Giovanni Lapenta},
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {2923 - 2927},
  Volume                   = {51},

  Abstract                 = {Abstract Helsim is a 3D electro-magnetic particle-in-cell simulator used to simulate the behaviour of plasma in space. Particle-in-cell simulators track the movement of particles through space, with the particles generating and being subjected to various fields (electric, magnetic and or gravitational). Helsim dissociates the particles data structure from the fields, allowing them to be distributed and load- balanced independently and can simulate experiments with highly im-balanced particle distributions with ease. This paper shows weak scaling results of a highly im-balanced particle setup on up to 32 thousand cores. The results validate the basic claims for scal-ability for imbalanced particle distributions, but also highlights a problem with a workaround we had to implement to circumvent an OpenMPI bug we encountered. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2015.05.479},
  ISSN                     = {1877-0509},
  Keywords                 = {Particle-in-cell},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915012879}
}

@Article{Xiaoguang201550,
  Title                    = {GS-DMR: Low-overhead soft error detection scheme for stencil-based computation },
  Author                   = {Ren Xiaoguang and Xu Xinhai and Wang Qian and Chen Juan and Wang Miao and Yang Xuejun},
  Journal                  = {Parallel Computing },
  Year                     = {2015},
  Pages                    = {50 - 65},
  Volume                   = {41},

  Abstract                 = {Abstract Soft errors are becoming a prominent problem for massive parallel scientific applications. Dual-modular redundancy (DMR) can provide approximately 100% error coverage, but it has the problem of overhead excessive. Stencil kernel is one of the most important routines applied in the context of structured grids. In this paper, we propose Grid Sampling \{DMR\} (GS-DMR), a low-overhead soft error detection scheme for stencil-based computation. Instead of comparing the whole set of the results in the traditional DMR, GS-DMR just compares a subset of the results according to sampling on the grid data, which is based on the error propagation pattern on the grid. We also design a fault tolerant (FT) framework combining GS-DMR with checkpoint technology, and provide theoretical analysis and an algorithm for the optimal \{FT\} parameters. Experimental results on Tianhe-2 supercomputer demonstrate that GS-DMR can achieve a good \{FT\} effect for stencil-based computation, and the effect is greatly improved for massively parallel applications, reducing the total \{FT\} overhead up to 51%. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2014.11.003},
  ISSN                     = {0167-8191},
  Keywords                 = {GS-DMR},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819114001409}
}

@Article{Xing2014210,
  Title                    = {\{HPC\} Benchmark Assessment with Statistical Analysis },
  Author                   = {Fei Xing and Haihang You and Charngda Lu},
  Journal                  = {Procedia Computer Science },
  Year                     = {2014},
  Note                     = {2014 International Conference on Computational Science },
  Pages                    = {210 - 219},
  Volume                   = {29},

  Abstract                 = {Abstract High-performance computing (HPC) benchmarks are widely used to evaluate and rank system performance. This paper introduces a benchmark assessment tool equipped with a rigorous statistical method to evaluate \{HPC\} benchmarks against a set of scientific applications. The method is based on the combination of Variable Clustering (VarCluster) and Principal Component Analysis (PCA). We built the tool upon \{HPC\} Challenge (HPCC) benchmark suite and six popular scientific applications of Kraken, a petaflop supercomputer. Experimental results show that HPCC's Fast Fourier Transform (FFT) kernel, rather than the High-Performance Linpack (HPL) on which Top500 is based, is more representative of the \{HPC\} workloads on Kraken. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2014.05.019},
  ISSN                     = {1877-0509},
  Keywords                 = {statistical method},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050914001963}
}

@Article{Xu2015200,
  Title                    = {Engineering molecular dynamics simulation in chemical engineering },
  Author                   = {Ji Xu and Xiaoxia Li and Chaofeng Hou and Limin Wang and Guangzheng Zhou and Wei Ge and Jinghai Li},
  Journal                  = {Chemical Engineering Science },
  Year                     = {2015},
  Note                     = {2013 Danckwerts Special Issue on Molecular Modelling in Chemical Engineering },
  Pages                    = {200 - 216},
  Volume                   = {121},

  Abstract                 = {Abstract Chemical engineering systems usually involve multiple spatio-temporal scales, grouped into different levels, from the molecular scale of reactants to the industrial scale of reactors. Molecular dynamics (MD) simulation is one of the most fundamental methods for the study of such systems, but it is too costly and hence formidable for simulating large-scale behavior directly. However, there are two great potentials in extending this method. First, the logic and algorithms of traditional \{MD\} simulations can be generalized from the material level to higher levels since the elements of each level are all discrete in nature, and can be well defined, allowing an MD-style simulation based on different elements. Second, \{MD\} simulations can be accelerated by realizing the structural consistency among the problem, model, software and hardware (the so-called \{EMMS\} paradigm). These two potentials give possibilities to engineer the method of \{MD\} simulation to deal with the whole spectrum of chemical engineering phenomena. In this review, we summarize our discrete simulation studies to explore such potentials, from the establishment of a general software and hardware framework, to the typical applications at different levels, including the reactions in coal pyrolysis, the dynamics in virion, the atomic behavior in silicon at millimeter scale, and finally continuum flow. The possibility of engineering \{MD\} simulation into a virtual experiment platform is discussed finally. },
  Doi                      = {http://dx.doi.org/10.1016/j.ces.2014.09.051},
  ISSN                     = {0009-2509},
  Keywords                 = {Engineering \{MD\} simulation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0009250914005557}
}

@Article{Xu20121106,
  Title                    = {Microwave tomography for breast cancer detection on Cell broadband engine processors },
  Author                   = {Meilian Xu and Parimala Thulasiraman and Sima Noghanian},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2012},
  Note                     = {Accelerators for High-Performance Computing },
  Number                   = {9},
  Pages                    = {1106 - 1116},
  Volume                   = {72},

  Abstract                 = {Microwave tomography (MT) is a safe screening modality that can be used for breast cancer detection. The technique uses the dielectric property contrasts between different breast tissues at microwave frequencies to determine the existence of abnormalities. Our proposed \{MT\} approach is an iterative process that involves two algorithms: Finite-Difference Time-Domain (FDTD) and Genetic Algorithm (GA). It is a compute intensive problem: (i) the number of iterations can be quite large to detect small tumors; (ii) many fine-grained computations and discretizations of the object under screening are required for accuracy. In our earlier work, we developed a parallel algorithm for microwave tomography on CPU-based homogeneous, multi-core, distributed memory machines. The performance improvement was limited due to communication and synchronization latencies inherent in the algorithm. In this paper, we exploit the parallelism of microwave tomography on the Cell \{BE\} processor. Since \{FDTD\} is a numerical technique with regular memory accesses, intensive floating point operations and \{SIMD\} type operations, the algorithm can be efficiently mapped on the Cell processor achieving significant performance. The initial implementation of \{FDTD\} on Cell \{BE\} with 8 \{SPEs\} is 2.9 times faster than an eight node shared memory machine and 1.45 times faster than an eight node distributed memory machine. In this work, we modify the \{FDTD\} algorithm by overlapping computations with communications during asynchronous \{DMA\} transfers. The modified algorithm also orchestrates the computations to fully use data between \{DMA\} transfers to increase the computation-to-communication ratio. We see 54% improvement on 8 \{SPEs\} (27.9% on 1 SPE) for the modified \{FDTD\} in comparison to our original \{FDTD\} algorithm on Cell BE. We further reduce the synchronization latency between \{GA\} and \{FDTD\} by using mechanisms such as double buffering. We also propose a performance prediction model based on \{DMA\} transfers, number of instructions and operations, the processor frequency and \{DMA\} bandwidth. We show that the execution time from our prediction model is comparable (within 0.5 s difference) with the execution time of the experimental results on one SPE. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2011.10.013},
  ISSN                     = {0743-7315},
  Keywords                 = {Breast cancer detection},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731511002127}
}

@Article{Xu20152,
  Title                    = {ARCHER, a new Monte Carlo software tool for emerging heterogeneous computing environments },
  Author                   = {X. George Xu and Tianyu Liu and Lin Su and Xining Du and Matthew Riblett and Wei Ji and Deyang Gu and Christopher D. Carothers and Mark S. Shephard and Forrest B. Brown and Mannudeep K. Kalra and Bob Liu},
  Journal                  = {Annals of Nuclear Energy },
  Year                     = {2015},
  Note                     = {Joint International Conference on Supercomputing in Nuclear Applications and Monte Carlo 2013, \{SNA\} + \{MC\} 2013. Pluri- and Trans-disciplinarity, Towards New Modeling and Numerical Simulation Paradigms },
  Pages                    = {2 - 9},
  Volume                   = {82},

  Abstract                 = {Abstract The Monte Carlo radiation transport community faces a number of challenges associated with peta- and exa-scale computing systems that rely increasingly on heterogeneous architectures involving hardware accelerators such as \{GPUs\} and Xeon Phi coprocessors. Existing Monte Carlo codes and methods must be strategically upgraded to meet emerging hardware and software needs. In this paper, we describe the development of a software, called \{ARCHER\} (Accelerated Radiation-transport Computations in Heterogeneous EnviRonments), which is designed as a versatile testbed for future Monte Carlo codes. Preliminary results from five projects in nuclear engineering and medical physics are presented. },
  Doi                      = {http://dx.doi.org/10.1016/j.anucene.2014.08.062},
  ISSN                     = {0306-4549},
  Keywords                 = {Monte Carlo},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0306454914004629}
}

@Article{Yamamoto20143795,
  Title                    = {Performance of Parallel Simulators on Peta-scale Platforms for Coupled Multi-physics Modelling of \{CO2\} Geologic Sequestration },
  Author                   = {Hajime Yamamoto and Kengo Nakajima and Keni Zhang and Shinichi Nanai},
  Journal                  = {Energy Procedia },
  Year                     = {2014},
  Note                     = {12th International Conference on Greenhouse Gas Control Technologies, GHGT-12 },
  Pages                    = {3795 - 3804},
  Volume                   = {63},

  Abstract                 = {Abstract Powerful numerical codes for modeling complex coupled processes of physics and chemistry have been developed for predicting the fate of \{CO2\} in reservoirs. However, they are often computationally demanding for solving highly non-linear models in sufficient spatial and temporal resolutions. In this study, two parallel simulators were implemented and optimized on two supercomputers with a thousand to tens of thousands of processors. The two simulators were: a parallel simulator of multi-phase flow TOUGH2-MP, and a parallelized in-house version of chemically reactive transport simulator TOUGHREACT. The optimization efforts including solver replacements were rewarded by twice to several tens of times speedup of calculations. The performance measurement confirmed that the simulators exhibit excellent scalability showing almost linear speedup up to more than 20,000 processors, and allow performing simulations at high resolutions with multi-million grids in a practical time. The paper is concluded with a demonstrative simulation of a highly non-linear process of dissolution-diffusion-convection that requires high spatial and temporal resolutions. },
  Doi                      = {http://dx.doi.org/10.1016/j.egypro.2014.11.408},
  ISSN                     = {1876-6102},
  Keywords                 = {geologicl carbon storage},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1876610214022231}
}

@Article{Yamamoto2014576,
  Title                    = {The K computer Operations: Experiences and Statistics },
  Author                   = {Keiji Yamamoto and Atsuya Uno and Hitoshi Murai and Toshiyuki Tsukamoto and Fumiyoshi Shoji and Shuji Matsui and Ryuichi Sekizawa and Fumichika Sueyasu and Hiroshi Uchiyama and Mitsuo Okamoto and Nobuo Ohgushi and Katsutoshi Takashina and Daisuke Wakabayashi and Yuki Taguchi and Mitsuo Yokokawa},
  Journal                  = {Procedia Computer Science },
  Year                     = {2014},
  Note                     = {2014 International Conference on Computational Science },
  Pages                    = {576 - 585},
  Volume                   = {29},

  Abstract                 = {Abstract The K computer, released on September 29, 2012, is a large-scale parallel supercomputer system consisting of 82,944 compute nodes. We have been able to resolve a significant number of operation issues since its release. Some system software components have been fixed and improved to obtain higher stability and utilization. We achieved 94% service availability because of a low hardware failure rate and approximately 80% node utilization by careful adjustment of operation parameters. We found that the K computer is an extremely stable and high utilization system. },
  Doi                      = {http://dx.doi.org/10.1016/j.procs.2014.05.052},
  ISSN                     = {1877-0509},
  Keywords                 = {Supercomputer},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050914002294}
}

@Article{Yang2015170,
  Title                    = {NationTelescope: Monitoring and visualizing large-scale collective behavior in \{LBSNs\} },
  Author                   = {Dingqi Yang and Daqing Zhang and Longbiao Chen and Bingqing Qu},
  Journal                  = {Journal of Network and Computer Applications },
  Year                     = {2015},
  Pages                    = {170 - 180},
  Volume                   = {55},

  Abstract                 = {Abstract The research of collective behavior has attracted a lot of attention in recent years, which can empower various applications, such as recommendation systems and intelligent transportation systems. However, in traditional social science, it is practically difficult to collect large-scale user behavior data. Fortunately, with the ubiquity of smartphones and Location Based Social Networks (LBSNs), users continuously report their activities online, which massively reflect their collective behavior. In this paper, we propose NationTelescope, a platform that monitors, compares and visualizes large-scale nation-wide user behavior in LBSNs. First, it continuously collects user behavior data from LBSNs. Second, it automatically generates behavior data summary and integrates an interactive map interface for data visualization. Third, in order to compare and visualize the behavioral differences across countries, it detects the discriminative activities according to the related traffic patterns in different countries. By implementing a prototype of NationTelescope platform, we evaluate its effectiveness and usability via two case studies and a system usability scale survey. The results show that the platform can not only efficiently capture, compare and visualize nation-wide collective behavior, but also achieve good usability and user experience. },
  Doi                      = {http://dx.doi.org/10.1016/j.jnca.2015.05.010},
  ISSN                     = {1084-8045},
  Keywords                 = {Participatory sensing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1084804515001101}
}

@Article{Yavits2014,
  Title                    = {The effect of communication and synchronization on Amdahl’s law in multicore systems },
  Author                   = {L. Yavits and A. Morad and R. Ginosar},
  Journal                  = {Parallel Computing },
  Year                     = {2014},
  Number                   = {1},
  Pages                    = {1 - 16},
  Volume                   = {40},

  Abstract                 = {Abstract This work analyses the effects of sequential-to-parallel synchronization and inter-core communication on multicore performance, speedup and scaling from Amdahl’s law perspective. Analytical modeling supported by simulation leads to a modification of Amdahl’s law, reflecting lower than originally predicted speedup, due to these effects. In applications with high degree of data sharing, leading to intense inter-core connectivity requirements, the workload should be executed on a smaller number of larger cores. Applications requiring intense sequential-to-parallel synchronization, even highly parallelizable ones, may better be executed by the sequential core. To improve the scalability and performance speedup of a multicore, it is as important to address the synchronization and connectivity intensities of parallel algorithms as their parallelization factor. },
  Doi                      = {http://dx.doi.org/10.1016/j.parco.2013.11.001},
  ISSN                     = {0167-8191},
  Keywords                 = {Multicore},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167819113001324}
}

@Article{Yilmaz2013388,
  Title                    = {Surface conformed linear mesh and data subdivision technique for large-scale flow simulation and visualization in Variable Intensity Computational Environment },
  Author                   = {Erdal Yilmaz and Shahrouz Aliabadi},
  Journal                  = {Computers \& Fluids },
  Year                     = {2013},
  Note                     = {Selected contributions of the 23rd International Conference on Parallel Fluid Dynamics ParCFD2011 },
  Pages                    = {388 - 402},
  Volume                   = {80},

  Abstract                 = {In this paper, we report the development of a parallel program to isotropically subdivide a 3-D hybrid unstructured coarse base mesh to generate a finer computational mesh without user interaction. Our Variable Intensity Computational Environment enables scientific computations using very large mesh yet allows users to interact with more manageable smaller mesh. The main motivation behind this study is to overcome the bottleneck in generating and processing of the computational meshes with billions of elements. First, we generate a coarse mesh using any unstructured mesh generator. Then, we subdivide the coarse mesh to the level of resolution needed for the simulations. Finally, we conform mesh nodes on solid surfaces to the original geometry since linear subdivision ignores surface curvatures. We use K–D tree search algorithm in the surface mapping. To deform interior mesh nodes due to the surface correction, we use the spring analogy method since deformations are very small. Surface correction is implemented in parallel using the Message Passing Interface. The new mesh obtained from the isotropic subdivision preserves mesh density distribution of the original coarse mesh. The mesh subdivision with surface correction is integral part of our Variable Intensity Computational Environment. Three test cases are used to demonstrate applicability of this method: a generic reentry vehicle, an Army projectile, and a sphere. Flow solutions are obtained using our compressible and incompressible Navier–Stokes CaMEL flow solvers with the Detached Eddy Simulation turbulence model. Flow solutions and mesh subdivisions are performed in a parallel cluster at the Jackson State University. },
  Doi                      = {http://dx.doi.org/10.1016/j.compfluid.2012.01.017},
  ISSN                     = {0045-7930},
  Keywords                 = {Mesh multiplication},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045793012000266}
}

@Article{Yilmaz2013773,
  Title                    = {Application of surface conformed linear mesh and data subdivision technique to a spinning projectile },
  Author                   = {Erdal Yilmaz and Shahrouz Aliabadi},
  Journal                  = {Computers \& Fluids },
  Year                     = {2013},
  Pages                    = {773 - 781},
  Volume                   = {88},

  Abstract                 = {Abstract In this paper, we report a spinning projectile application of a parallel \{CFD\} program featuring surface-conformed isotropic mesh subdivision. The subdivision technique generates finer computational mesh without user interaction using a 3-D hybrid unstructured coarse base. The main motivation behind the subdivision technique is to overcome the bottleneck in generating and processing of the computational meshes with billions of elements. First, we generate a coarse mesh using any unstructured mesh generator. Then, we subdivide the coarse mesh to the level of resolution needed for the simulations. Finally, we conform mesh nodes on solid surfaces to the original geometry since linear subdivision ignores surface curvatures. We use K-D tree search algorithm in the surface mapping. To deform interior mesh nodes due to the surface correction, we use the spring analogy method since deformations are very small. Surface correction is implemented in parallel using the Message Passing Interface. The new mesh obtained from the isotropic subdivision preserves mesh density distribution of the original coarse mesh. The mesh subdivision with surface correction is integral part of our Variable Intensity Computational Environment. A projectile test case with and without spinning at different angles of attack are used to demonstrate the applicability of this method. Flow solutions are obtained using our compressible Navier–Stokes flow solver, CaMEL Aero, with the Detached Eddy Simulation turbulence model. Flow solutions and mesh subdivisions are performed in our parallel cluster at the Jackson State University. },
  Doi                      = {http://dx.doi.org/10.1016/j.compfluid.2013.06.006},
  ISSN                     = {0045-7930},
  Keywords                 = {Mesh multiplication},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045793013002211}
}

@Article{Yokota201317,
  Title                    = {FMM-based vortex method for simulation of isotropic turbulence on GPUs, compared with a spectral method },
  Author                   = {Rio Yokota and L.A. Barba},
  Journal                  = {Computers \& Fluids },
  Year                     = {2013},
  Note                     = {Selected contributions of the 23rd International Conference on Parallel Fluid Dynamics ParCFD2011 },
  Pages                    = {17 - 27},
  Volume                   = {80},

  Abstract                 = {The Lagrangian vortex method offers an alternative numerical approach for direct numerical simulation of turbulence. The fact that it uses the fast multipole method (FMM)—a hierarchical algorithm for N-body problems with highly scalable parallel implementations—as numerical engine makes it a potentially good candidate for exascale systems. However, there have been few validation studies of Lagrangian vortex simulations and the insufficient comparisons against standard \{DNS\} codes has left ample room for skepticism. This paper presents a comparison between a Lagrangian vortex method and a pseudo-spectral method for the simulation of decaying homogeneous isotropic turbulence. This flow field is chosen despite the fact that it is not the most favorable flow problem for particle methods (which shine in wake flows or where vorticity is compact), due to the fact that it is ideal for the quantitative validation of \{DNS\} codes. We use a 2563 grid with Reλ = 50 and 100 and look at the turbulence statistics, including high-order moments. The focus is on the effect of the various parameters in the vortex method, e.g., order of \{FMM\} series expansion, frequency of reinitialization, overlap ratio and time step. The vortex method uses an \{FMM\} code (exaFMM) that runs on \{GPU\} hardware using CUDA, while the spectral code (hit3d) runs on \{CPU\} only. Results indicate that, for this application (and with the current code implementations), the spectral method is an order of magnitude faster than the vortex method when using a single \{GPU\} for the \{FMM\} and six \{CPU\} cores for the FFT. },
  Doi                      = {http://dx.doi.org/10.1016/j.compfluid.2012.08.002},
  ISSN                     = {0045-7930},
  Keywords                 = {Computational fluid dynamics},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045793012003003}
}

@Article{Yokota2013445,
  Title                    = {Petascale turbulence simulation using a highly parallel fast multipole method on \{GPUs\} },
  Author                   = {Rio Yokota and L.A. Barba and Tetsu Narumi and Kenji Yasuoka},
  Journal                  = {Computer Physics Communications },
  Year                     = {2013},
  Number                   = {3},
  Pages                    = {445 - 455},
  Volume                   = {184},

  Abstract                 = {This paper reports large-scale direct numerical simulations of homogeneous-isotropic fluid turbulence, achieving sustained performance of 1.08 petaflop/s on gpu hardware using single precision. The simulations use a vortex particle method to solve the Navier–Stokes equations, with a highly parallel fast multipole method (fmm) as numerical engine, and match the current record in mesh size for this application, a cube of 4096 3 computational points solved with a spectral method. The standard numerical approach used in this field is the pseudo-spectral method, relying on the fft algorithm as the numerical engine. The particle-based simulations presented in this paper quantitatively match the kinetic energy spectrum obtained with a pseudo-spectral method, using a trusted code. In terms of parallel performance, weak scaling results show the fmm-based vortex method achieving 74% parallel efficiency on 4096 processes (one gpu per mpi process, 3 gpus per node of the tsubame-2.0 system). The fft-based spectral method is able to achieve just 14% parallel efficiency on the same number of mpi processes (using only cpu cores), due to the all-to-all communication pattern of the fft algorithm. The calculation time for one time step was 108 s for the vortex method and 154 s for the spectral method, under these conditions. Computing with 69 billion particles, this work exceeds by an order of magnitude the largest vortex-method calculations to date. },
  Doi                      = {http://dx.doi.org/10.1016/j.cpc.2012.09.011},
  ISSN                     = {0010-4655},
  Keywords                 = {Isotropic turbulence},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010465512002974}
}

@Article{You2016828,
  Title                    = {The role of research efficiency in the evolution of scientific productivity and impact: An agent-based model },
  Author                   = {Zhi-Qiang You and Xiao-Pu Han and Tarik Hadzibeganovic},
  Journal                  = {Physics Letters A },
  Year                     = {2016},
  Number                   = {7–8},
  Pages                    = {828 - 836},
  Volume                   = {380},

  Abstract                 = {Abstract We introduce an agent-based model to investigate the effects of production efficiency (PE) and hot field tracing capability (HFTC) on productivity and impact of scientists embedded in a competitive research environment. Agents compete to publish and become cited by occupying the nodes of a citation network calibrated by real-world citation datasets. Our Monte-Carlo simulations reveal that differences in individual performance are strongly related to PE, whereas \{HFTC\} alone cannot provide sustainable academic careers under intensely competitive conditions. Remarkably, the negative effect of high competition levels on productivity can be buffered by elevated research efficiency if simultaneously \{HFTC\} is sufficiently low. },
  Doi                      = {http://dx.doi.org/10.1016/j.physleta.2015.12.022},
  ISSN                     = {0375-9601},
  Keywords                 = {Agent-based model},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0375960115010580}
}

@Article{Yu2015,
  Title                    = {Quantitative modeling of power performance tradeoffs on extreme scale systems },
  Author                   = {Li Yu and Zhou Zhou and Sean Wallace and Michael E. Papka and Zhiling Lan},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2015},
  Pages                    = {1 - 14},
  Volume                   = {84},

  Abstract                 = {Abstract As high performance computing (HPC) continues to grow in scale and complexity, energy becomes a critical constraint in the race to exascale computing. The days of “performance at all cost” are coming to an end. While performance is still a major objective, future \{HPC\} will have to deliver desired performance under the energy constraint. Among various power management methods, power capping is a widely used approach. Unfortunately, the impact of power capping on system performance, user jobs, and power-performance efficiency are not well studied due to many interfering factors imposed by system workload and configurations. To fully understand power management in extreme scale systems with a fixed power budget, we introduce a power-performance modeling tool named PuPPET (Power Performance \{PETri\} net). Unlike the traditional performance modeling approaches such as analytical methods or trace-based simulators, we explore a new approach–colored Petri nets–for the design of PuPPET. PuPPET is fast and extensible for navigating through different configurations. More importantly, it can scale to hundreds of thousands of processor cores and at the same time provide high levels of modeling accuracy. We validate PuPPET by using system traces (i.e., workload log and power data) collected from the production 48-rack \{IBM\} Blue Gene/Q supercomputer at Argonne National Laboratory. Our trace-based validation demonstrates that PuPPET is capable of modeling the dynamic execution of parallel jobs on the machine by providing an accurate approximation of energy consumption. In addition, we present two case studies of using PuPPET to study power-performance tradeoffs on petascale systems. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2015.06.006},
  ISSN                     = {0743-7315},
  Keywords                 = {High performance computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731515001045}
}

@Article{Yu20151,
  Title                    = {Quantitative modeling of power performance tradeoffs on extreme scale systems },
  Author                   = {Li Yu and Zhou Zhou and Sean Wallace and Michael E. Papka and Zhiling Lan},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2015},
  Pages                    = {1 - 14},
  Volume                   = {84},

  Abstract                 = {Abstract As high performance computing (HPC) continues to grow in scale and complexity, energy becomes a critical constraint in the race to exascale computing. The days of “performance at all cost” are coming to an end. While performance is still a major objective, future \{HPC\} will have to deliver desired performance under the energy constraint. Among various power management methods, power capping is a widely used approach. Unfortunately, the impact of power capping on system performance, user jobs, and power-performance efficiency are not well studied due to many interfering factors imposed by system workload and configurations. To fully understand power management in extreme scale systems with a fixed power budget, we introduce a power-performance modeling tool named PuPPET (Power Performance \{PETri\} net). Unlike the traditional performance modeling approaches such as analytical methods or trace-based simulators, we explore a new approach–colored Petri nets–for the design of PuPPET. PuPPET is fast and extensible for navigating through different configurations. More importantly, it can scale to hundreds of thousands of processor cores and at the same time provide high levels of modeling accuracy. We validate PuPPET by using system traces (i.e., workload log and power data) collected from the production 48-rack \{IBM\} Blue Gene/Q supercomputer at Argonne National Laboratory. Our trace-based validation demonstrates that PuPPET is capable of modeling the dynamic execution of parallel jobs on the machine by providing an accurate approximation of energy consumption. In addition, we present two case studies of using PuPPET to study power-performance tradeoffs on petascale systems. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2015.06.006},
  ISSN                     = {0743-7315},
  Keywords                 = {High performance computing},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731515001045}
}

@Article{Yuan20142423,
  Title                    = {Static load-balanced routing for slimmed fat-trees },
  Author                   = {Xin Yuan and Santosh Mahapatra and Michael Lang and Scott Pakin},
  Journal                  = {Journal of Parallel and Distributed Computing },
  Year                     = {2014},
  Number                   = {5},
  Pages                    = {2423 - 2432},
  Volume                   = {74},

  Abstract                 = {Abstract Slimmed fat-trees have recently been proposed and deployed to reduce costs in High Performance Computing (HPC) clusters. While existing static routing schemes such as destination-mod-k (D-mod-k) routing are load-balanced and effective for full bisection bandwidth fat-trees, they incur significant load imbalance in many slimmed fat-trees. In this work, we propose a static load balanced routing scheme, called Round-Robin Routing ( R R R ), for 2 - and 3 -level extended generalized fat-trees (XGFTs), which represent many fat-tree variations including slimmed fat-trees. R R R achieves near perfect load-balancing for any such \{XGFT\} in that links at the same level of a tree carry traffic from almost the same number of source–destination pairs. Our evaluation results indicate that on many slimmed fat-trees, R R R is significantly better than D-mod-k for dense traffic patterns due to its better load-balancing property, but performs worse for sparse patterns. We develop a combined routing scheme that enjoys the strengths of both R R R and D-mod-k by using R R R in conjunction with D-mod-k. The combined routing is a robust load-balanced routing scheme for slimmed fat-trees: it performs similar to D-mod-k for sparse traffic patterns and to R R R for dense patterns. },
  Doi                      = {http://dx.doi.org/10.1016/j.jpdc.2014.02.001},
  ISSN                     = {0743-7315},
  Keywords                 = {Fat-tree},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0743731514000215}
}

@Article{Zasada2012314,
  Title                    = {IMENSE: An e-infrastructure environment for patient specific multiscale data integration, modelling and clinical treatment },
  Author                   = {Stefan J. Zasada and Tao Wang and Ali Haidar and Enjie Liu and Norbert Graf and Gordon Clapworthy and Steven Manos and Peter V. Coveney},
  Journal                  = {Journal of Computational Science },
  Year                     = {2012},
  Note                     = {Advanced Computing Solutions for Health Care and Medicine },
  Number                   = {5},
  Pages                    = {314 - 327},
  Volume                   = {3},

  Abstract                 = {Secure access to patient data and analysis tools to run on that data will revolutionize the treatment of a wide range of diseases, by using advanced simulation techniques to underpin the clinical decision making process. To achieve these goals, suitable e-Science infrastructures are required to allow clinicians and researchers to trivially access data and launch simulations. In this paper we describe the open source Individualized \{MEdiciNe\} Simulation Environment (IMENSE), which provides a platform to securely manage clinical data, and to perform wide ranging analysis on that data, ultimately with the intention of enhancing clinical decision making with direct impact on patient health care. We motivate the design decisions taken in the development of the \{IMENSE\} system by considering the needs of researchers in the ContraCancrum project, which provides a paradigmatic case in which clinicians and researchers require coordinated access to data and simulation tools. We show how the modular nature of the \{IMENSE\} system makes it applicable to a wide range of biomedical computing scenarios, from within a single hospital to major international research projects. },
  Doi                      = {http://dx.doi.org/10.1016/j.jocs.2011.07.001},
  ISSN                     = {1877-7503},
  Keywords                 = {Clinical decision support},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877750311000639}
}

@Article{Zaspel2016505,
  Title                    = {Subspace correction methods in algebraic multi-level frames },
  Author                   = {Peter Zaspel},
  Journal                  = {Linear Algebra and its Applications },
  Year                     = {2016},
  Pages                    = {505 - 521},
  Volume                   = {488},

  Abstract                 = {Abstract This study aims at introducing new algebraic multi-level solution techniques for linear systems with M-matrices. Previous optimal geometric constructions by multi-level generating systems or multi-level frames are adapted. The new contribution is a purely algebraic construction of multi-level frames. A new class of algebraic multi-level algorithms is derived by applying subspace correction iterative solvers to the algebraic multi-level linear system. These algorithms feature error resilience properties and potential massive parallelism. The proposed work outperforms previous geometric constructions since a black-box, geometry-independent methodology is considered. Moreover, optimality results of geometric constructions are matched. Overall, the new method will be well suited for generic linear algebra libraries for future multi- and many-core systems. },
  Doi                      = {http://dx.doi.org/10.1016/j.laa.2015.09.026},
  ISSN                     = {0024-3795},
  Keywords                 = {Algebraic multigrid},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0024379515005418}
}

@Article{Zaspel2013356,
  Title                    = {Solving incompressible two-phase flows on multi-GPU clusters },
  Author                   = {Peter Zaspel and Michael Griebel},
  Journal                  = {Computers \& Fluids },
  Year                     = {2013},
  Note                     = {Selected contributions of the 23rd International Conference on Parallel Fluid Dynamics ParCFD2011 },
  Pages                    = {356 - 364},
  Volume                   = {80},

  Abstract                 = {We present a fully multi-GPU-based double-precision solver for the three-dimensional two-phase incompressible Navier–Stokes equations. It is able to simulate the interaction of two fluids like air and water based on a level-set approach. High-order finite difference schemes and Chorin’s projection approach for space and time discretization are applied. An in-depth performance analysis shows a realistic speed-up of the order of three by comparing equally priced \{GPUs\} and \{CPUs\} and more than a doubling in energy efficiency for GPUs. We observe profound strong and weak scaling on two different multi-GPU clusters. },
  Doi                      = {http://dx.doi.org/10.1016/j.compfluid.2012.01.021},
  ISSN                     = {0045-7930},
  Keywords                 = {Graphics processing units},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0045793012000308}
}

@Article{Zhao2016519,
  Title                    = {Amorphization and nanocrystallization of silicon under shock compression },
  Author                   = {S. Zhao and E.N. Hahn and B. Kad and B.A. Remington and C.E. Wehrenberg and E.M. Bringa and M.A. Meyers},
  Journal                  = {Acta Materialia },
  Year                     = {2016},
  Pages                    = {519 - 533},
  Volume                   = {103},

  Abstract                 = {Abstract High-power, short-duration, laser-driven, shock compression and recovery experiments on [001] silicon unveiled remarkable structural changes above a pressure threshold. Two distinct amorphous regions were identified: (a) a bulk amorphous layer close to the surface and (b) amorphous bands initially aligned with {111} slip planes. Further increase of the laser energy leads to the re-crystallization of amorphous silicon into nanocrystals with high concentration of nano-twins. This amorphization is produced by the combined effect of high magnitude hydrostatic and shear stresses under dynamic shock compression. Shock-induced defects play a very important role in the onset of amorphization. Calculations of the free energy changes with pressure and shear, using the Patel-Cohen methodology, are in agreement with the experimental results. Molecular dynamics simulation corroborates the amorphization, showing that it is initiated by the nucleation and propagation of partial dislocations. The nucleation of amorphization is analyzed qualitatively by classical nucleation theory. },
  Doi                      = {http://dx.doi.org/10.1016/j.actamat.2015.09.022},
  ISSN                     = {1359-6454},
  Keywords                 = {Laser shock compression},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1359645415006916}
}

@Article{Zhao201574,
  Title                    = {Pressure and shear-induced amorphization of silicon },
  Author                   = {S. Zhao and B. Kad and E.N. Hahn and B.A. Remington and C.E. Wehrenberg and C.M. Huntington and H.-S. Park and E.M. Bringa and K.L. More and M.A. Meyers},
  Journal                  = {Extreme Mechanics Letters },
  Year                     = {2015},
  Pages                    = {74 - 80},
  Volume                   = {5},

  Abstract                 = {Abstract Here we report that high-power, pulsed, laser-driven shock compression of monocrystalline silicon produces directional amorphization, revealed by high-resolution transmission electron microscopy and confirmed by molecular dynamics simulations. At the lowest energy level experiment, generating a pressure of ∼4 GPa, silicon reacts elastically. At intermediate energy levels (P∼11 and 22 GPa), amorphization is observed both at the surface and directionally, along planes making angles close to the maximum shear. At the highest laser energy level explored here, ( P p e a k ∼28 GPa), the recovered sample shows a nanocrystalline microstructure near the surface. This nanocrystalline structure forms by crystallization from the amorphous phase and is thought to be a post-shock phenomenon. Shear-induced lattice defects (stacking faults and twins) on crystallographic slip planes play a crucial role in the onset of amorphization. Molecular dynamics show that silicon behaves elastically until ∼10 \{GPa\} and, at slightly higher pressures, partial dislocations and stacking faults are emitted from the surface. Driven by the high-amplitude stress pulse, these defects travel inwards along specific crystallographic orientations and intersect, leading to further defect creation, additional plastic work, and, at higher pressures, amorphous bands in intersecting patterns. The typical high-pressure solid–solid phase transitions of silicon are not observed whereas the high shear stresses are relaxed by localized dislocation motion/interactions and eventually by directional amorphization, which occurs below the critical hydrostatic pressure for melting of silicon in shock compression. It is therefore proposed that the combined effects of hydrostatic and shear stresses lead to directional amorphization. },
  Doi                      = {http://dx.doi.org/10.1016/j.eml.2015.10.001},
  ISSN                     = {2352-4316},
  Keywords                 = {Laser shock compression},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S235243161530002X}
}

@Article{Zhao20153,
  Title                    = {Enabling scalable scientific workflow management in the Cloud },
  Author                   = {Yong Zhao and Youfu Li and Ioan Raicu and Shiyong Lu and Wenhong Tian and Heng Liu},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2015},
  Pages                    = {3 - 16},
  Volume                   = {46},

  Abstract                 = {Abstract Cloud computing is gaining tremendous momentum in both academia and industry. In this context, we define the term “Cloud Workflow” as the specification, execution and provenance tracking of large-scale scientific workflows, as well as the management of data and computing resources to support the execution of large-scale scientific workflows in the Cloud. In this paper, we first analyze the gap between these two complementary technologies, and what it means to bring Clouds and workflows together. Then, we present the key challenges in supporting Cloud workflows, and present our reference framework for scientific workflow management in the Cloud. Last we present our experience in integrating a scientific workflow management system—Swift into the Cloud. We discuss the performance of cluster provisioning within the OpenNebula Cloud platform, the Eucalyptus Cloud platform and Amazon EC2, and we demonstrate the capability and efficiency of the integration using a \{NASA\} \{MODIS\} image processing workflow and the Montage image mosaic workflow. Note to practitioners. Scientific workflow management plays a very important role for scientific computing and application coordination, while Cloud computing offers scalability and resource on-demand. We devise autonomous methods to integrate scientific workflow management systems with Cloud platforms and also provision resources for large scale workflows, which can facilitate scientists to easily manage their workflows in the Cloud, and take advantage of large scale Cloud resources. There are a few integration options and many challenges in the process, and the experience we gain will help researchers in migrating their workflow management systems and workflow applications into the Cloud. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2014.10.023},
  ISSN                     = {0167-739X},
  Keywords                 = {Cloud workflow},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X14002179}
}

@Article{Zheng2015313,
  Title                    = {CSquare: A new kilo-core-oriented topology },
  Author                   = {Naijun Zheng and Huaxi Gu and Xin Huang and Xiaokang Chen},
  Journal                  = {Microprocessors and Microsystems },
  Year                     = {2015},
  Number                   = {4–5},
  Pages                    = {313 - 320},
  Volume                   = {39},

  Abstract                 = {Abstract As the number of cores in a multicore chip increases, the kilo-core processor will be a trend in Network-on-Chip development. For such case, the network topology needs to scale effectively. In this paper, we propose a new scalable topology for kilo-core-oriented processors named CSquare, a cluster-formed structure, in which each cluster is a variation of the butterfly-tree. For each cluster, the routers adopt parallel-level structure to obtain efficient global connections. With the global interconnections between clusters, the topology scale can be extended at a much faster rate than with only one cluster. For such characters, we propose a deadlock-free routing algorithm for CSquare, called GNCA. Compared with 2D-Mesh and Torus, \{CSquare\} employs fewer routers and links. The simulation results indicate that \{CSquare\} greatly improves the average latency and throughput under various traffic patterns and consumes less power and area. },
  Doi                      = {http://dx.doi.org/10.1016/j.micpro.2015.03.008},
  ISSN                     = {0141-9331},
  Keywords                 = {Network-on-Chip},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0141933115000332}
}

@InCollection{Zhong2015197,
  Title                    = {7.05 - Numerical Methods for Mantle Convection },
  Author                   = {S.J. Zhong and D.A. Yuen and L.N. Moresi and M.G. Knepley},
  Booktitle                = {Treatise on Geophysics (Second Edition) },
  Publisher                = {Elsevier},
  Year                     = {2015},

  Address                  = {Oxford},
  Edition                  = {Second Edition},
  Editor                   = {Schubert, Gerald },
  Pages                    = {197 - 222},

  Abstract                 = {Abstract Over the past 40 years, numerical methods used to model mantle convection have matured significantly and now occupy a distinctive niche in computational fluid dynamics. The central issue for the partial differential equations governing mantle dynamics concerns the rheology governing the flow of mantle rocks under relevant temperature and pressure conditions. The momentum equation is the most computationally intensive portion of this coupled system because of its strongly nonlinear, elliptical character. We review the various discretization methods, ranging from finite differences to finite elements, which have been employed. We present in detail finite-element implementations of the Uzawa algorithm for the momentum equation and of the streamline Petrov–Galerkin algorithm for the energy equation. We review the application of modern techniques such as the Schur complement solvers and least-squares commutator preconditioners in the solution of the elliptical equation. We discuss the computational libraries available for massively parallel simulation and their application to this system of equations and give a preview of approaches suitable for exascale computing, which is a major challenge for the decade ahead. },
  Doi                      = {http://dx.doi.org/10.1016/B978-0-444-53802-4.00130-5},
  ISBN                     = {978-0-444-53803-1},
  Keywords                 = {Finite element},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780444538024001305}
}

@Article{Zou20144,
  Title                    = {FlexAnalytics: A Flexible Data Analytics Framework for Big Data Applications with I/O Performance Improvement },
  Author                   = {Hongbo Zou and Yongen Yu and Wei Tang and Hsuan-Wei Michelle Chen},
  Journal                  = {Big Data Research },
  Year                     = {2014},
  Note                     = {Special Issue on Scalable Computing for Big Data },
  Pages                    = {4 - 13},
  Volume                   = {1},

  Abstract                 = {Abstract Increasingly larger scale applications are generating an unprecedented amount of data. However, the increasing gap between computation and I/O capacity on High End Computing machines makes a severe bottleneck for data analysis. Instead of moving data from its source to the output storage, in-situ analytics processes output data while simulations are running. However, in-situ data analysis incurs much more computing resource contentions with simulations. Such contentions severely damage the performance of simulation on HPE. Since different data processing strategies have different impact on performance and cost, there is a consequent need for flexibility in the location of data analytics. In this paper, we explore and analyze several potential data-analytics placement strategies along the I/O path. To find out the best strategy to reduce data movement in given situation, we propose a flexible data analytics (FlexAnalytics) framework in this paper. Based on this framework, a FlexAnalytics prototype system is developed for analytics placement. FlexAnalytics system enhances the scalability and flexibility of current I/O stack on \{HEC\} platforms and is useful for data pre-processing, runtime data analysis and visualization, as well as for large-scale data transfer. Two use cases – scientific data compression and remote visualization – have been applied in the study to verify the performance of FlexAnalytics. Experimental results demonstrate that FlexAnalytics framework increases data transition bandwidth and improves the application end-to-end transfer performance. },
  Doi                      = {http://dx.doi.org/10.1016/j.bdr.2014.07.001},
  ISSN                     = {2214-5796},
  Keywords                 = {I/O bottlenecks},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S2214579614000021}
}

@Article{Zounmevo2014,
  Title                    = {A fast and resource-conscious \{MPI\} message queue mechanism for large-scale jobs },
  Author                   = {Judicael A. Zounmevo and Ahmad Afsahi},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2014},
  Note                     = {Special Issue on Extreme Scale Parallel Architectures and Systems, Cryptography in Cloud Computing and Recent Advances in Parallel and Distributed Systems, \{ICPADS\} 2012 Selected Papers },
  Pages                    = {265 - 290},
  Volume                   = {30},

  Abstract                 = {Abstract The Message Passing Interface (MPI) message queues have been shown to grow proportionately to the job size for many applications. With such a behaviour and knowing that message queues are used very frequently, ensuring fast queue operations at large scales is of paramount importance in the current and the upcoming exascale computing eras. Scalability, however, is two-fold. With the growing processor core density per node, and the expected smaller memory density per core at larger scales, a queue mechanism that is blind on memory requirements poses another scalability issue even if it solves the speed of operation problem. In this work we propose a multidimensional queue management mechanism whose operation time and memory overhead grow sub-linearly with the job size. We show why a novel approach is justified in spite of the existence of well-known and fast data structures such as binary search trees. We compare our proposal with a linked list-based approach which is not scalable in terms of speed of operation, and with an array-based method which is not scalable in terms of memory consumption. Our proposed multidimensional approach yields queue operation time speedups that translate to up to 4-fold execution time improvement over the linked list design for the applications studied in this work. It also shows a consistent lower memory footprint compared to the array-based design. Finally, compared to the linked list-based queue, our proposed design yields cache miss rate improvements which are on average on par with the array-based design. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2013.07.003},
  ISSN                     = {0167-739X},
  Keywords                 = {MPI},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X13001489}
}

@Article{Zounmevo2014265,
  Title                    = {A fast and resource-conscious \{MPI\} message queue mechanism for large-scale jobs },
  Author                   = {Judicael A. Zounmevo and Ahmad Afsahi},
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2014},
  Note                     = {Special Issue on Extreme Scale Parallel Architectures and Systems, Cryptography in Cloud Computing and Recent Advances in Parallel and Distributed Systems, \{ICPADS\} 2012 Selected Papers },
  Pages                    = {265 - 290},
  Volume                   = {30},

  Abstract                 = {Abstract The Message Passing Interface (MPI) message queues have been shown to grow proportionately to the job size for many applications. With such a behaviour and knowing that message queues are used very frequently, ensuring fast queue operations at large scales is of paramount importance in the current and the upcoming exascale computing eras. Scalability, however, is two-fold. With the growing processor core density per node, and the expected smaller memory density per core at larger scales, a queue mechanism that is blind on memory requirements poses another scalability issue even if it solves the speed of operation problem. In this work we propose a multidimensional queue management mechanism whose operation time and memory overhead grow sub-linearly with the job size. We show why a novel approach is justified in spite of the existence of well-known and fast data structures such as binary search trees. We compare our proposal with a linked list-based approach which is not scalable in terms of speed of operation, and with an array-based method which is not scalable in terms of memory consumption. Our proposed multidimensional approach yields queue operation time speedups that translate to up to 4-fold execution time improvement over the linked list design for the applications studied in this work. It also shows a consistent lower memory footprint compared to the array-based design. Finally, compared to the linked list-based queue, our proposed design yields cache miss rate improvements which are on average on par with the array-based design. },
  Doi                      = {http://dx.doi.org/10.1016/j.future.2013.07.003},
  ISSN                     = {0167-739X},
  Keywords                 = {MPI},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X13001489}
}

@Article{vshivkov2008adaptive,
  Title                    = {Адаптивное изменение массы модельных частиц при моделировании тлеющего ВЧ-разряда в силановой плазме},
  Author                   = {Вшивков, В.А.,Лазарева, Г.Г., Снытников, А.В.},
  Journal                  = {Вычислительные технологии},
  Year                     = {2008},
  Volume                   = {13}
}

@InCollection{tagkey2015xv,
  Title                    = {Preface },
  Booktitle                = {Multicore and \{GPU\} Programming },
  Publisher                = {Morgan Kaufmann},
  Year                     = {2015},

  Address                  = {Boston},
  Editor                   = {Barlas, Gerassimos },
  Pages                    = {xv - xix},

  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-417137-4.09981-0},
  ISBN                     = {978-0-12-417137-4},
  Key                      = {tagkey2015xv},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780124171374099810}
}

@InCollection{tagkey2012151,
  Title                    = {Appendix 3 - Current Supercomputers },
  Booktitle                = {Universe, Human Immortality and Future Human Evaluation },
  Publisher                = {Elsevier},
  Year                     = {2012},

  Address                  = {London},
  Editor                   = {Bolonkin, Alexander },
  Pages                    = {151 - 154},

  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-415801-6.00024-4},
  ISBN                     = {978-0-12-415801-6},
  Key                      = {tagkey2012151},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780124158016000244}
}

@InCollection{tagkey2013vii,
  Title                    = {Preface },
  Booktitle                = {Green and Sustainable Computing: Part II},
  Publisher                = {Elsevier},
  Year                     = {2013},
  Editor                   = {Ali Hurson},
  Pages                    = {vii - viii},
  Series                   = {Advances in Computers },
  Volume                   = {88},

  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-407725-6.00013-7},
  ISSN                     = {0065-2458},
  Key                      = {tagkey2013vii},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780124077256000137}
}

@InCollection{tagkey2012257,
  Title                    = {Subject Index },
  Publisher                = {Elsevier},
  Year                     = {2012},
  Editor                   = {Ali Hurson and Atif Memon},
  Pages                    = {257 - 272},
  Series                   = {Advances in Computers },
  Volume                   = {87},

  Doi                      = {http://dx.doi.org/10.1016/B978-0-12-396528-8.00012-2},
  ISSN                     = {0065-2458},
  Key                      = {tagkey2012257},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B9780123965288000122}
}

@Article{tagkey2015iii,
  Title                    = {Contents },
  Journal                  = {Procedia Computer Science },
  Year                     = {2015},
  Note                     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature },
  Pages                    = {iii - xxiv},
  Volume                   = {51},

  Doi                      = {http://dx.doi.org/10.1016/S1877-0509(15)01317-4},
  ISSN                     = {1877-0509},
  Key                      = {tagkey2015iii},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1877050915013174}
}

@Article{tagkey2014iii,
  Title                    = {Contents },
  Journal                  = {Future Generation Computer Systems },
  Year                     = {2014},
  Note                     = {Special Issue on Extreme Scale Parallel Architectures and Systems, Cryptography in Cloud Computing and Recent Advances in Parallel and Distributed Systems, \{ICPADS\} 2012 Selected Papers },
  Pages                    = {iii - iv},
  Volume                   = {30},

  Doi                      = {http://dx.doi.org/10.1016/S0167-739X(13)00226-4},
  ISSN                     = {0167-739X},
  Key                      = {tagkey2014iii},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X13002264}
}

@Article{tagkey201346,
  Title                    = {Events Diary },
  Journal                  = {Materials Today },
  Year                     = {2013},
  Number                   = {1–2},
  Pages                    = {46 - },
  Volume                   = {16},

  Doi                      = {http://dx.doi.org/10.1016/j.mattod.2013.01.004},
  ISSN                     = {1369-7021},
  Key                      = {tagkey201346},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1369702113000059}
}

@InCollection{tagkey2008ix,
  Title                    = {Contributors },
  Booktitle                = {Advances in COMPUTERSHigh Performance Computing},
  Publisher                = {Elsevier},
  Year                     = {2008},
  Pages                    = {ix - xv},
  Series                   = {Advances in Computers },
  Volume                   = {72},

  Abstract                 = {Publisher Summary This chapter lists the names of the people who have contributed to the publication of the book, Advances in Computers, Volume 72, such as Sadaf R. Alam, Roy L. Campbell, Laura Nett Carrington, Tzu-Yi Chen, and others. },
  Doi                      = {http://dx.doi.org/10.1016/S0065-2458(09)60003-6},
  ISSN                     = {0065-2458},
  Key                      = {tagkey2008ix},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0065245809600036}
}

